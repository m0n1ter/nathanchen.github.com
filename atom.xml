<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[NathanCHEN]]></title>
  <link href="http://nathanchen.github.io/atom.xml" rel="self"/>
  <link href="http://nathanchen.github.io/"/>
  <updated>2016-03-27T20:32:46+08:00</updated>
  <id>http://nathanchen.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[应用多级缓存模式支撑海量读服务]]></title>
    <link href="http://nathanchen.github.io/14590098445355.html"/>
    <updated>2016-03-27T00:30:44+08:00</updated>
    <id>http://nathanchen.github.io/14590098445355.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">如何缓存数据</h3>

<h4 id="toc_1">过期与不过期</h4>

<p>不过期缓存的场景一般思路如下：</p>

<p><img src="media/14590098445355/14590098715786.jpg" alt=""/></p>

<p>首先写数据库，如果成功则写缓存。这种机制存在一些问题：</p>

<ul>
<li>事务在提交时失败则写缓存是不会回滚的，造成DB和缓存数据不一致</li>
<li>多个人并发写缓存可能出现脏数据</li>
<li>同步写对性能有一定影响，异步写又存在丢数据的风险</li>
</ul>

<p>如果对缓存数据一致性要求不是那么高，数据量也不是很大，可以考虑定期全量同步缓存。</p>

<p><img src="media/14590098445355/14590100613107.jpg" alt=""/></p>

<ol>
<li>把写缓存改成写消息，通过消息通知数据变更</li>
<li>同步缓存系统会订阅消息，并根据消息进行更新缓存</li>
<li>数据一致性可以采用：消息体只包括ID，然后查库获取最新版本数据；通过时间戳和内容摘要机制（MD5）进行缓存更新</li>
<li>如上方法也不能保证消息不丢失，可以采用：应用在本地记录更新日志，当消息丢失了，回放更新日志</li>
</ol>

<p>过期缓存机制的常见步骤是：首先读取缓存，如果不命中，则查询数据，然后异步写入缓存并设置过期时间，下次读取将命中缓存。</p>

<h3 id="toc_2">Reference</h3>

<p><a href="http://jinnianshilongnian.iteye.com/blog/2283670">http://jinnianshilongnian.iteye.com/blog/2283670</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浅谈Web缓存]]></title>
    <link href="http://nathanchen.github.io/14589988314853.html"/>
    <updated>2016-03-26T21:27:11+08:00</updated>
    <id>http://nathanchen.github.io/14589988314853.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">浏览器缓存</h3>

<h4 id="toc_1">Cache-Control</h4>

<p>1、<code>max-age</code>（单位为<code>s</code>）当浏览器向服务器发送请求后，在<code>max-age</code>这段时间里浏览器就不会再向服务器发送请求了。<code>max-age</code>会覆盖掉<code>Expires</code>。</p>

<pre><code>max-age=2592000
</code></pre>

<p>也就是说缓存有效期为2592000秒（也就是30天）。于是在30天内都会使用这个版本的资源，即使服务器上的资源发生了变化，浏览器也不会得到通知。</p>

<p>2、<code>s-maxage</code>（单位为<code>s</code>），只用于共享缓存（比如<code>CDN</code>）</p>

<pre><code>s-maxage=60
</code></pre>

<p>在这60秒中，即使更新了<code>CDN</code>的内容，浏览器也不会进行请求。如果存在<code>s-maxage</code>，则会覆盖掉<code>max-age</code>和<code>Expires header</code>。</p>

<p>3、<code>public</code>指定响应会被缓存，并且在多用户间共享。如果没有指定<code>public</code>还是<code>private</code>，则默认为<code>public</code></p>

<p>4、<code>private</code>响应只作为私有的缓存，不能在用户间共享。</p>

<p>5、<code>no-cache</code>指定不缓存响应，表明资源不进行缓存。设置了<code>no-cache</code>之后并不代表浏览器不缓存，而是在缓存前要向服务器确认资源是否被更改。因此有的时候只设置<code>no-cache</code>防止缓存还是不够保险，还可以加上<code>private</code>指令，将过期时间设为过去的时间。</p>

<p>6、<code>no-store</code>绝对禁止缓存</p>

<h4 id="toc_2">Expires</h4>

<p>缓存过期时间，用来指定资源到期的时间，是服务器端的具体的时间点。也就是说，<code>Expires = max-age + 请求时间</code>，需要和<code>Last-modified</code>结合使用。</p>

<h4 id="toc_3">Last-modified</h4>

<p>服务器端文件的最后修改时间，需要和<code>cache-control</code>共同使用，是检查服务器端资源是否更新的一种方式。当浏览器再次进行请求时，会向服务器传送<code>If-Modified-Since</code>报头，询问<code>Last-Modified</code>时间点之后资源是否被修改过。如果没有修改，则返回码为<code>304</code>，使用缓存；如果修改过，则再次去服务器请求资源，返回码和首次请求相同为<code>200</code>，资源为服务器最新资源。</p>

<h4 id="toc_4">ETag</h4>

<p>根据实体内容生成一段<code>hash</code>字符串，标识资源的状态，由服务端产生。浏览器会将这串字符串传回服务器，验证资源是否已经修改</p>

<p><img src="media/14589988314853/14589994585073.jpg" alt=""/></p>

<p>使用<code>ETag</code>可以解决<code>Last-modified</code>存在的一些问题：</p>

<ul>
<li>某些服务器不能精确得到资源的最后修改时间，这样就无法通过最后修改时间判断资源是否更新 </li>
<li>如果资源修改非常频繁，在秒以下的时间内进行修改，而<code>Last-modified</code>只能精确到秒 </li>
<li>一些资源的最后修改时间改变了，但是内容没改变，使用<code>ETag</code>就认为资源还是没有修改的。</li>
</ul>

<h3 id="toc_5">使用缓存流程</h3>

<p><img src="media/14589988314853/14589996373194.jpg" alt=""/></p>

<h3 id="toc_6">其他</h3>

<p><code>LocalStorage</code>是一种本地存储的公共资源，域名下很多应用共享这份资源会有风险；<code>LocalStorage</code>是以页面域名划分的，如果有多个等价域名之间的<code>LocalStorage</code>不互通，则会造成缓存多份浪费。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入分析`Java I/O`的工作机制]]></title>
    <link href="http://nathanchen.github.io/14588873943004.html"/>
    <updated>2016-03-25T14:29:54+08:00</updated>
    <id>http://nathanchen.github.io/14588873943004.html</id>
    <content type="html"><![CDATA[
<p>不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符，所以<code>I/O</code>操作的都是字节而不是字符。但是我们的程序中通常操作的数据都是字符形式的。</p>

<p>基于字节的<code>I/O</code>操作接口输入和输出分别是<code>InputStream</code>和<code>OutputStream</code></p>

<p>写字符的<code>I/O</code>操作接口涉及的是<code>write(char[] buf, int off, int len)</code></p>

<p>读字符的<code>I/O</code>操作是<code>read(char[] buf, int off, int len)</code></p>

<h4 id="toc_0">字节与字符的转化接口</h4>

<p>数据持久化或网络传输都是以字节进行的，所以必须要有<strong>字符到字节或者字节到字符</strong>的转化。</p>

<h4 id="toc_1">几种访问文件的方式</h4>

<p><strong>读取和写入文件<code>I/O</code>操作都调用操作系统提供的接口</strong>，因为磁盘设备是由操作系统管理的，应用程序要访问物理设备只能通过系统调用的方式来工作。</p>

<p>只要是系统调用就可能存在内核空间地址和用户空间地址切换的问题，这是操作系统为了保护系统本身的运行安全而将内核程序运行使用的内存空间和用户程序运行的内存空间隔离造成的。这样虽然保证了内核程序运行的安全性，但是也必然<strong>存在数据可能需要从内核空间向用户空间复制的问题</strong>。</p>

<p>如果遇到非常耗时的操作，如磁盘<code>I/O</code>，数据从磁盘复制到内核空间，然后又从内核空间复制到用户空间，将会非常缓慢。这时操作系统为了加速<code>I/O</code>访问，在<strong>内核空间使用缓存机制，也就是将从磁盘读取的文件按照一定的组织方式进行缓存</strong>。</p>

<h5 id="toc_2">标准访问文件方式</h5>

<p><strong>当应用程序调用<code>read()</code>接口</strong>时，操作系统检查内核的告诉缓存中有没有需要的数据。如果已经缓存了，那么就直接从缓存中返回；如果没有，从磁盘中读取，然后缓存在操作系统的缓存中。</p>

<p><strong>当应用程序调用<code>write()</code>接口</strong>时，将数据从用户地址空间复制到内核地址空间的缓存中。这时，对用户程序来说，写操作就已经完成了，至于什么时候再写到磁盘中是有操作系统决定的，除非显式地调用<code>sync</code>同步命令</p>

<h5 id="toc_3">直接<code>I/O</code>方式</h5>

<p><strong>应用程序直接访问磁盘数据，而不经过操作系统内核数据缓冲区</strong>，这样做的目的就是减少一次从内核缓冲区到用户程序缓存的数据复制。</p>

<p>这种访问文件的方式通常是在对数据的缓存管理由应用程序实现的数据库管理程序中。（如数据库管理系统中，系统明确地知道应该缓存哪些数据，应该失效哪些数据，还可以对一些热点数据做预加载，提前将热点数据加载到内存，可以加速数据的访问效率；而操作系统并不知道哪些是热点数据，只是简单地缓存最近一次从磁盘读取的数据）</p>

<p><strong>缺点：如果访问的数据不在应用程序缓存中，那么每次数据都会直接从磁盘加载。这种直接加载会非常缓慢</strong>。</p>

<h5 id="toc_4">同步访问文件方式</h5>

<p><strong>数据的读取和写入都是同步操作的</strong>，它与标准访问文件方式不同的是，<strong>只有当数据被成功写到磁盘时才返回给应用程序成功标志</strong>。</p>

<p>这种访问文件方式<strong>性能比较差</strong>，只有在一些对数据安全性要求比较高的场景中才会使用，而且通常这种操作方式的硬件都是定制的。</p>

<h5 id="toc_5">异步访问文件方式</h5>

<p><strong>当访问数据的线程发出请求之后，线程会接着去处理其他事情</strong>，而不是阻塞等待，当请求的数据返回后继续处理下面的操作。这种访问文件的方式可以明显地提高应用程序的效率，但是不会改变访问文件的效率。</p>

<h5 id="toc_6">内存映射方式</h5>

<p>内存映射方式是指操作系统将内存中的某一块区域与磁盘中的文件关联起来，当要访问内存中一段数据时，转换为访问文件的某一段数据。这种方式的目的同样是减少数据从内核空间缓存到用户空间缓存的数据复制操作，因为这两个空间的数据是共享的。</p>

<h4 id="toc_7">Java访问磁盘文件</h4>

<p>数据在磁盘中的唯一最小描述就是文件，也就是说上层应用程序只能通过文件来操作磁盘上的数据，文件也是操作系统和磁盘驱动器交互的最小单元。</p>

<p><code>Java</code>中通常的<code>File</code>并不代表一个真实存在的文件对象，当你指定一个路径描述符时，它就会返回一个代表这个路径的一个虚拟对象，这个可能是一个真实存在的文件或者是一个包含多个文件的目录。</p>

<p>如何从磁盘读取一段文本字符：</p>

<p>当传入一个文件路径时，将会根据这个路径创建一个<code>File</code>对象来标识这个文件，然后根据这个<code>File</code>对象创建真正读取文件的操作对象，这时将会真正创建一个关联真实存在的磁盘文件的文件描述符<code>FileDescriptor</code>，通过这个对象可以直接控制这个磁盘文件。</p>

<p>由于我们需要读取的是字符格式，所以需要<code>StreamDecoder</code>类将<code>byte</code>解码为<code>char</code>格式。</p>

<h4 id="toc_8">Java序列化</h4>

<p>Java序列化就是将一个对象转化成一串二进制表示的字节数组，通过保存或转移这些字节数据来达到持久化的目的。需要持久化，对象必须继承<code>java.io.Serializable</code>接口。</p>

<p>反序列化则是相反的过程，将这个字节数组再重新构造成对象。</p>

<h3 id="toc_9">网络<code>I/O</code>工作机制</h3>

<h4 id="toc_10">TCP状态转化</h4>

<p><img src="media/14588873943004/14588911569166.jpg" alt=""/></p>

<p>1、CLOSED：起始点，在超时或者连接关闭时进入此状态<br/>
2、LISTEN：Server端在等待连接时的状态，Server端为此要调用Scok</p>

<h4 id="toc_11">影响网络传输的因素</h4>

<p>将一份数据从一个地方正确地传输到另一个地方所需要的时间我们称为响应时间。影响这个响应时间的因素有很多。</p>

<ul>
<li>网络带宽</li>
<li>传输距离</li>
<li><code>TCP</code>拥塞控制</li>
</ul>

<p><code>TCP</code>传输是一个<code>停-等-停-等</code>协议，传输放和接受方的步调要一致，要达到这个步调一致就要通过拥塞控制来调节。TCP在传输时会设定一个窗口（<code>BDP，Brandwidth Delay Product</code>），这个窗口的大小是由带宽和<code>RTT</code>（<code>Round-Trip Time</code>，数据在两端的来回时间，也就是响应时间）决定的。计算的公式是<code>带宽（b/s）</code> * <code>RTT（s）</code>。通过这个值可以得出理论上最优的<code>TCP</code>缓冲区的大小。</p>

<h4 id="toc_12"><code>Java Socket</code>的工作机制</h4>

<p><code>Socket</code>描述计算机之间完成相互通信的一种抽象功能。</p>

<p>打个比方，可以把<code>Socket</code>比作两个城市之间的交通工具，有了它，就可以在城市之间来回穿梭了、交通工具有多种，每种交通工具也有相应的交通规则。<code>Socket</code>也一样，也有多种。大部分情况我们使用的是基于<code>TCP/IP</code>的流套接字，它是一种稳定的通信协议。</p>

<p><img src="media/14588873943004/14588952417202.jpg" alt=""/></p>

<p><code>主机A</code>的应用程序要能和<code>主机B</code>的应用程序<strong>通信，必须通过<code>Socket</code>建立连接</strong>，而<strong>建立<code>Socket</code>连接必须由底层<code>TCP/IP</code>协议来建立<code>TCP</code>连接</strong>。<strong>建立<code>TCP</code>连接需要底层<code>IP</code>协议来寻址网络中的主机</strong>。网络层使用的<code>IP</code>协议可以帮助我们根据<code>IP</code>地址来找到目标主机，但是一台主机上可能运行着多个应用程序，如何才能与指定的应用程序通信就要通过<code>TCP</code>或<code>UDP</code>的地址，也就是<strong>端口号</strong>来指定了。</p>

<h4 id="toc_13">建立通信链路</h4>

<p>当客户端要与服务端通信时，客户端<strong>首先要创建一个<code>Socket</code>实例</strong>，操作系统将为这个<code>Socket</code>实例<strong>分配一个没有被使用的本地端口号</strong>，并<strong>创建一个包含本地和远程地址和端口号的套接字数据结构</strong>，这个数据结构将一直保存在系统中直到这个连接关闭。</p>

<p>在创建<code>Socket</code>实例的构造函数正确返回之前，将要进行<code>TCP</code>的三次握手协议，<code>TCP</code>握手协议完成后，<code>Socket</code>实例对象将创建完成，否则将抛出<code>IOException</code>错误。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深入Web请求过程]]></title>
    <link href="http://nathanchen.github.io/14588864645651.html"/>
    <updated>2016-03-25T14:14:24+08:00</updated>
    <id>http://nathanchen.github.io/14588864645651.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>B/S =&gt; Browser / Server<br/>
C/S =&gt; Client / Server</p>
</blockquote>

<h3 id="toc_0">如何发起一个请求</h3>

<p>浏览器在建立<code>Socket</code>连接之前，必须根据地址栏里输入的<code>URL</code>的域名<code>DNS</code>解析出<code>IP</code>地址，再根据这个<code>IP</code>地址和默认80端口与远程服务器建立<code>Socket</code>连接，然后浏览器根据这个<code>URL</code>组装成一个<code>get</code>类型的<code>HTTP</code>请求头，通过<code>outputStream.write()</code>发送到目标服务器，服务器等待<code>inputStream.read()</code>返回数据，最后断开这个连接。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I]]></title>
    <link href="http://nathanchen.github.io/14588864364518.html"/>
    <updated>2016-03-25T14:13:56+08:00</updated>
    <id>http://nathanchen.github.io/14588864364518.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高性能MySQL - 创建高性能的索引]]></title>
    <link href="http://nathanchen.github.io/14588857020339.html"/>
    <updated>2016-03-25T14:01:42+08:00</updated>
    <id>http://nathanchen.github.io/14588857020339.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">索引基础</h3>

<p>索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要，因为<strong>MySQL只能高效地使用索引的最左前缀列</strong>。创建一个包含两个列的索引，和创建两个只包含一列的索引是大不相同的。</p>

<h4 id="toc_1">索引的类型</h4>

<h5 id="toc_2">B-Tree索引</h5>

<p>B-Tree通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搜索引擎关键字智能提示的一种实现]]></title>
    <link href="http://nathanchen.github.io/14588733684599.html"/>
    <updated>2016-03-25T10:36:08+08:00</updated>
    <id>http://nathanchen.github.io/14588733684599.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">解决方案</h3>

<h5 id="toc_1">关键字收集</h5>

<p>当用户输入一个前缀时，碰到提示的候选词很多的时候，如何取舍，哪些展示在前面，哪些展示在后面？</p>

<p>用户在使用搜索引擎查找商家时，会输入大量的关键字，每一次输入就是对关键字的一次投票，那么关键字被输入的次数越多，它对应的查询就比较热门，所以需要查询的关键字记录下来，并且统计出每个关键字的频率，方便提示结果按照频率排序。</p>

<p>搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来。</p>

<h5 id="toc_2">拼音缩写提取</h5>

<p><code>chongqing</code>, <code>zhongqing</code> -&gt; <code>cq</code>, <code>zq</code></p>

<h3 id="toc_3">索引与前缀查询</h3>

<h4 id="toc_4">方案一：Trie树 + TopK算法</h4>

<p><strong>Trie树</strong>即字典树，又称单词查找树或键树，是一种树形结构，一种哈希树的变种。</p>

<p>它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。</p>

<p><img src="media/14588733684599/14588739187774.jpg" alt=""/></p>

<p>从上图可知，当用户输入前缀<code>i</code>的时候，搜索框可能会展示以<code>i</code>为前缀的<code>in</code>，<code>inn</code>，<code>int</code>等关键词，再当用户输入前缀<code>a</code>的时候，搜索框里面可能会提示以<code>a</code>为前缀的<code>ate</code>等关键词。如此，实现搜索引擎智能提示<code>suggestion</code>的第一个步骤便清晰了</p>

<p><strong>TopK算法</strong>用于解决统计热词的问题。解决TopK问题主要有两种策略：HashMap统计+排序（堆排序）。</p>

<p><code>HashMap</code>统计：先对这批海量数据预处理。具体方法是：维护一个<code>Key</code>为<code>Query</code>字串，<code>Value</code>为该<code>Query</code>出现次数的<code>HashMap</code>。</p>

<p><strong>该方案存在的问题</strong>是：</p>

<ul>
<li>需要维护拼音、缩写两棵<code>Trie</code>树。</li>
</ul>

<h4 id="toc_5">方案二：<code>Solr</code>自带<code>Suggest</code>智能提示</h4>

<p><strong>该方案存在的问题</strong>是：</p>

<ul>
<li>返回的结果是基于索引中字段的词频进行排序，不是用户搜索关键字的频率，因此不能将一些热门关键字排在前面。</li>
<li>拼音提示，多音字，缩写还是要另外加索引字段。</li>
</ul>

<h4 id="toc_6">方案三 <code>Solrcloud</code>建立单独的<code>collection</code>,利用<code>Solr</code>前缀查询实现</h4>

<p>专门为关键字建立一个索引<code>collection</code>，利用<code>Solr</code>前缀查询实现。<code>Solr</code>中的<code>copyField</code>能很好解决我们同时索引多个字段(汉字、<code>pinyin</code>, <code>abbre</code>)的需求，且<code>field</code>的<code>multiValued</code>属性设置为<code>true</code>时能解决同一个关键字的多音字组合问题。</p>

<h3 id="toc_7">Reference</h3>

<p><a href="http://tech.meituan.com/pinyin-suggest.html">http://tech.meituan.com/pinyin-suggest.html</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java内存访问重排序的研究]]></title>
    <link href="http://nathanchen.github.io/14588711280200.html"/>
    <updated>2016-03-25T09:58:48+08:00</updated>
    <id>http://nathanchen.github.io/14588711280200.html</id>
    <content type="html"><![CDATA[
<pre><code>public class PossibleReordering {
    static int x = 0, y = 0;
    static int a = 0, b = 0;
    
    public static void main(String[] args) throws InterruptedException {
        Thread one = new Thread(new Runnable() {
            public void run() {
                a = 1;
                x = b;
            }
        });
    
        Thread other = new Thread(new Runnable() {
            public void run() {
                b = 1;
                y = a;
            }
        });
        one.start();other.start();
        one.join();other.join();
        System.out.println(“(” + x + “,” + y + “)”);
    }
}
</code></pre>

<p>这段代码的执行结果也可能是（0，0），因为，在实际运行时，代码指令可能并不是严格按照代码语句顺序执行的。</p>

<p>得到（0，0）结果的语句执行过程：</p>

<p><img src="media/14588711280200/14588715411444.jpg" alt=""/></p>

<p><code>a=1</code>和<code>x=b</code>这两个语句的赋值操作的顺序被颠倒了，或者说，发生了指令“重排序<code>(reording)</code>”</p>

<p>大多数现代微处理器都会采用将指令乱序执行的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避免获取下一条指令所需数据时造成的等待，通过乱序执行的技术，处理器可以大大提高执行效率。</p>

<h3 id="toc_0"><code>as-if-serial</code>语义</h3>

<p>所有的动作都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。</p>

<pre><code>int a = 1;
int b = 2;
int c = a + b;
</code></pre>

<p>将上面的代码编译成<code>Java</code>字节码或生成机器指令，可视为展开成了以下动作：</p>

<pre><code>1. 对a赋值1
2. 对b赋值2
3. 取a的值
4. 取b的值
5. 将取到两个值相加后存入c
</code></pre>

<p>在上面5个动作中，<code>动作1</code>可能会和<code>动作2、4</code>重排序，<code>动作2</code>可能会和<code>动作1、3</code>重排序，<code>动作3</code>可能会和<code>动作2、4</code>重排序，<code>动作4</code>可能会和<code>动作1、3</code>重排序。但<code>动作1</code>和<code>动作3、5</code>不能重排序。<code>动作2</code>和<code>动作4、5</code>不能重排序。因为它们之间存在数据依赖关系，一旦重排，<code>as-if-serial</code>语义便无法保证</p>

<h3 id="toc_1">内存访问重排序与内存可见性</h3>

<p>计算机系统中，为了尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存（cache）以提高性能。</p>

<p><img src="media/14588711280200/14588720292789.jpg" alt=""/></p>

<p>在这种模型下会存在一个现象，即缓存中的数据与主内存的数据并不是实时同步的，各CPU（或CPU核心）间缓存的数据并不是实时同步的。从程序的视角来看，就是同一个时间点，各个线程所看到的共享变量的值可能是不一致的。</p>

<h3 id="toc_2">内存访问重排序与Java内存模型</h3>

<p>根据<code>Java</code>内存模型中的规定，可以总结出以下几条<code>happens-before</code>规则。<code>happens-before</code>的前后两个操作不会被重排序且后者对前者的内存可见。</p>

<ul>
<li>程序次序法则：线程中的每个<code>动作A</code>都<code>happens-before</code>于该线程中的每一个<code>动作B</code>，其中，在程序中，所有的<code>动作B</code>都能出现在<code>动作A</code>之后。</li>
<li>监视器锁法则：对一个监视器锁的解锁<code>happens-before</code>于每一个后续对同一监视器锁的加锁。</li>
<li><code>volatile</code>变量法则：对<code>volatile</code>域的写入操作<code>happens-before</code>于每一个后续对同一个域的读写操作。</li>
<li>线程启动法则：在一个线程里，对<code>Thread.start()</code>的调用会<code>happens-before</code>于每个启动线程的动作。</li>
<li>线程终结法则：线程中的任何动作都<code>happens-before</code>于其他线程检测到这个线程已经终结、或者从<code>Thread.join()</code>调用中成功返回，或<code>Thread.isAlive()</code>返回<code>false</code>。</li>
<li>中断法则：一个线程调用另一个线程的<code>interrupt</code> <code>happens-before</code>于被中断的线程发现中断。</li>
<li>终结法则：一个对象的构造函数的结束<code>happens-before</code>于这个对象<code>finalizer</code>的开始。</li>
<li>传递性：如果<code>A</code> <code>happens-before</code>于<code>B</code>，且<code>B</code> <code>happens-before</code>于<code>C</code>，则<code>A</code> <code>happens-before</code>于<code>C</code></li>
</ul>

<h3 id="toc_3">Reference</h3>

<p><a href="http://tech.meituan.com/java-memory-reordering.html">http://tech.meituan.com/java-memory-reordering.html</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[`MySQL`索引原理及慢查询优化]]></title>
    <link href="http://nathanchen.github.io/14588705157449.html"/>
    <updated>2016-03-25T09:48:35+08:00</updated>
    <id>http://nathanchen.github.io/14588705157449.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">MySQL索引原理</h3>

<h4 id="toc_1">索引目的</h4>

<p>在于提高查询效率，可以类比字典，如果要查<code>mysql</code>这个单词，我们肯定需要定位到<code>m</code>字母，然后从下往上找到<code>y</code>字母，再找到剩下的<code>sql</code>。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的。</p>

<h4 id="toc_2">索引原理</h4>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[`HashMap`底层原理]]></title>
    <link href="http://nathanchen.github.io/14588687241012.html"/>
    <updated>2016-03-25T09:18:44+08:00</updated>
    <id>http://nathanchen.github.io/14588687241012.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">引言</h3>

<blockquote>
<p><code>HashMap</code>基于哈希表的<code>Map</code>接口的实现。此实现提供所有可选的映射操作，并允许使用<code>null</code>值和<code>null</code>键。（除了不同步和允许使用<code>null</code>之外，<code>HashMap</code>类与<code>Hashtable</code>大致相同）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。</p>

<p>值得注意的是<code>HashMap</code>不是线程安全的，如果想要线程安全的<code>HashMap</code>，可以通过<code>Collections</code>类的静态方法<code>synchronizedMap</code>获得线程安全的<code>HashMap</code>。</p>

<pre><code>Map map = Collections.synchronizedMap(new HashMap());
</code></pre>
</blockquote>

<h3 id="toc_1">一、数据结构与冲突</h3>

<p><code>HashMap</code>的底层主要是基于数组和链表来实现的，它之所以有相当快的查询速度主要是因为它是通过计算散列码来决定存储的位置。<strong><code>HashMap</code>中主要是通过<code>key</code>的<code>hashCode</code>来计算<code>hash</code>值的</strong>，只要<code>hashCode</code>相同，计算出来的<code>hash</code>值就一样。<strong>如果存储的对象对多了，就有可能不同的对象所算出来的<code>hash</code>值是相同的，这就出现了所谓的<code>hash</code>冲突</strong>。解决<code>hash</code>冲突的方法有很多，<code>HashMap</code>底层是<strong>通过链表来解决<code>hash</code>冲突的</strong>。</p>

<p><img src="media/14588687241012/14588688631332.jpg" alt=""/></p>

<p>图中，左边部分代表哈希表，也称为哈希数组，数组的每个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。右边部分则显示数组内部结构，<code>HashMap</code>其实就是一个<code>Entry</code>数组，<code>Entry</code>对象中包含了键和值，其中<code>next</code>也是一个<code>Entry</code>对象，它就是用来处理<code>hash</code>冲突的，形成一个链表。</p>

<h3 id="toc_2">二、HashMap相关属性</h3>

<pre><code>transient Entry[] table;//存储元素的实体数组

transient int size;//存放元素的个数

int threshold; //临界值，当实际大小超过临界值时，会进行扩容，扩容大小为当前的2倍。threshold = 负载因子*容量

final float loadFactor; //负载因子

transient int modCount;//被修改的次数
</code></pre>

<p>其中比较重要的两个参数是容量(<code>Capacity</code>) 和 负载因子(<code>Load factor</code>)</p>

<blockquote>
<p><strong>Initial capacity</strong>: The capacity is the number of buckets in the hash table, The initial capacity is simply the capacity at the time the hash table is created.<br/>
<strong>Load factor</strong>: The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased.</p>
</blockquote>

<p>简单的说，<code>Capacity</code>就是<code>bucket</code>的大小，<code>loadFactor</code>就是<code>bucket</code>填满程度的最大比例。</p>

<p><code>loadFactor</code>越大，填满的元素越多，好处是，空间利用率高了，但冲突的机会加大了，链表长度会越来越长,查找效率降低。</p>

<p>反之，<code>loadFactor</code>越小，填满的元素越少，好处是冲突的机会减小了，但空间浪费多了，表中的数据将过于稀疏（很多空间还没用，就开始扩容了）</p>

<p>因此,必须在 “冲突的机会” 与 “空间利用率” 之间寻找一种平衡与折衷. 这种平衡与折衷本质上是数据结构中有名的 “时-空” 矛盾的平衡与折衷.</p>

<p>如果机器内存足够，并且想要提高查询速度的话可以将<code>loadFactor</code>设置小一点；相反如果机器内存紧张，并且对查询速度没有什么要求的话可以将<code>loadFactor</code>设置大一点。不过<strong>一般取默认值0.75</strong>就好。</p>

<h3 id="toc_3">三、使用频率最高的两个方法<code>put</code>和<code>get</code></h3>

<p><code>put</code>函数大致的思路为：</p>

<p>1、对<code>key</code>的<code>hashCode()</code>做<code>hash</code>，然后再计算<code>index</code>；</p>

<p>2、如果没碰撞直接放到<code>bucket</code>里；</p>

<p>3、如果碰撞了，以链表的形式存在<code>buckets</code>后；</p>

<p>4、如果碰撞导致链表过长(大于等于<code>TREEIFY_THRESHOLD</code>)，就把链表转换成红黑树；</p>

<p>5、如果节点已经存在就替换<code>old value</code>(保证<code>key</code>的唯一性)；</p>

<p>6、如果<code>bucket</code>满了(超过<code>loadFactor * current capacity</code>)，就要<code>resize</code>。</p>

<pre><code>public V put(K key, V value) 
{
    // 对key的hashCode()做hash
    return putVal(hash(key), key, value, false, true);
}
 
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) 
{
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;

    // tab为空则创建
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;

    // 计算index，并对null做处理
    if ((p = tab[i = (n - 1) &amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);

    else 
    {
        Node&lt;K,V&gt; e; K k;

        // 节点存在
        if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
            e = p;

        // 该链为树
        else if (p instanceof TreeNode)
            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);

        // 该链为链表
        else 
        {
            for (int binCount = 0; ; ++binCount) 
            {
                if ((e = p.next) == null) 
                {
                    p.next = newNode(hash, key, value, null);
                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    break;
                p = e;
            }
        }
        // 写入
        if (e != null) 
        { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 超过load factor*current capacity，resize
    if (++size &gt; threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
</code></pre>

<p><code>get</code>函数大致思路如下：</p>

<p>1、<code>bucket</code>里的第一个节点，直接命中；</p>

<p>2、如果有冲突，则通过<code>key.equals(k)</code>去查找对应的<code>entry</code>；</p>

<p>3、若为树，则在树中通过<code>key.equals(k)</code>查找，<code>O(logn)</code>；</p>

<p>4、若为链表，则在链表中通过<code>key.equals(k)</code>查找，<code>O(n)</code>。</p>

<pre><code>public V get(Object key) 
{
    Node&lt;K,V&gt; e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
 
final Node&lt;K,V&gt; getNode(int hash, Object key) 
{
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) 
    {
        // 直接命中
        if (first.hash == hash &amp;&amp; // always check first node
            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
            return first;
        // 未命中
        if ((e = first.next) != null) 
        {
            // 在树中get
            if (first instanceof TreeNode)
                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);
            // 在链表中get
            do 
            {
                if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
</code></pre>

<h3 id="toc_4">四、<code>resize</code>的实现</h3>

<p>当<code>put</code>时，如果发现目前的<code>bucket</code>占用程度已经超过了<code>loadFactor</code>所希望的比例，那么就会发生<code>resize</code>。在<code>resize</code>的过程，简单的说就是把<code>bucket</code>扩充为2倍，之后重新计算<code>index</code>，把节点再放到新的<code>bucket</code>中。<code>resize</code>的注释是这样描述的：</p>

<blockquote>
<p>Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table.</p>
</blockquote>

<p>大致意思就是说，<strong>当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置</strong>。</p>

<p>怎么理解呢？例如我们从16扩展为32时，具体的变化如下所示：</p>

<p><img src="media/14588687241012/14588692702341.jpg" alt=""/></p>

<p>因此元素在重新计算<code>hash</code>之后，因为<code>n</code>变为2倍，那么<code>n-1</code>的<code>mask</code>范围在高位多<code>1bit</code>(红色)，因此新的<code>index</code>就会发生这样的变化：</p>

<p><img src="media/14588687241012/14588692827747.jpg" alt=""/></p>

<p>因此，我们在扩充<code>HashMap</code>的时候，不需要重新计算<code>hash</code>，只需要看看原来的<code>hash</code>值新增的那个<code>bit</code>是1还是0就好了，是0的话索引没变，是1的话索引变成<code>原索引+oldCap</code>。可以看看下图为16扩充为32的<code>resize</code>示意图：</p>

<p><img src="media/14588687241012/14588693335759.jpg" alt=""/></p>

<p>这个设计非常巧妙，既省去了重新计算<code>hash</code>值的时间，而且同时，由于新增的<code>1bit</code>是0还是1可以认为是随机的，因此<code>resize</code>的过程，均匀的把之前的冲突的节点分散到新的<code>bucket</code>了。</p>

<h3 id="toc_5">总结</h3>

<p>通过<code>hash</code>的方法，通过<code>put</code>和<code>get</code>存储和获取对象。存储对象时，我们将<code>K/V</code>传给<code>put</code>方法时，它调用<code>hashCode</code>计算<code>hash</code>从而得到<code>bucket</code>位置，进一步存储，<code>HashMap</code>会根据当前<code>bucket</code>的占用情况自动调整容量(超过<code>loadFactor</code>则<code>resize</code>为原来的2倍)。获取对象时，我们将<code>K</code>传给<code>get</code>，它调用<code>hashCode</code>计算<code>hash</code>从而得到<code>bucket</code>位置，并进一步调用<code>equals()</code>方法确定键值对。如果发生碰撞的时候，<code>HashMap</code>通过链表将产生碰撞冲突的元素组织起来，在<code>Java 8</code>中，如果一个<code>bucket</code>中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[倒排索引及`tf-idf`算法简介]]></title>
    <link href="http://nathanchen.github.io/14587172862630.html"/>
    <updated>2016-03-23T15:14:46+08:00</updated>
    <id>http://nathanchen.github.io/14587172862630.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">倒排索引简介</h1>

<p>倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(<code>inverted index</code>)。带有倒排索引的文件我们称为倒排索引文件，简称倒排文件(<code>inverted file</code>)。</p>

<p>倒排文件（倒排索引），索引对象是文档或者文档集合中的单词等，用来存储这些单词在一个文档或者一组文档中的存储位置，是对文档或者文档集合的一种最常用的索引机制。</p>

<p>搜索引擎的关键步骤就是建立倒排索引，倒排索引一般表示为一个关键词，然后是它的频度（出现的次数），位置（出现在哪一篇文章或网页中，及有关的日期，作者等信息），它相当于为互联网上几千亿页网页做了一个索引，<strong>好比一本书的目录、标签一般</strong>。读者想看哪一个主题相关的章节，直接根据目录即可找到相关的页面。不必再从书的第一页到最后一页，一页一页的查找。</p>

<h2 id="toc_1">Lucene倒排索引原理</h2>

<p>Lucene是一个开放源代码的高性能的Java全文检索引擎工具包，不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。目的是为软件开发人员提供一个简单易用的工具包，以方便在目标系统中实现全文检索的功能，或者以此为基础建立起完整的全文检索引擎。</p>

<p>Lucene使用的是倒排文件索引结构。该结构及相应的生成算法如下：  　　</p>

<p>设有两篇文章1和2：</p>

<p>文章1的内容为：</p>

<pre><code>    Tom lives in Guangzhou, I live in Guangzhou too.
</code></pre>

<p>文章2的内容为：</p>

<pre><code>    He once lived in Shanghai.
</code></pre>

<h3 id="toc_2">取得关键词</h3>

<p>由于Lucene是基于关键词索引和查询的，首先我们要取得这两篇文章的关键词，通常我们需要如下处理措施： 　　</p>

<ul>
<li><p>我们现在有的是文章内容，即一个字符串，我们先要找出字符串中的所有单词，即<strong>分词</strong>。英文单词由于用空格分隔，比较好处理。中文单词间是连在一起的需要特殊的分词处理 　 　</p></li>
<li><p><strong>去掉没有意义的大众词汇</strong>。文章中的<code>in</code>, <code>once</code>, <code>too</code>等词没有什么实际意义，中文中的<code>的</code>、<code>是</code>等字通常也无具体含义，这些不代表概念的词可以过滤掉 　　</p></li>
<li><p>用户通常希望查<code>He</code>时能把含<code>he</code>，<code>HE</code>的文章也找出来，所以所有单词需要<strong>统一大小写</strong>。 　　</p></li>
<li><p><strong>单词的统一化</strong>。用户通常希望查<code>live</code>时能把含<code>lives</code>，<code>lived</code>的文章也找出来，所以需要把<code>lives</code>，<code>lived</code>还原成<code>live</code> 　　</p></li>
<li><p>文章中的<strong>标点符号</strong>通常不表示某种概念，也可以过滤掉 　　</p></li>
</ul>

<p>在Lucene中以上措施由<code>Analyzer</code>类完成。 经过上面处理后，</p>

<p>文章1的所有关键词为：</p>

<pre><code>    [tom] [live] [guangzhou] [i] [live] [guangzhou]
</code></pre>

<p>文章2的所有关键词为：</p>

<pre><code>    [he] [live] [shanghai]
</code></pre>

<h3 id="toc_3">建立倒排索引</h3>

<p>有了关键词后，我们就可以建立倒排索引了。上面的对应关系是：<code>文章号</code>对<code>文章中所有关键词</code>。倒排索引把这个关系倒过来，变成: <code>关键词</code>对<code>拥有该关键词的所有文章号</code>。</p>

<p>文章1，2经过倒排后变成 　　</p>

<pre><code>关键词            文章号 　　
guangzhou        1
he               2 
i                1 
live             1,2
shanghai         2
tom              1 
</code></pre>

<p><strong>通常仅知道关键词在哪些文章中出现还不够，我们还需要知道关键词在文章中出现次数和出现的位置</strong>，通常有两种位置：</p>

<ul>
<li><p>字符位置，即记录该词是文章中第几个字符（优点是关键词亮显时定位快）</p></li>
<li><p>关键词位置，即记录该词是文章中第几个关键词（优点是节约索引空间、词组（phase）查询快），lucene中记录的就是这种位置　　</p></li>
</ul>

<p>加上<code>出现频率</code>和<code>出现位置</code>信息后，我们的索引结构变为： 　　</p>

<pre><code>关键词               文章号[出现频率]            出现位置 
guangzhou           1[2]                      3, 6 　
he                  2[1]                      1
i                   1[1]                      4
live                1[2]                      2, 5
                    2[1]                      2 
shanghai            2[1]                      3
tom                 1[1]                      1 
</code></pre>

<p>以<code>live</code>这行为例我们说明一下该结构：<code>live</code>在<code>文章1</code>中出现了2次，<code>文章2</code>中出现了一次，它的出现位置为<code>2,5,2</code>这表示什么呢？我们需要结合文章号和出现频率来分析，<code>文章1</code>中出现了2次，那么<code>2,5</code>就表示<code>live</code>在<code>文章1</code>中出现的两个位置，<code>文章2</code>中出现了一次，剩下的<code>2</code>就表示<code>live</code>是<code>文章2</code>中第2个关键字。 　　</p>

<p>以上就是Lucene索引结构中最核心的部分。我们注意到关键字是按字符顺序排列的（Lucene没有使用B树结构），因此Lucene可以用二元搜索算法快速定位关键词。</p>

<h3 id="toc_4">实现</h3>

<p>实现时，Lucene将上面三列分别作为词典文件<code>（Term Dictionary）</code>、频率文件<code>(frequencies)</code>、位置文件<code>(positions)</code>保存。其中词典文件不仅保存有每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。 　　</p>

<p>Lucene中使用了<code>field</code>的概念，用于表达信息所在位置（如标题中，文章中，url中），在建索引中，该<code>field</code>信息也记录在词典文件中，每个关键词都有一个<code>field</code>信息(因为每个关键字一定属于一个或多个<code>field</code>)。</p>

<h3 id="toc_5">压缩算法</h3>

<p>为了减小索引文件的大小，Lucene对索引还使用了压缩技术。</p>

<p>首先，<strong>对词典文件中的关键词进行了压缩</strong>，关键词压缩为&lt;前缀长度，后缀&gt;</p>

<pre><code>    例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为&lt;3，语&gt;。
</code></pre>

<p>其次大量用到的是<strong>对数字的压缩</strong>，<strong>数字只保存与上一个值的差值</strong>（这样可以减小数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389（不压缩要用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）。</p>

<h3 id="toc_6">应用原因</h3>

<p>下面我们可以通过对该索引的查询来解释一下为什么要建立索引。 　　</p>

<p>假设要查询单词<code>live</code>，Lucene先对词典二元查找、找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。词典通常非常小，因而，整个过程的时间是毫秒级的。 　　</p>

<p>而用普通的顺序匹配算法，不建索引，而是对所有文章的内容进行字符串匹配，这个过程将会相当缓慢，当文章数目很大时，时间往往是无法忍受的。</p>

<h2 id="toc_7">TF-IDF及其算法</h2>

<p><code>TF-IDF（term frequency – inverted document frequency）</code>是一种用于资讯检索与资讯探勘的常用加权技术。<code>TF-IDF</code>是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<strong>字词的重要性随着它在文件中出现的次数成正比增加</strong>，但同时会<strong>随着它在语料库中出现的频率成反比下降</strong>。TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜寻引擎还会使用基于连结分析的评级方法，以确定文件在搜寻结果中出现的顺序。</p>

<h3 id="toc_8">原理</h3>

<p>在一份给定的文件里，<strong>词频 (term frequency, TF)</strong>指的是某一个给定的词语在该文件中出现的次数。<strong>这个数字通常会被归一化</strong>（分子一般小于分母区别于IDF），<strong>以防止它偏向长的文件</strong>。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否。）</p>

<p><strong>逆向文件频率 (inverse document frequency, IDF)</strong>是一个词语普遍重要性的度量。某一特定词语的IDF，可以<strong>由总文件数目除以包含该词语之文件的数目，再将得到的商取对数</strong>得到。</p>

<p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。</p>

<p><strong>TFIDF的主要思想是</strong>：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TFIDF实际上是：<code>TF * IDF</code>，TF词频(Term Frequency)，IDF反文档频率(Inverse Document Frequency)。<strong>TF</strong>表示词条在文档d中出现的频率（另一说：TF词频(Term Frequency)指的是<strong>某一个给定的词语在该文件中出现的次数</strong>）。<strong>IDF的主要思想是：如果包含词条t的文档越少，也就是n越小，IDF越大</strong>，则说明词条t具有很好的类别区分能力。如果某一类文档C中包含词条t的文档数为m，而其它类包含t的文档总数为k，显然所有包含t的文档数n=m+k，当m大的时候，n也大，按照IDF公式得到的IDF的值会小，就说明该词条t类别区分能力不强。（另一说：IDF反文档频率(Inverse Document Frequency)是指果包含词条的文档越少，IDF越大，则说明词条具有很好的类别区分能力。）但是实际上，如果一个词条在一个类的文档中频繁出现，则说明该词条能够很好代表这个类的文本的特征，这样的词条应该给它们赋予较高的权重，并选来作为该类文本的特征词以区别与其它类文档。这就是IDF的不足之处.</p>

<p>在一份给定的文件里，<strong>词频（term frequency，TF）</strong>指的是某一个给定的词语在该文件中出现的频率。这个数字是对<strong>词数(term count)</strong>的归一化，以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词数，而不管该词语重要与否。）</p>

<p>对于在某一特定文件 d<sub>j</sub> 里的词语  t<sub>i</sub>  来说，它的重要性可表示为：</p>

<p><img src="media/14587172862630/14587192129158.jpg" alt=""/></p>

<blockquote>
<p>以上式子中 <img src="media/14587172862630/14587192460077.jpg" alt=""/><br/>
是该词在文件<img src="media/14587172862630/14587192606951.jpg" alt=""/><br/>
中的出现次数，而分母则是在文件<img src="media/14587172862630/14587192606951.jpg" alt=""/>中所有字词的出现次数之和。</p>
</blockquote>

<p><strong>逆向文件频率（inverse document frequency，IDF）</strong>是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到：</p>

<p><img src="media/14587172862630/14587193987421.jpg" alt=""/></p>

<p>其中</p>

<blockquote>
<ul>
<li><strong>|D|</strong>：语料库中的文件总数</li>
<li><img src="media/14587172862630/14587194172144.jpg" alt=""/>
：包含词语 <img src="media/14587172862630/14587194452522.jpg" alt=""/>
的文件数目（即 <img src="media/14587172862630/14587194565514.jpg" alt=""/>
的文件数目）如果该词语不在语料库中，就会导致被除数为零，因此一般情况下使用 <img src="media/14587172862630/14587194771634.jpg" alt=""/></li>
</ul>
</blockquote>

<p>然后</p>

<p><img src="media/14587172862630/14587195313386.jpg" alt=""/></p>

<blockquote>
<p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。</p>
</blockquote>

<h3 id="toc_9">示例</h3>

<h4 id="toc_10">示例一</h4>

<p>假如一篇文件的总词语数是100个，而词语<code>母牛</code>出现了3次，那么<code>母牛</code>一词在该文件中的词频<strong>tf就是3/100=0.03</strong>。一个计算文件频率 (DF) 的方法是测定有多少份文件出现过<code>母牛</code>一词，然后除以文件集里包含的文件总数。所以，如果<code>母牛</code>一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是 <strong>log(10,000,000 / 1,000)=4</strong>。最后的TF-IDF的分数为0.03 * 4=0.12。</p>

<h4 id="toc_11">示例二</h4>

<p><strong>根据关键字k1,k2,k3进行搜索结果的相关性就变成 TF1 x IDF1 + TF2 x IDF2 + TF3 x IDF3</strong>。比如document1的term总量为1000，k1,k2,k3在document1出现的次数是100，200，50。包含了 k1, k2, k3的docuement总量分别是 1000， 10000，5000。document set的总量为10000。 TF1 = 100/1000 = 0.1 TF2 = 200/1000 = 0.2 TF3 = 50/1000 = 0.05 IDF1 = log(10000/1000) = log(10) = 2.3 IDF2 = log(10000/100000) = log(1) = 0; IDF3 = log(10000/5000) = log(2) = 0.69 这样关键字k1,k2,k3与docuement1的相关性= <code>0.1*2.3 + 0.2*0 + 0.05*0.69 = 0.2645</code>其中k1比k3的比重在document1要大，k2的比重是0.</p>

<h4 id="toc_12">示例三</h4>

<p>在某个一共有一千词的网页中<code>原子能</code>、<code>的</code>和<code>应用</code>分别出现了2次、35次和5次，那么它们的词频就分别是 0.002、0.035 和 0.005。 我们将这三个数相加，其和 0.042 就是相应网页和查询“原子能的应用” 相关性的一个简单的度量。概括地讲，如果一个查询包含关键词 w1,w2,...,wN, 它们在一篇特定网页中的词频分别是: TF1, TF2, ..., TFN。 （TF: term frequency)。 那么，这个查询和该网页的相关性就是:TF1 + TF2 + ... + TFN。</p>

<p>读者可能已经发现了又一个漏洞。在上面的例子中，词<code>的</code>站了总词频的 80% 以上，而它对确定网页的主题几乎没有用。我们称这种词叫<strong><code>应删除词（Stopwords)</code></strong>，也就是说在度量相关性是不应考虑它们的频率。在汉语中，应删除词还有“是”、“和”、“中”、“地”、“得”等等几十个。忽略这些应删除词后，上述网页的相似度就变成了0.007，其中“原子能”贡献了 0.002，“应用”贡献了 0.005。细心的读者可能还会发现另一个小的漏洞。在汉语中，“应用”是个很通用的词，而“原子能”是个很专业的词，后者在相关性排名中比前者重要。因此我们需要给汉语中的每一个词给一个权重，这个权重的设定必须满足下面两个条件：</p>

<blockquote>
<ol>
<li><p>一个词预测主题能力越强，权重就越大，反之，权重就越小。我们在网页中看到“原子能”这个词，或多或少地能了解网页的主题。我们看到“应用”一次，对主题基本上还是一无所知。因此，“原子能“的权重就应该比应用大。</p></li>
<li><p>应删除词的权重应该是零。</p></li>
</ol>
</blockquote>

<p>我们很容易发现，如果一个关键词只在很少的网页中出现，我们通过它就容易锁定搜索目标，它的权重也就应该大。反之如果一个词在大量网页中出现，我们看到它仍然不很清楚要找什么内容，因此它应该小。概括地讲，假定一个关键词 ｗ 在 Ｄｗ 个网页中出现过，那么 Ｄｗ 越大，ｗ的权重越小，反之亦然。在信息检索中，使用最多的权重是“逆文本频率指数” （Inverse document frequency 缩写为ＩＤＦ），它的公式为ｌｏｇ（Ｄ／Ｄｗ）其中Ｄ是全部网页数。比如，我们假定中文网页数是Ｄ＝１０亿，应删除词“的”在所有的网页中都出现，即Ｄｗ＝１０亿，那么它的ＩＤＦ＝log(10亿/10亿）= log (1) = ０。<strong>假如专用词<code>原子能</code>在两百万个网页中出现，即Ｄｗ＝２００万，则它的权重ＩＤＦ＝log(500) =6.2。又假定通用词<code>应用</code>，出现在五亿个网页中，它的权重ＩＤＦ = log(2)则只有 0.7。也就只说，在网页中找到一个<code>原子能</code>的比配相当于找到九个<code>应用</code>的匹配。</strong>利用 IDF，上述相关性计算个公式就由词频的简单求和变成了加权求和，即 <code>TF1*IDF1 +　TF2*IDF2 ＋... + TFN*IDFN</code>。在上面的例子中，该网页和“原子能的应用”的相关性为 0.0161，其中“原子能”贡献了 0.0126，而“应用”只贡献了0.0035。这个比例和我们的直觉比较一致了。</p>

<h3 id="toc_13">附录：ElasticSearch相关查询</h3>

<h5 id="toc_14">文档内容</h5>

<pre><code>curl -XGET &#39;172.168.5.110:9200/logstash-wap-2016.03.22/wap/AVOcKIIFPPR76qlEVfH2?pretty&#39;
</code></pre>

<p>结果</p>

<p>{<br/>
  <q>_index</q> : <q>logstash-wap-2016.03.22</q>,<br/>
  <q>_type</q> : <q>wap</q>,<br/>
  <q>_id</q> : <q>AVOcKIIFPPR76qlEVfH2</q>,<br/>
  <q>_version</q> : 1,<br/>
  <q>found</q> : true,<br/>
  <q>_source</q> : {<br/>
    <q>message</q> : <q>2016-03-22 10:30:12 - [ INFO ] [appName: wap] 172.168.5.224 - [cn.hao24.mobile.aop.RequestAOP] Beginning method: cn.hao24.mobile.controller.goods.GoodsController.getGoodsExtendDescAPP\tRequest end. This request cost [26 ms] time. =&gt; [SID: MasmqDCe1iFiullGvJWHPe8VIfzIJjeZk] [CustId: ] [CustIp: ] [OsVersion: ] [PhoneModel: ] V1</q>,<br/>
    <q>@version</q> : <q>1</q>,<br/>
    <q>@timestamp</q> : <q>2016-03-22T02:30:13.287Z</q>,<br/>
    <q>host</q> : <q>template-CentOS6.5</q>,<br/>
    <q>path</q> : <q>/hao24/logs/admin-log.log</q>,<br/>
    <q>timestamp</q> : <q>2016-03-22 10:30:12</q>,<br/>
    <q>loglevel</q> : <q>INFO</q>,<br/>
    <q>appName</q> : <q>wap</q>,<br/>
    <q>serverip</q> : <q>172.168.5.224</q>,<br/>
    <q>class</q> : <q>cn.hao24.mobile.aop</q>,<br/>
    <q>method</q> : <q>RequestAOP</q>,<br/>
    <q>status</q> : <q>Beginning method: cn.hao24.mobile.controller.goods.GoodsController.getGoodsExtendDescAPP\tRequest end. This request cost [26 ms] time.</q>,<br/>
    <q>sid</q> : <q>MasmqDCe1iFiullGvJWHPe8VIfzIJjeZk</q><br/>
  }<br/>
}</p>

<h5 id="toc_15">查看Status字段分词</h5>

<pre><code>curl -XPOST &#39;172.168.5.110:9200/logstash-wap-2016.03.22/_analyze?pretty&#39; -d &#39;
{
    &quot;text&quot;: &quot;Beginning method: cn.hao24.mobile.controller.category.CategoryController.listAjax  Request end. This request cost [268 ms] time.&quot;
}&#39;
</code></pre>

<h5 id="toc_16">结果</h5>

<pre><code>{
  &quot;tokens&quot; : [ {
    &quot;token&quot; : &quot;beginning&quot;,
    &quot;start_offset&quot; : 0,
    &quot;end_offset&quot; : 9,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 0
  }, {
    &quot;token&quot; : &quot;method&quot;,
    &quot;start_offset&quot; : 10,
    &quot;end_offset&quot; : 16,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 1
  }, {
    &quot;token&quot; : &quot;cn.hao24&quot;,
    &quot;start_offset&quot; : 18,
    &quot;end_offset&quot; : 26,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 2
  }, {
    &quot;token&quot; : &quot;mobile.controller.category.categorycontroller.listajaxrequest&quot;,
    &quot;start_offset&quot; : 27,
    &quot;end_offset&quot; : 88,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 3
  }, {
    &quot;token&quot; : &quot;end&quot;,
    &quot;start_offset&quot; : 89,
    &quot;end_offset&quot; : 92,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 4
  }, {
    &quot;token&quot; : &quot;this&quot;,
    &quot;start_offset&quot; : 94,
    &quot;end_offset&quot; : 98,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 5
  }, {
    &quot;token&quot; : &quot;request&quot;,
    &quot;start_offset&quot; : 99,
    &quot;end_offset&quot; : 106,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 6
  }, {
    &quot;token&quot; : &quot;cost&quot;,
    &quot;start_offset&quot; : 107,
    &quot;end_offset&quot; : 111,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 7
  }, {
    &quot;token&quot; : &quot;268&quot;,
    &quot;start_offset&quot; : 113,
    &quot;end_offset&quot; : 116,
    &quot;type&quot; : &quot;&lt;NUM&gt;&quot;,
    &quot;position&quot; : 8
  }, {
    &quot;token&quot; : &quot;ms&quot;,
    &quot;start_offset&quot; : 117,
    &quot;end_offset&quot; : 119,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 9
  }, {
    &quot;token&quot; : &quot;time&quot;,
    &quot;start_offset&quot; : 121,
    &quot;end_offset&quot; : 125,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 10
  } ]
}
</code></pre>

<h5 id="toc_17">TF-IDF分值</h5>

<pre><code>curl -XGET &#39;172.168.5.110:9200/logstash-wap-2016.03.22/wap/AVOcKIIFPPR76qlEVfH2/_explain?pretty&#39; -d &#39;{
      &quot;query&quot; : {
        &quot;term&quot; : { &quot;status&quot; : &quot;request&quot; }
      }
}&#39;
</code></pre>

<h5 id="toc_18">结果</h5>

<p>{<br/>
  <q>_index</q> : <q>logstash-wap-2016.03.22</q>,<br/>
  <q>_type</q> : <q>wap</q>,<br/>
  <q>_id</q> : <q>AVOcKIIFPPR76qlEVfH2</q>,<br/>
  <q>matched</q> : true,<br/>
  <q>explanation</q> : {<br/>
    <q>value</q> : 2.5711107,<br/>
    <q>description</q> : <q>sum of:</q>,<br/>
    <q>details</q> : [ {<br/>
      <q>value</q> : 2.5711107,<br/>
      <q>description</q> : <q>weight(status:request in 31) [PerFieldSimilarity], result of:</q>,<br/>
      <q>details</q> : [ {<br/>
        <q>value</q> : <mark><strong>2.5711107</strong></mark>,<br/>
        <q>description</q> : <q>fieldWeight in 31, product of:</q>,<br/>
        <q>details</q> : [ {<br/>
          <mark><q>value</q> : 1.4142135,</mark><br/>
          <q>description</q> : <q><mark><strong>tf</strong></mark>(freq=2.0), with freq of:</q>,<br/>
          <q>details</q> : [ {<br/>
            <q>value</q> : 2.0,<br/>
            <q>description</q> : <q>termFreq=2.0</q>,<br/>
            <q>details</q> : [ ]<br/>
          } ]<br/>
        }, {<br/>
          <mark><q>value</q> : 1.8180498,</mark><br/>
          <q>description</q> : <q><mark><strong>idf</strong></mark>(docFreq=439561, maxDocs=996081)</q>,<br/>
          <q>details</q> : [ ]<br/>
        }, {<br/>
          <q>value</q> : 1.0,<br/>
          <q>description</q> : <q>fieldNorm(doc=31)</q>,<br/>
          <q>details</q> : [ ]<br/>
        } ]<br/>
      } ]<br/>
    }, {<br/>
      <q>value</q> : 0.0,<br/>
      <q>description</q> : <q>match on required clause, product of:</q>,<br/>
      <q>details</q> : [ {<br/>
        <q>value</q> : 0.0,<br/>
        <q>description</q> : <q># clause</q>,<br/>
        <q>details</q> : [ ]<br/>
      }, {<br/>
        <q>value</q> : 0.55003995,<br/>
        <q>description</q> : <q>_type:wap, product of:</q>,<br/>
        <q>details</q> : [ {<br/>
          <q>value</q> : 1.0,<br/>
          <q>description</q> : <q>boost</q>,<br/>
          <q>details</q> : [ ]<br/>
        }, {<br/>
          <q>value</q> : 0.55003995,<br/>
          <q>description</q> : <q>queryNorm</q>,<br/>
          <q>details</q> : [ ]<br/>
        } ]<br/>
      } ]<br/>
    } ]<br/>
  }<br/>
}</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高性能MySQL - Schema与数据类型优化]]></title>
    <link href="http://nathanchen.github.io/14585676478158.html"/>
    <updated>2016-03-21T21:40:47+08:00</updated>
    <id>http://nathanchen.github.io/14585676478158.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">选择优化的数据类型</h3>

<h4 id="toc_1">字符串类型</h4>

<h5 id="toc_2">VARCHAR</h5>

<p><code>VARCHAR</code>类型用于存储可变长字符串。它比定长类型更节省空间，因为它仅使用必要的空间。</p>

<p><code>VARCHAR</code>需要使用1或2个额外字节记录字符串的长度：如果列的最大长度小于或等于255字节，则只使用1个字节表示；否则使用2个字节。</p>

<h5 id="toc_3">CHAR</h5>

<p><code>CHAR</code>类型是定长的：<code>MySQL</code>总是根据定义的字符串长度分配足够的空间。当存储<code>CHAR</code>值时，<code>MySQL</code>会删除所有的末尾空格。</p>

<p><code>CHAR</code>适合存储很短的字符串，或者所有值都接近同一个长度。；对于经常变更的数据，<code>CHAR</code>也比<code>VARCHAR</code>更好，因为定长的<code>CHAR</code>类型不容易产生碎片。对于非常短的列，<code>CHAR</code>比<code>VARCHAR</code>在存储空间上也更有效率。</p>

<h4 id="toc_4">日期和时间类型</h4>

<p>除了特殊情况，通常应该尽量使用<code>TIMESTAMP</code>，因为它比<code>DATETIME</code>空间效率更高。</p>

<h4 id="toc_5">特殊类型数据</h4>

<p>人们经常使用<code>VARCHAR(15)</code>列来存储<code>IP</code>地址。然而，它们实际上是32位无符号整数，不是字符串。用小数点将地址分成四段的表示方法只是为了让人们阅读容易。所以应该用无符号整数存储<code>IP</code>地址。</p>

<h3 id="toc_6">范式和反范式</h3>

<h4 id="toc_7">范式的优点和缺点</h4>

<p><strong>范式化通常能够带来的好处</strong>：</p>

<ul>
<li>范式化的更新操作通常比反范式化要快</li>
<li>当数据较好地范式化时，就只有很少或者没有重复数据，所以只需要修改更少的数据</li>
<li>范式化的表通常更小，可以更好地放在内存里，所以执行操作会更快</li>
<li>很少有多余的数据意味着检索列表数据时更少需要<code>DISTINCT</code>或者<code>GROUP BY</code>语句。</li>
</ul>

<p><strong>范式化设计的<code>schema</code>的缺点是通常需要关联</strong>。稍微复杂一些的查询语句在符合范式的<code>schema</code>上都可能需要至少一次关联，也许更多。</p>

<h4 id="toc_8">反范式的优点和缺点</h4>

<p>反范式化的<code>schema</code>因为所有数据都在一张表中，可以很好地避免关联。</p>

<p>如果不需要关联表，则对大部分查询最差的情况——即使表没有使用索引——是全表扫描。当数据比内存大时，这可能比关联要快得多，因为这样避免了随机I/O。</p>

<blockquote>
<p>混用范式化和反范式化</p>
</blockquote>

<h3 id="toc_9">加快ALTER TABLE操作的速度</h3>

<p>不是所有的<code>ALTER TABLE</code>操作都会引起表重建。例如，有两种方法可以改变或者删除一个列的默认值（一种方法很快，另一种则很慢）。</p>

<p>假如要修改电影的默认租赁期限，从三天改到五天。下面是很慢的方式：</p>

<pre><code class="language-sql">ALTER TABLE sakila.film
MODIFY COLUMN rental_duration TINYINT(3) NOT NULL DEFAULT 5;
</code></pre>

<p><code>SHOW STATUS</code>显示这个语句做了1000次读和1000次插入操作。换句话说，它拷贝了整张表到一张新表，甚至列的类型、大小和可否为<code>NULL</code>属性都没改变。</p>

<p>另外一种方法是通过<code>ALTER COLUMN</code>操作来改变列的默认值：</p>

<pre><code class="language-sql">ALTER TABLE sakila.film
ALTER COLUMN rental_duration SET DEFAULT 5;
</code></pre>

<p>这个语句会直接修改<code>.frm</code>文件而不涉及表数据。所以，这个操作是非常快的。</p>

<h4 id="toc_10">只修改.frm文件</h4>

<p>下面这些操作是有可能不需要重建表的：</p>

<ul>
<li>移除（不是增加）一个列的<code>AUTO_INCREMENT</code>属性</li>
<li>增加、移除，或更改<code>ENUM</code>和<code>SET</code>常量。如果移除的是已经有行数据用到其值的常量，查询将会返回一个空字符串值</li>
</ul>

<p>基本的技术是为想要的表结构创建一个新的<code>.frm</code>文件，然后用它替换掉已经存在的那张表的<code>.frm</code>文件，像下面这样：</p>

<ul>
<li>创建一张有相同结构的空表，并进行所需要的修改</li>
<li>执行<code>FLUSH TABLES WITH READ LOCK</code>。这将会关闭所有正在使用的表，并且禁止任何表被打开。</li>
<li>交换<code>.frm</code>文件</li>
<li>执行<code>UNLOCK TABLES</code>来释放第二步的读锁</li>
</ul>

<h4 id="toc_11">快速创建<code>MyISAM</code>索引</h4>

<p>为了高效地载入数据到MyISAM表中，有一个常用的技巧是先禁用、载入数据，然后重新启用索引：</p>

<pre><code>ALTER TABLE test.load_data DISABLE KEYS;
-- load the data
ALTER TABLE test.load_data ENABLE KEYS;
</code></pre>

<p>这个技巧能够发挥作用，是因为构建索引的工作被延迟到数据完全载入以后，这个时候已经可以通过排序来构建索引了。这样做会快很多，并且使得索引树的碎片更少、更紧凑。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高性能MySQL - MySQL架构与历史]]></title>
    <link href="http://nathanchen.github.io/14585518429633.html"/>
    <updated>2016-03-21T17:17:22+08:00</updated>
    <id>http://nathanchen.github.io/14585518429633.html</id>
    <content type="html"><![CDATA[
<h4 id="toc_0">连接管理与安全性</h4>

<p>每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个CPU核心或者CPU中运行。服务器会负责缓存线程，因此不需要为每一个新建的连接创建或者销魂线程。</p>

<h4 id="toc_1">优化与执行</h4>

<p>MySQL会解析查询，并 创建内部数据结构（解析树），然后对其进行各种优化，包括重写查询、决定表的读取顺序，以及选择合适的索引等。用户可以通过特殊的关键字提示优化器，影响它的决策过程。也可以请求优化器解释优化过程的各个因素，使用户可以知道服务器是如何进行优化决策的，并提供一个参考基准，便于用户重构查询和schema、修改相关配置。</p>

<p>对于SELECT语句，在解析查询之前，服务器会先检查查询缓存（Query Cache），如果能够在其中找到对应的查询，服务器就不必再执行查询解析、优化和执行的整个过程，而是直接返回查询缓存中的结果集。</p>

<h4 id="toc_2">读写锁</h4>

<p>读锁是共享的，或者说是相互不阻塞的。多个客户在同一时刻可以同时读取统一资源，而互不干扰。</p>

<p>写锁是排他的，也就是说一个写锁会阻塞其他的写锁和读锁。</p>

<h4 id="toc_3">锁粒度</h4>

<p>一种提高共享资源并发性的方式就是让锁定对象更有选择性。尽量只锁定需要修改的部分数据，而不是所有的资源。更理想的方式是，只对会修改的数据片进行精确的锁定。任何时候，在给定的资源上，锁定的数据量越少，则系统的并发程度越高，只要相互之间不发生冲突即可。</p>

<h5 id="toc_4">表锁</h5>

<p>MySQL最基本的锁策略，并且是开销最小的策略。</p>

<p>一个用户在对表进行写操作（插入、删除、更新等）前，需要先获得写锁，这会阻塞其他用户对该表的所有读写操作。只有没有写锁时，其他读取的用户才能获得读锁，读锁之间是不相互阻塞的。</p>

<h5 id="toc_5">行级锁</h5>

<p>最大程度地支持并发处理，同时也带来了最大的锁开销。</p>

<h4 id="toc_6">死锁</h4>

<p>InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。</p>

<p>死锁发生以后，只有部分或者完全回滚其中一个事务。</p>

<h4 id="toc_7">事务日志</h4>

<p>使用事务日志，存储引擎在修改表的数据时，只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到硬盘。</p>

<p>事务日志采用的是追加的方式，因此写日志的操作是磁盘上的一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方法相对来说要快得多。</p>

<p>事务日志持久以后，内存中被修改的数据在后台可以慢慢地刷回到硬盘。</p>

<p>如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。</p>

<h4 id="toc_8">MySQL的事务</h4>

<p>MySQL默认采用自动提交模式。</p>

<h5 id="toc_9">隐式和显式锁定</h5>

<p>InnoDB采用的是两阶段锁定协议（two-phase locking protocol）。在事务执行过程中，随时都可以执行锁定，锁只有在执行COMMIT或者ROLLBACK的时候才会释放，并且所有的锁是在同一时刻被释放。</p>

<h4 id="toc_10">多版本并发控制</h4>

<p>InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的过期时间（或删除时间）。当然存储的并不是实际的时间值，而是系统版本号。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。</p>

<p>MVCC只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。其他两个隔离级别都和MVCC不兼容。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[虚拟机类加载机制]]></title>
    <link href="http://nathanchen.github.io/14585496303082.html"/>
    <updated>2016-03-21T16:40:30+08:00</updated>
    <id>http://nathanchen.github.io/14585496303082.html</id>
    <content type="html"><![CDATA[
<p>虚拟机把描述类的数据从Class文件加载到内存，并堆数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。</p>

<h3 id="toc_0">类加载的时机</h3>

<p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括了：加载、验证、准备、解析、初始化、使用和卸载七个阶段。其中验证、准备和解析三个部分统称为连接。</p>

<p>虚拟机规范严格规定了有且只有四种情况必须立即对类进行初始化：</p>

<ul>
<li>遇到new、getstatic、putstatic和invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段的时候，以及调用一个类的静态方法的时候</li>
<li>使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化</li>
</ul>

<p>194/412</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to Data Concurrency and Consistency in a Multiuser Environment]]></title>
    <link href="http://nathanchen.github.io/14585418716089.html"/>
    <updated>2016-03-21T14:31:11+08:00</updated>
    <id>http://nathanchen.github.io/14585418716089.html</id>
    <content type="html"><![CDATA[
<p>The <strong>serializable</strong> mode of transaction behavior tries to ensure that transactions run in such a way that they appear to be executed one at a time, or serially, rather than concurrently.</p>

<ul>
<li>Dirty reads: A transaction reads data that has been written by another transaction that has not been committed yet</li>
<li>Nonrepeatable reads: A transaction re-reads data it has previously read and finds that another committed transaction has <strong>modified or deleted the data</strong></li>
<li>Phantom reads: A transaction re-runs a query returning a set of rows that satisfies a search condition and finds that another committed transaction has <strong>inserted additional rows</strong> that satisfy the condition.</li>
</ul>

<blockquote>
<p>Oracle offers the read committed and serializable isolation levels, as well as a read-only mode. <strong>Read committed is the default</strong>.</p>
</blockquote>

<h4 id="toc_0">How Oracle Manages Data Concurrency and Consistency</h4>

<h5 id="toc_1">Multiversion Concurrency Control</h5>

<p>Oracle automatically provides read consistency to a query so that <strong>all the data that the query sees comes from a single point in time</strong> (statement-level read consistency). Orable can also provide read consistency to all of the queries in a transaction (transaction-level read consistency).</p>

<p>Oracle uses the information maintained in its <strong>rollback segments</strong> to provide these consistent views. <strong>The rollback segments contain the old values of data that have been changed by uncommitted or recently committed transactions</strong>.</p>

<h5 id="toc_2">Statement-Level Read Consistency</h5>

<p>Oracle always enforces statement-level read consistency. <strong>This gurantees that all the data returned by a single query comes from a single point in time - the time that the query begin</strong>.</p>

<p>As query execution proceesds, only data committed before the query began is visible to the query. The query does not see changes committed after statement execution begins.</p>

<h5 id="toc_3">Transaction-Level Read Consistency</h5>

<p>Oracle also offers the option of enforcing transaction-level read consistency. When a transaction runs in serializable mode, all data accesses reflect the state of the database as of the time the transaction began.</p>

<p>This mean that the data seen by all queries within the same transaction is consistent with respect to a single point in time, <strong>except that queries mde by a serializable transaction do see changes mode by the transaction itself</strong>.</p>

<p>Transactional-level read consistency produces repeatable reads and does not expose a query to phantoms.</p>

<h4 id="toc_4">Comparison of Read Committed and Seriablizable Isolation</h4>

<h5 id="toc_5">Row-Level Locking</h5>

<p>Both read committed and serializable transactions use row-level locking, and both will <strong>wait if they try to change a row updated by an uncommitted concurrent transaction</strong>. The second transaction that tries to update a given row waits for the other transaction to commit or undo and release its lock. If that other transaction rolls back, the waiting transaction, regardless of its isolation mode, can proceed to change the previously locked row as if the other transaction had not existed.</p>

<h5 id="toc_6">Referential Integrity</h5>

<p>Because Orable does not use read locks in either read-consistent or seriablizable transactions. data read by one transaction can be overwritten by another. Transaction that perform database consistency checks at the application level cannot assume that the data they read will remain unchanged during the execution of the transaction even though such changes are not visible to the transaction.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[]]></title>
    <link href="http://nathanchen.github.io/14584833737979.html"/>
    <updated>2016-03-20T22:16:13+08:00</updated>
    <id>http://nathanchen.github.io/14584833737979.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">实验一</h2>

<ul>
<li>两次读写操作</li>
</ul>

<pre><code class="language-java">for (int i = 0; i &lt; 2; i++)
{
    try
    {
        Thread.sleep(5000);
    }
    catch (InterruptedException e)
    {
        e.printStackTrace();
    }
    List&lt;WechatUser&gt; wechatUserList = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUserList.size());
    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
    try
    {
        Thread.sleep(1000);
    }
    catch (InterruptedException e)
    {
        e.printStackTrace();
    }

}   
</code></pre>

<h3 id="toc_1">结果：</h3>

<p>2016-03-20 22:13:30 [org.springframework.transaction.annotation.AnnotationTransactionAttributeSource]-[DEBUG] Adding transactional method &#39;WechatRegistServiceImpl.insertUser&#39; with attribute: PROPAGATION_REQUIRED,<mark><strong>ISOLATION_SERIALIZABLE</strong></mark>; &#39;&#39;<br/>
2016-03-20 22:13:30 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Acquired Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] for JDBC transaction<br/>
2016-03-20 22:13:30 [org.springframework.jdbc.datasource.DataSourceUtils]-[DEBUG] <mark><strong>Changing isolation level</strong></mark> of JDBC Connection [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] to <mark><strong>8</strong></mark><br/>
2016-03-20 22:13:30 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[WARN] satart<br/>
2016-03-20 22:13:31 [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping]-[DEBUG] Looking up handler method for path <mark><strong>/insert.html</strong></mark><br/>
2016-03-20 22:13:31 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Acquired Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] for JDBC transaction<br/>
2016-03-20 22:13:35 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Creating a new SqlSession</strong></mark><br/>
2016-03-20 22:13:35 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Registering transaction synchronization for SqlSession <mark><strong>[org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]</strong></mark><br/>
2016-03-20 22:13:35 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER <br/>
2016-03-20 22:13:35 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]<br/>
2016-03-20 22:13:35 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：0    用户数量：0</strong></mark><br/>
2016-03-20 22:13:35 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> <mark><strong>[org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]</strong></mark> from current transaction<br/>
2016-03-20 22:13:35 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  <mark><strong>Preparing: insert</strong></mark> into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) <br/>
2016-03-20 22:13:35 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]<br/>
2016-03-20 22:13:35 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   0 条</strong></mark><br/>
2016-03-20 22:13:36 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Creating a new SqlSession</strong></mark><br/>
2016-03-20 22:13:36 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Registering transaction synchronization for SqlSession <mark><strong>[org.apache.ibatis.session.defaults.DefaultSqlSession@32358420]</strong></mark><br/>
2016-03-20 22:13:36 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER <br/>
2016-03-20 22:13:41 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> <mark><strong>[org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]</strong></mark> from current transaction<br/>
2016-03-20 22:13:41 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER <br/>
2016-03-20 22:13:41 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]<br/>
2016-03-20 22:13:41 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：1    用户数量：1</strong></mark><br/>
2016-03-20 22:13:41 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> <mark><strong>[org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]</strong></mark> from current transaction<br/>
2016-03-20 22:13:41 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  <mark><strong>Preparing: insert</strong></mark> into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) <br/>
2016-03-20 22:13:41 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]<br/>
2016-03-20 22:13:41 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   1 条</strong></mark><br/>
2016-03-20 22:13:42 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Transaction synchronization committing SqlSession</strong></mark> <mark><strong>[org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]</strong></mark><br/>
2016-03-20 22:13:42 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Transaction synchronization deregistering SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]<br/>
2016-03-20 22:13:42 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Transaction synchronization closing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@4fb26a36]<br/>
2016-03-20 22:13:42 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Initiating transaction commit</strong></mark><br/>
2016-03-20 22:13:42 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] Committing JDBC transaction on Connection [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver]<br/>
2016-03-20 22:13:42 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] &lt;==      <mark><strong>Total: 2</strong></mark><br/>
2016-03-20 22:13:42 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession <mark><strong>[org.apache.ibatis.session.defaults.DefaultSqlSession@32358420]</strong></mark><br/>
2016-03-20 22:13:42 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：0    用户数量：2</strong></mark><br/>
2016-03-20 22:13:42 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@32358420] from current transaction<br/>
2016-03-20 22:13:42 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  Preparing: insert into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) <br/>
2016-03-20 22:13:42 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@32358420]<br/>
2016-03-20 22:13:42 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------写入数据第   0 条<br/>
2016-03-20 22:13:42 [org.springframework.jdbc.datasource.DataSourceUtils]-[DEBUG] <mark><strong>Resetting isolation level</strong></mark> of JDBC Connection [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] to 4<br/>
2016-03-20 22:13:42 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Releasing JDBC Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] after transaction<br/>
2016-03-20 22:13:42 [org.springframework.web.servlet.DispatcherServlet]-[DEBUG] Null ModelAndView returned to DispatcherServlet with name &#39;spring&#39;: assuming HandlerAdapter completed request handling<br/>
2016-03-20 22:13:42 [org.springframework.web.servlet.DispatcherServlet]-[DEBUG] Successfully completed request<br/>
2016-03-20 22:13:48 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@32358420] from current transaction</p>

<p>...</p>

<p>2016-03-20 22:13:49 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] Committing JDBC transaction on Connection [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver]<br/>
2016-03-20 22:13:49 [org.springframework.jdbc.datasource.DataSourceUtils]-[DEBUG] <mark><strong>Resetting isolation level of JDBC Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] to 4<br/>
2016-03-20 22:13:49 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Releasing JDBC Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] after transaction</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux常用命令]]></title>
    <link href="http://nathanchen.github.io/14584714230833.html"/>
    <updated>2016-03-20T18:57:03+08:00</updated>
    <id>http://nathanchen.github.io/14584714230833.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">free</h3>

<pre><code>                   1      2        3       4      5         6
1              total     used     free  shared  buffers  cached
2 Mem:      24677460 23276064  1401396       0  870540 12084008
3 -/+ buffers/cache: 10321516  14355944
4 Swap:     25151484    224188  24927296
</code></pre>

<p><code>buffers</code>是用于存放要输出到<code>disk</code>（块设备）的数据的，<br/>
<code>cached</code>是存放从<code>disk</code>上读出的数据</p>

<p><code>-buffers/cache</code>，表示一个应用程序认为系统被用掉多少内存；<br/>
<code>+buffers/cache</code>，表示一个应用程序认为系统还有多少内存；</p>

<p>在linux中有这么一种思想，<strong>内存不用白不用</strong>，因此它尽可能的<code>cached</code>和<code>buffer</code>一些数据，以方便下次使用。但实际上这些内存也是可以立刻拿来使用的。<br/>
因为被系统<code>cached</code>和<code>buffer</code>占用的内存可以被快速回收，所以通常<code>FO[3][3]</code>比<code>FO[2][3]</code>会大很多</p>

<pre><code>FO[2][1] = FO[2][2] + FO[2][3]
FO[3][2] = FO[2][2] - FO[2][5] - FO[2][6]
FO[3][3] = FO[2][3] + FO[2][5] + FO[2][6]
</code></pre>

<h3 id="toc_1">du -h --max-depth=1</h3>

<p>查看硬盘占用情况</p>

<p><code>--max-depth=1</code>下一级目录</p>

<h3 id="toc_2">df -h</h3>

<p>查看整机硬盘使用情况</p>

<h3 id="toc_3">df -hl</h3>

<p>查看整机硬盘使用情况（G, M, K为单位）</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据库事务实验 (ISOLATION_DEFAULT)]]></title>
    <link href="http://nathanchen.github.io/14582743812545.html"/>
    <updated>2016-03-18T12:13:01+08:00</updated>
    <id>http://nathanchen.github.io/14582743812545.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>ISOLATION_DEFAULT: Use the default isolation level of the underlying datastore.</p>

<p>The default isolation level in MySQL’s InnoDB is <strong>REPEATABLE READ</strong>.</p>
</blockquote>

<h2 id="toc_0">实验一</h2>

<ul>
<li><code>@transaction</code>标签在class上</li>
<li><code>mapper xml</code>没有配置<code>flushCache</code>以及<code>useCache</code></li>
<li>初始表数据为空</li>
</ul>

<h3 id="toc_1">先执行<code>insert</code>20次，每次休眠1秒</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_2">再执行<code>select</code>30次，每次休眠1秒</h3>

<pre><code class="language-java">    List&lt;WechatUser&gt; wechatUser = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUser.size());
</code></pre>

<h3 id="toc_3">结果：</h3>

<p>2016-03-18 12:49:39 [org.springframework.transaction.annotation.AnnotationTransactionAttributeSource]-[DEBUG] <mark><strong>Adding transactional method</strong></mark> &#39;WechatRegistServiceImpl.insertUser&#39; with attribute: <mark><strong>PROPAGATION_REQUIRED</strong></mark>,<mark><strong>ISOLATION_DEFAULT</strong></mark>; &#39;&#39;</p>

<p>2016-03-18 12:49:39 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Creating new transaction</strong></mark> with name [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl.insertUser]: <mark><strong>PROPAGATION_REQUIRED</strong></mark>,<mark><strong>ISOLATION_DEFAULT</strong></mark>; &#39;&#39;</p>

<p>2016-03-18 12:49:40 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Acquired Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] <mark><strong>for JDBC transaction</strong></mark></p>

<p>2016-03-18 12:49:40 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Switching JDBC Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] <mark><strong>to manual commit</strong></mark></p>

<p>2016-03-18 12:49:40 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Creating a new SqlSession</strong></mark></p>

<p>2016-03-18 12:49:40 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Registering transaction synchronization for SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353]</p>

<p>2016-03-18 12:49:40 [org.mybatis.spring.transaction.SpringManagedTransaction]-[DEBUG] JDBC Connection [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] <mark><strong>will be managed by Spring</strong></mark></p>

<p>2016-03-18 12:49:40 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  <mark><strong>Preparing: insert</strong></mark> into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) </p>

<p>2016-03-18 12:49:40 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt; Parameters: 1234567890(String), insert(String), null</p>

<p>2016-03-18 12:49:40 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] &lt;==    Updates: 1</p>

<p>2016-03-18 12:49:40 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353]</p>

<p>2016-03-18 12:49:40 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   0 条</strong></mark></p>

<p>2016-03-18 12:49:41 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353] <mark><strong>from current transaction</strong></mark></p>

<p>2016-03-18 12:49:41 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  Preparing: insert into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) </p>

<p>2016-03-18 12:49:41 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt; Parameters: 1234567890(String), insert(String), null</p>

<p>2016-03-18 12:49:41 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] &lt;==    Updates: 1</p>

<p>2016-03-18 12:49:41 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> <br/>
[org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353]<br/>
2016-03-18 12:49:41 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   1 条</strong></mark></p>

<p>...</p>

<p>2016-03-18 12:49:43 [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping]-[DEBUG] Looking up handler method for path /<mark><strong>select.html</strong></mark></p>

<p>2016-03-18 12:49:43 [org.springframework.transaction.annotation.AnnotationTransactionAttributeSource]-[DEBUG] <mark><strong>Adding transactional method</strong></mark> &#39;WechatRegistServiceImpl.selectUser&#39; with attribute: <mark><strong>PROPAGATION_REQUIRED</strong></mark>,<mark><strong>ISOLATION_DEFAULT</strong></mark>; &#39;&#39;</p>

<p>2016-03-18 12:49:43 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Creating new transaction</strong></mark> with name [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl.selectUser]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT; &#39;&#39;</p>

<p>2016-03-18 12:49:43 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Acquired Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] <mark><strong>for JDBC transaction</strong></mark></p>

<p>2016-03-18 12:49:43 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Switching JDBC Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] <mark><strong>to manual commit</strong></mark></p>

<p>2016-03-18 12:49:43 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Creating a new SqlSession</strong></mark></p>

<p>2016-03-18 12:49:43 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Registering transaction synchronization for SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d]</p>

<p>2016-03-18 12:49:43 [org.mybatis.spring.transaction.SpringManagedTransaction]-[DEBUG] <mark><strong>JDBC Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] <mark><strong>will be managed by Spring</strong></mark></p>

<p>2016-03-18 12:49:43 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER </p>

<p>2016-03-18 12:49:43 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt; Parameters: </p>

<p>2016-03-18 12:49:43 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] &lt;==      Total: 0</p>

<p>2016-03-18 12:49:43 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> <br/>
[org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d]</p>

<p>2016-03-18 12:49:43 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：0    用户数量：0</strong></mark></p>

<p>2016-03-18 12:49:44 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353] from current transaction</p>

<p>2016-03-18 12:49:44 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  <mark><strong>Preparing: insert</strong></mark> into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) </p>

<p>...</p>

<p>2016-03-18 12:49:44 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d] <mark><strong>from current transaction</strong></mark></p>

<p>2016-03-18 12:49:44 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d]</p>

<p>2016-03-18 12:49:44 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：1    用户数量：0</strong></mark></p>

<p>...</p>

<p>2016-03-18 12:50:00 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Transaction synchronization committing SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353]</p>

<p>2016-03-18 12:50:00 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Transaction synchronization deregistering SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353]</p>

<p>2016-03-18 12:50:00 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Transaction synchronization closing SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@21e3b353]</p>

<p>2016-03-18 12:50:00 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Initiating transaction commit</strong></mark></p>

<p>2016-03-18 12:50:00 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Committing JDBC transaction on Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver]</p>

<p>2016-03-18 12:50:00 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Releasing JDBC Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] after transaction</p>

<p>2016-03-18 12:50:00 [org.springframework.jdbc.datasource.DataSourceUtils]-[DEBUG] <mark><strong>Returning JDBC Connection to DataSource</strong></mark></p>

<p>2016-03-18 12:50:11 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d] <mark><strong>from current transaction</strong></mark></p>

<p>2016-03-18 12:50:11 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d]</p>

<p>2016-03-18 12:50:11 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：28    用户数量：0</strong></mark></p>

<p>2016-03-18 12:50:12 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Fetched SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d] <mark><strong>from current transaction</strong></mark></p>

<p>2016-03-18 12:50:12 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Releasing transactional SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@7a50701d]</p>

<p>2016-03-18 12:50:12 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：29    用户数量：0</strong></mark></p>

<h3 id="toc_4">再发一次<code>select</code>请求</h3>

<p>...</p>

<p>2016-03-18 12:59:34 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER <br/>
2016-03-18 12:59:34 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt; Parameters: <br/>
2016-03-18 12:59:34 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==      Total: 20<br/>
2016-03-18 12:59:34 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@75ab43b7]<br/>
2016-03-18 12:59:34 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：0    用户数量：20</strong></mark><br/>
2016-03-18 12:59:35 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Fetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@75ab43b7] from current transaction<br/>
2016-03-18 12:59:35 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@75ab43b7]<br/>
2016-03-18 12:59:35 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：1    用户数量：20</strong></mark><br/>
2016-03-18 12:59:36 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Fetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@75ab43b7] from current transaction<br/>
2016-03-18 12:59:36 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@75ab43b7]<br/>
2016-03-18 12:59:36 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：2    用户数量：20</strong></mark></p>

<h3 id="toc_5">结论</h3>

<ul>
<li>读在一个事务中读的都是缓存，一个事务进行中没有新的请求过去</li>
<li>事务的状态是：<code>PROPAGATION_REQUIRED</code>,<code>ISOLATION_DEFAULT</code></li>
<li>先是<code>Creating a new SqlSession</code>，然后<code>Releasing transactional SqlSession</code>，再有请求则是<code>Fetched SqlSession from current transaction</code></li>
<li><strong>读事务中第一次读，拿到的数据是写事务进行之前数据库的状态；之后拿到的数据都是在缓存中拿到的，无论写事务状态是什么</strong>。</li>
</ul>

<hr/>

<h2 id="toc_6">实验二</h2>

<ul>
<li>@transaction标签在class上</li>
<li>mapper xml没有配置flushCache以及useCache</li>
</ul>

<h3 id="toc_7">先执行<code>insert</code>20次，每次休眠1秒（同一个insert方法）</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_8">再执行<code>insert</code>20次，每次休眠1秒（同一个insert方法）</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_9">结果：</h3>

<p>2016-03-18 13:16:56 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  <mark><strong>Preparing: insert</strong></mark> into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) <br/>
2016-03-18 13:16:56 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt; Parameters: 1234567890(String), insert(String), null<br/>
2016-03-18 13:16:56 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==    Updates: 1<br/>
2016-03-18 13:16:56 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3cb57f97]<br/>
2016-03-18 13:16:56 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   1 条</strong></mark><br/>
2016-03-18 13:16:57 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Fetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@302693e9] from current transaction<br/>
2016-03-18 13:16:57 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  <mark><strong>Preparing: insert</strong></mark> into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) <br/>
2016-03-18 13:16:57 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt; Parameters: 1234567890(String), insert(String), null<br/>
2016-03-18 13:16:57 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==    Updates: 1<br/>
2016-03-18 13:16:57 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@302693e9]<br/>
2016-03-18 13:16:57 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   8 条</strong></mark></p>

<h3 id="toc_10">结论</h3>

<ul>
<li>两次写事务并行进行</li>
</ul>

<hr/>

<h2 id="toc_11">实验三</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
<li><code>mapper xml</code>没有配置<code>flushCache</code>以及<code>useCache</code></li>
<li>初始表数据为空</li>
</ul>

<h3 id="toc_12">先执行<code>insert</code>20次，每次休眠1秒</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_13">再执行<code>select</code>30次，每次休眠1秒</h3>

<pre><code class="language-java">    List&lt;WechatUser&gt; wechatUser = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUser.size());
</code></pre>

<h3 id="toc_14">结果：</h3>

<p>同实验一</p>

<hr/>

<h2 id="toc_15">实验四</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
<li><code>mapper xml</code>没有配置<code>flushCache</code>以及<code>useCache</code></li>
</ul>

<h3 id="toc_16">先执行<code>insert</code>20次，每次休眠1秒</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_17">再执行<code>insert</code>20次，每次休眠1秒</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_18">结果：</h3>

<p>同实验二</p>

<hr/>

<h2 id="toc_19">实验五</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
<li><code>mapper xml</code>设置<code>flushCache=&quot;true&quot; useCache=&quot;false&quot;</code></li>
</ul>

<pre><code class="language-xml">    &lt;select id=&quot;select&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;java.lang.String&quot; flushCache=&quot;true&quot; useCache=&quot;false&quot;&gt;
</code></pre>

<ul>
<li>初始表数据为空</li>
</ul>

<h3 id="toc_20">先执行<code>insert</code>20次，每次休眠1秒</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_21">再执行<code>select</code>30次，每次休眠1秒</h3>

<pre><code class="language-java">    List&lt;WechatUser&gt; wechatUser = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUser.size());
</code></pre>

<h3 id="toc_22">结果：</h3>

<p>2016-03-18 13:49:37 [org.springframework.transaction.annotation.AnnotationTransactionAttributeSource]-[DEBUG] <mark><strong>Adding transactional method</strong></mark> &#39;WechatRegistServiceImpl.insertUser&#39; with attribute: <mark><strong>PROPAGATION_REQUIRED</strong></mark>,<mark><strong>ISOLATION_DEFAULT</strong></mark>; &#39;&#39;<br/>
2016-03-18 13:49:37 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Creating new transaction with name</strong></mark> [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl.insertUser]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT; &#39;&#39;<br/>
2016-03-18 13:49:38 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Acquired Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver] for JDBC transaction</p>

<p>...</p>

<p>2016-03-18 13:49:38 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt;  <mark><strong>Preparing: insert</strong></mark> into WECHAT_USER (open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date) values (?, ?, 1, ?, <q>system</q>, now(), <q>system</q>, now()) </p>

<p>2016-03-18 13:49:38 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] ==&gt; Parameters: 1234567890(String), insert(String), null</p>

<p>2016-03-18 13:49:38 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.insert]-[DEBUG] &lt;==    Updates: 1</p>

<p>2016-03-18 13:49:38 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Releasing transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@2e6ab308]</p>

<p>2016-03-18 13:49:38 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   0 条</strong></mark></p>

<p>...</p>

<p>2016-03-18 13:49:39 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   1 条</strong></mark></p>

<p>...</p>

<p>2016-03-18 13:49:40 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   2 条</strong></mark></p>

<p>2016-03-18 13:49:40 [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping]-[DEBUG] Looking up handler method for path /<mark><strong>select.html</strong></mark></p>

<p>2016-03-18 13:49:40 [org.springframework.transaction.annotation.AnnotationTransactionAttributeSource]-[DEBUG] <mark><strong>Adding transactional method</strong></mark> &#39;WechatRegistServiceImpl.selectUser&#39; with attribute: <mark><strong>PROPAGATION_REQUIRED</strong></mark>,<mark><strong>ISOLATION_DEFAULT</strong></mark>; &#39;&#39;</p>

<p>...</p>

<p>2016-03-18 13:49:40 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER </p>

<p>...</p>

<p>2016-03-18 13:49:40 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：0    用户数量：0</strong></mark></p>

<p>...</p>

<p>2016-03-18 13:49:41 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER </p>

<p>...</p>

<p>2016-03-18 13:49:41 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：1    用户数量：0</strong></mark></p>

<p>...</p>

<p>2016-03-18 13:50:08 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER </p>

<p>2016-03-18 13:50:08 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：28    用户数量：0</strong></mark></p>

<p>2016-03-18 13:50:09 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.select]-[DEBUG] ==&gt;  <mark><strong>Preparing: select</strong></mark> user_id, open_id, user_name, use_yn, authority_value, insert_id, insert_date, modify_id, modify_date from WECHAT_USER </p>

<p>2016-03-18 13:50:09 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：29    用户数量：0</strong></mark></p>

<h3 id="toc_23">结论</h3>

<ul>
<li><strong>读事务中第一次读，拿到的数据是写事务进行之前数据库的状态</strong>。</li>
</ul>

<hr/>

<h2 id="toc_24">实验六</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
</ul>

<h3 id="toc_25">先执行<code>update</code>20次，每次休眠1秒（<code>update</code>同一条数据）</h3>

<pre><code class="language-java">    int result = wechatUserMapper.update(wechatUser);
    logger.info(&quot;----------------修改数据：&quot; + i + &quot;  结果&quot; + result);
</code></pre>

<h3 id="toc_26">再执行<code>update</code>20次，每次休眠1秒（<code>update</code>同一条数据）</h3>

<pre><code class="language-java">    int result = wechatUserMapper.update(wechatUser);
    logger.info(&quot;----------------修改数据：&quot; + i + &quot;  结果&quot; + result);
</code></pre>

<h3 id="toc_27">结果：</h3>

<p>2016-03-18 14:50:30 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.update]-[DEBUG] ==&gt;  <mark><strong>Preparing: update</strong></mark> WECHAT_USER SET open_id = ?, user_name = ?, modify_date = now() where open_id = <q>abc</q> </p>

<p>2016-03-18 14:50:30 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>修改数据：0  结果1</strong></mark></p>

<p>2016-03-18 14:50:31 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] Fetched SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@77e2cc94] from current transaction</p>

<p>2016-03-18 14:50:31 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.update]-[DEBUG] ==&gt;  <mark><strong>Preparing: update</strong></mark> WECHAT_USER SET open_id = ?, user_name = ?, modify_date = now() where open_id = <q>abc</q> </p>

<p>2016-03-18 14:50:31 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>修改数据：1  结果0</strong></mark></p>

<p>2016-03-18 14:50:32 [org.springframework.web.servlet.DispatcherServlet]-[DEBUG] DispatcherServlet with name &#39;spring&#39; processing GET request for [/springtest/update.html]</p>

<p>2016-03-18 14:50:32 [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping]-[DEBUG] Looking up handler method for path /<mark><strong>update.html</strong></mark></p>

<p>...</p>

<p>2016-03-18 14:50:32 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.update]-[DEBUG] ==&gt;  <mark><strong>Preparing: update</strong></mark> WECHAT_USER SET open_id = ?, user_name = ?, modify_date = now() where open_id = <q>abc</q> </p>

<p>2016-03-18 14:50:32 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>修改数据：2  结果0</strong></mark></p>

<p>...</p>

<p>2016-03-18 14:50:49 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>修改数据：19  结果0</strong></mark></p>

<p>2016-03-18 14:50:50 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Transaction synchronization committing SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@77e2cc94]</p>

<p>2016-03-18 14:50:50 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Transaction synchronization deregistering SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@77e2cc94]</p>

<p>2016-03-18 14:50:50 [org.mybatis.spring.SqlSessionUtils]-[DEBUG] <mark><strong>Transaction synchronization closing SqlSession</strong></mark> [org.apache.ibatis.session.defaults.DefaultSqlSession@77e2cc94]</p>

<p>2016-03-18 14:50:50 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Initiating transaction commit</strong></mark></p>

<p>2016-03-18 14:50:50 [org.springframework.jdbc.datasource.DataSourceTransactionManager]-[DEBUG] <mark><strong>Committing JDBC transaction on Connection</strong></mark> [jdbc:mysql://localhost:3306/sip?useUnicode=yes&amp;characterEncoding=UTF8, UserName=root@localhost, MySQL-AB JDBC Driver]</p>

<p>...</p>

<p>2016-03-18 14:50:50 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>修改数据：0  结果0</strong></mark></p>

<p>...</p>

<p>2016-03-18 14:50:51 [cn.hao24.mobauto.mapper.wechatusers.WechatUserMapper.update]-[DEBUG] ==&gt;  <mark><strong>Preparing: update</strong></mark> WECHAT_USER SET open_id = ?, user_name = ?, modify_date = now() where open_id = <q>abc</q> </p>

<p>2016-03-18 14:50:51 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>修改数据：1  结果0</strong></mark></p>

<h3 id="toc_28">结论</h3>

<ul>
<li><strong>当两个写事务都是操作同一个数据的时候，第二个写事务会等第一个写事务提交之后才会进行</strong>。</li>
</ul>

<hr/>

<h2 id="toc_29">实验七</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
</ul>

<h3 id="toc_30">先执行<code>update</code>20次，每次休眠1秒（<code>update</code>不同一条数据）</h3>

<pre><code class="language-java">    int result = wechatUserMapper.update(wechatUser);
    logger.info(&quot;----------------修改数据：&quot; + i + &quot;  结果&quot; + result);
</code></pre>

<h3 id="toc_31">再执行<code>update</code>20次，每次休眠1秒（<code>update</code>不同一条数据）</h3>

<pre><code class="language-java">    int result = wechatUserMapper.update(wechatUser);
    logger.info(&quot;----------------修改数据：&quot; + i + &quot;  结果&quot; + result);
</code></pre>

<h3 id="toc_32">结果：</h3>

<p>同实验六</p>

<hr/>

<h2 id="toc_33">实验八</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
</ul>

<h3 id="toc_34">先执行<code>update</code>20次，每次休眠1秒</h3>

<pre><code class="language-java">    int result = wechatUserMapper.update(wechatUser);
    logger.info(&quot;----------------修改数据：&quot; + i + &quot;  结果&quot; + result);
</code></pre>

<h3 id="toc_35">再执行<code>insert</code>20次，每次休眠1秒</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_36">结果：</h3>

<p>先执行<code>update</code>，<code>update</code>事务结束后，执行<code>insert</code></p>

<hr/>

<h2 id="toc_37">实验九</h2>

<ul>
<li><code>@transaction</code>标签在<code>class</code>上</li>
</ul>

<h3 id="toc_38">先执行<code>insert</code>20次，每次休眠1秒（不同insert方法）</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_39">再执行<code>insert</code>20次，每次休眠1秒（不同insert方法）</h3>

<pre><code class="language-java">    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_40">结果：</h3>

<p>并行</p>

<hr/>

<h2 id="toc_41">实验十</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
<li><code>mapper xml</code>设置<code>flushCache=&quot;true&quot; useCache=&quot;false&quot;</code></li>
</ul>

<pre><code class="language-xml">    &lt;select id=&quot;select&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;java.lang.String&quot; flushCache=&quot;true&quot; useCache=&quot;false&quot;&gt;
</code></pre>

<h3 id="toc_42">先执行<code>select + insert</code>20次，每次休眠1秒（同一个<code>select + insert</code>方法）</h3>

<pre><code class="language-java">    List&lt;WechatUser&gt; wechatUserList = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUserList.size());
    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_43">再执行<code>select + insert</code>20次，每次休眠1秒（同一个<code>select + insert</code>方法）</h3>

<pre><code class="language-java">    List&lt;WechatUser&gt; wechatUserList = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUserList.size());
    wechatUserMapper.insert(wechatUser);
    logger.info(&quot;----------------写入数据第   &quot; + i + &quot; 条&quot;);
</code></pre>

<h3 id="toc_44">结果：</h3>

<p>2016-03-18 16:17:43 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：5    用户数量：5</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:43 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   5 条</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:44 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：0    用户数量：0</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:44 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   0 条</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:44 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：6    用户数量：6</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:44 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   6 条</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:45 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：1    用户数量：1</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:58 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：19    用户数量：19</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:58 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   19 条</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:58 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>读出数据：14    用户数量：14</strong></mark></p>

<p>...</p>

<p>2016-03-18 16:17:58 [cn.hao24.mobauto.db.service.wechatuser.impl.WechatRegistServiceImpl]-[INFO] ----------------<mark><strong>写入数据第   14 条</strong></mark></p>

<h3 id="toc_45">结论</h3>

<ul>
<li><strong>两个读写事务或并行运行；但是他们对数据库的影响不会作用到彼此，即大家读的都是快照</strong></li>
</ul>

<hr/>

<h2 id="toc_46">实验十一</h2>

<ul>
<li><code>@transaction</code>标签在方法上</li>
<li><code>mapper xml</code>设置<code>flushCache=&quot;true&quot; useCache=&quot;false&quot;</code></li>
</ul>

<pre><code class="language-xml">    &lt;select id=&quot;select&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;java.lang.String&quot; flushCache=&quot;true&quot; useCache=&quot;false&quot;&gt;
</code></pre>

<h3 id="toc_47">先执行<code>select + update</code>20次，每次休眠1秒（同一个<code>select + update</code>方法）</h3>

<pre><code class="language-java">    List&lt;WechatUser&gt; wechatUserList = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUserList.size());
    int result = wechatUserMapper.update(wechatUser);
    logger.info(&quot;----------------修改数据：&quot; + i + &quot;  结果&quot; + result);
</code></pre>

<h3 id="toc_48">再执行<code>select + update</code>20次，每次休眠1秒（同一个<code>select + update</code>方法）</h3>

<pre><code class="language-java">    List&lt;WechatUser&gt; wechatUserList = wechatUserMapper.select();
    logger.info(&quot;----------------读出数据：&quot; + i + &quot;    用户数量：&quot; + wechatUserList.size());
    int result = wechatUserMapper.update(wechatUser);
    logger.info(&quot;----------------修改数据：&quot; + i + &quot;  结果&quot; + result);
</code></pre>

<h3 id="toc_49">结果：</h3>

<p>两次大事务串行</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why use Paxos?]]></title>
    <link href="http://nathanchen.github.io/14580966677658.html"/>
    <updated>2016-03-16T10:51:07+08:00</updated>
    <id>http://nathanchen.github.io/14580966677658.html</id>
    <content type="html"><![CDATA[
<p>Paxos is a protocol for state machine replication in an asynchronous environment that admits crash failures.</p>

<p>A replicated state machine works by having multiple state machines, also called <strong>replicas</strong>, working in parallel, maintaining the same state. <strong>When the replicas receive requests from a client they update their state by executing the command in the request and reply to the client</strong>. This way, <strong>the state is automatically replicated by the replicas and in the event of a failure the state does not get lost</strong>, making the replicated state machine reliable.</p>

<p>It is easy for replicas to execute client commands in the same order and remain in sync if there is only one client or if multiple clients send their requests strictly sequentially.</p>

<p>But if multiple clients send requests to replicas in parallel, then different replicas might receive these requests in different orders and execute the commands in different orders, causing their local states to diverge from one another over time.</p>

<p>To prevent replicas from diverging in the presence of multiple clients sending requests in parallel, <strong>the order in which the client commands will be executed by replicas should be decided</strong>.</p>

<p>To decide the order in which the client commands will be executed <strong>the replicas can be thought of as having a sequence of slots that need to be filled with commands that make up the inputs to the state machine they maintain</strong>.</p>

<p>In the example this sequence is shown as a table. <strong>Each slot is indexed by a slot number</strong>, starting from 1. <strong>Replicas receive requests from clients and assign them to specific slots</strong>, creating a sequence of commands. </p>

<p>In the face of concurrently operating clients, different replicas may end up proposing different commands for the same slot. To avoid inconsistency, <strong>a consensus protocol chooses a single command from the proposals for every slot</strong>.</p>

<p>In Paxos the subprotocol that implements consensus is called the multi-decree Synod protocol, or just Synod protocol for short. <strong>A replica awaits the decision before actually updating its sequence of commands in the table</strong>, <strong>executing the next command and computing a response to send back to the client that issued the request</strong>.</p>

<p>Essentially. the replicated state machine uses Paxos as an ordering entity which uses consensus to agree on which client command gets assigned to which slot. One has to make sure that the ordering entity itself is also reliable, that it can tolerate failure just like the replicaed state machine.</p>

<p>To achieve reliability, Paxos is run by multiple specialized processes in a distributed fashion. This is not trivial because up to f processes running Paxos might fail at any time and, because there is no bound on timing for delivering and processing messages, it is impossible for other processes to know for certain that the process has failed.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[`Memcached`解读]]></title>
    <link href="http://nathanchen.github.io/14580512169278.html"/>
    <updated>2016-03-15T22:13:36+08:00</updated>
    <id>http://nathanchen.github.io/14580512169278.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0"><code>Memcached</code>实现原理</h3>

<p><code>Memcached</code>将数据存放在内存中，有这么几个特点：</p>

<ul>
<li>访问速度比传统关系型数据库要快</li>
<li>只要<code>Memcached</code>重启了，数据也就丢失了</li>
</ul>

<p><code>Memcached</code>采用的内存分配方式是固定空间分配</p>

<p><img src="media/14580512169278/14580526561990.jpg" alt=""/></p>

<ul>
<li><code>Memcached</code>将内存空间分成一组<code>slab</code></li>
<li>每个<code>slab</code>下有若干个<code>page</code>，每个<code>page</code>默认是1MB，如果一个<code>slab</code>占用100MB内存的话，那么这个<code>slab</code>下就有100个<code>page</code></li>
<li>每个<code>page</code>里面包含一组<code>chunk</code>，<code>chunk</code>是真正存放数据的地方，同一个<code>slab</code>里面的<code>chunk</code>的大小是固定的</li>
<li>有相同大小的<code>chunk</code>的<code>slab</code>被组织在一起，称为<code>slab_class</code></li>
</ul>

<p><code>Memcached</code>有新的<code>value</code>进来，它的存放位置是由<code>value</code>的大小决定的，<code>value</code>总是被存放到与<code>chunk</code>大小最接近的那个<code>slab</code>。</p>

<p>放<code>slab</code>的时候，首先<code>slab</code>要申请内存，申请内存是以<code>page</code>为单位的，所以在放入第一个数据的时候，无论大小为多少，都会有1MB大小的<code>page</code>被分配给该<code>slab</code>。申请到<code>page</code>后，<code>slab</code>会将这个<code>page</code>的内存按<code>chunk</code>的大小进行切分，这样就变成一个<code>chunk</code>数组。</p>

<p>相邻<code>slab</code>内的<code>chunk</code>基本以1.25为比例的增长</p>

<p><code>Memcached</code>内存分配和回收算法，有三点要注意：</p>

<ul>
<li><code>Memcached</code>内存分配时，<code>chunk</code>里面会有内存浪费，88字节的<code>value</code>分配在128字节的<code>chunk</code>中，就损失了30个字节，但是避免了管理内存碎片的问题</li>
<li><code>Memcached</code>的<code>LRU</code>算法不是针对全局的，而是针对<code>slab</code>的</li>
<li><code>value</code>的大小不能大于1MB，因为<code>page</code>只有1MB</li>
</ul>

]]></content>
  </entry>
  
</feed>
