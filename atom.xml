<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[NathanCHEN]]></title>
    <link href="http://nathanchen.github.io/atom.xml" rel="self"/>
    <link href="http://nathanchen.github.io/"/>
    <updated>2016-04-02T22:42:00+08:00</updated>
    <id>http://nathanchen.github.io/</id>
    <author>
        <name><![CDATA[]]></name>

    </author>
    <generator uri="http://www.mweb.im/">MWeb</generator>
    
    <entry>
        <title type="html"><![CDATA[StringBuilder在高性能场景下的正确用法]]></title>
        <link href="http://nathanchen.github.io/14596982516208.html"/>
        <updated>2016-04-03T23:44:11+08:00</updated>
        <id>http://nathanchen.github.io/14596982516208.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">初始长度很重要</h3>

<p><code>StringBuilder</code>的内部有一个<code>char[]</code>，不同的<code>append()</code>就是不断的往<code>char[]</code>里填东西的过程。</p>

<p><code>new StringBuilder()</code>时<code>char[]</code>的默认长度为16，超过就用<code>System.arraycopy</code>成倍复制扩容。</p>

<p>这样一来有数组拷贝的成本，二来原来的<code>char[]</code>也白白浪费了，要被<code>GC</code>掉。</p>

<p>所以，合理设置一个初始值是很重要的。</p>

<blockquote>
<p>一种长度设置的思路，在<code>append()</code>的时候，不急着往<code>char[]</code>里塞东西，而是先拿一个<code>String[]</code>把它们都存起来，到了最后才把所有<code>String</code>的<code>length</code>加起来，构造一个合理长度的<code>StringBuilder</code>。</p>
</blockquote>

<h3 id="toc_1">但是，还是会浪费一倍的char[]</h3>

<p>因为：</p>

<pre><code class="language-java">return new String(value, 0, count);
</code></pre>

<p><code>String</code>的构造函数会用<code>System.arraycopy()</code>复制一次传入的<code>char[]</code>来保证安全性及不可变性，这样<code>StringBuilder</code>里的<code>char[]</code>就白白牺牲掉了。</p>

<p>为了不浪费这些<code>char[]</code>，可以重用<code>StringBuilder</code>。</p>

<h3 id="toc_2">重用StringBuilder</h3>

<pre><code class="language-java">public StringBuilder getStringBuilder() {
    sb.setLength(0);
    return sb;
}
</code></pre>

<p>为了避免并发冲突，这个<code>Holder</code>一般设为<code>ThreadLocal</code>。</p>

<h3 id="toc_3">+和StringBuilder</h3>

<pre><code class="language-java">String str = &quot;hello &quot; + user.getName();
</code></pre>

<p>这一句经过<code>javac</code>编译后的效果，的确等价于使用<code>StringBuilder</code>，但没有设定长度。</p>

<p>但是，如果像下面这样：</p>

<pre><code class="language-java">String str = &quot;hello &quot;;
str = str + user.getName();
</code></pre>

<p>每一条语句，都会生成一个新的<code>StringBuilder</code>，这样这里就有了两个<code>StringBuilder</code>，性能就完全不一样了。</p>

<p>保险起见，还是继续自己用<code>StringBuilder</code>并设定好长度。</p>

<pre><code class="language-java">private static final ThreadLocal&lt;StringBuilderHelper&gt; threadLocalStringBuilderHolder = new ThreadLocal&lt;StringBuilderHelper&gt;() {
    protected StringBuilderHelper initialValue() {
        return new StringBuilderHelper(256);
    }
}

StringBuilder sb = threadLocalStringBuilderHolder.get().resetAndGetStringBuilder();
</code></pre>

<blockquote>
<p>StringBuidlerHolder</p>
</blockquote>

<pre><code class="language-java">public class StringBuilderHolder {
    private final StringBuilder sb;
    
    public StringBuilderHolder(int capacity) {
        sb = new StringBuidler(capacity);
    }
    
    public StringBuilder resetAndGetStringBuilder() {
        sb.setLength(0);
        return sb;
    }
}
</code></pre>

<hr/>

<h3 id="toc_4">Reference</h3>

<p><a href="http://calvin1978.blogcn.com/articles/stringbuilder.html">http://calvin1978.blogcn.com/articles/stringbuilder.html</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[分布式Unique ID的生成方法一览]]></title>
        <link href="http://nathanchen.github.io/14596964476354.html"/>
        <updated>2016-04-03T23:14:07+08:00</updated>
        <id>http://nathanchen.github.io/14596964476354.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">发号器</h3>

<p>Oracle的自增ID</p>

<p>特点是准连续的自增数字，为什么说是准连续？因为性能考虑，每个Client一次会领20个ID回去慢慢用，用完了再来拿。另一个Client过来，拿的就是另外20个ID。</p>

<p>如果有多个数据中心，那就拿高位的几个bit来区分。</p>

<h3 id="toc_1">UUID</h3>

<ul>
<li>时间戳 + UUID版本号，分三段占16个字符</li>
<li>Clock Sequence号与保留字段，占4个字符</li>
<li>节点标识，占12个字符</li>
</ul>

<p>UUID有多种算法，能用于TraceID的是：</p>

<ul>
<li>version1：基于时间的算法</li>
<li>version4：基于随机数的算法</li>
</ul>

<h4 id="toc_2">version 4</h4>

<p>最暴力的做法，也是JDK里的算法，除了少数几个位必须按规范填，其余全部用随机数表示。</p>

<h4 id="toc_3">version 1</h4>

<p>严格守着原来各个位的规矩：</p>

<p>以100纳秒为1，从1582年10月15日算起</p>

<p>节点标识也有48bit，一般用MAC地址表示，如果有多快网卡就随便用一块。如果没有网卡，就用随机数凑数，或者拿一堆尽量多的其他信息，比如主机名什么的，拼在一起再hash</p>

<p>顺序号这16bit则仅用于避免前面的节点标识改变（网卡改了），时钟系统出问题，让它随机一下避免重复。</p>

<hr/>

<h3 id="toc_4">Reference</h3>

<p><a href="http://calvin1978.blogcn.com/articles/uuid.html">http://calvin1978.blogcn.com/articles/uuid.html</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[关于Java集合的小抄]]></title>
        <link href="http://nathanchen.github.io/14596091370634.html"/>
        <updated>2016-04-02T22:58:57+08:00</updated>
        <id>http://nathanchen.github.io/14596091370634.html</id>
        <content type="html"><![CDATA[
<h2 id="toc_0">List</h2>

<h3 id="toc_1">ArrayList</h3>

<p>以数组实现。节约空间，但数组有容量限制。超出限制时会增加<code>50%</code>容量，用<code>System.arraycopy()</code>复制到新的数组，因此最好能给出数组大小的预估值。默认第一次插入元素时，创建大小为10的数组。</p>

<h4 id="toc_2">基本优势</h4>

<p>按数组下标访问元素<code>get(i)</code> <code>set(i, e)</code>的性能很高。</p>

<p>直接在数组末尾加入元素<code>add(e)</code>的性能也高。</p>

<h4 id="toc_3">基本劣势</h4>

<p>如果按下表插入、删除元素<code>add(i, e)</code> <code>remove(i)</code> <code>remove(e)</code>，则要用System.arraycopy()来移动部分受影响的元素，性能就变差了。</p>

<h3 id="toc_4">LinkedList</h3>

<p>以双向链表实现。链表无容量限制，但本身使用了更多空间，也需要额外的链表指针操作。</p>

<h4 id="toc_5">基本优势</h4>

<p>不需扩容，调整容量</p>

<p>在链表两头的操作<code>add()</code> <code>addFirst()</code> <code>removeLast()</code>能省掉指针的移动</p>

<h4 id="toc_6">基本劣势</h4>

<p>按下标访问元素<code>get(i)</code> <code>set(i, e)</code>要遍历链表，将指针移动到位。如果<code>i</code>&gt;数组大小的一半，会从末尾移起。</p>

<h3 id="toc_7">CopyOnWriteArrayList</h3>

<p>并发优化的<code>ArrayList</code>。用<code>CopyOnWrite</code>策略，在修改时，先复制一个快照来修改，改完再让内部指针指向新数组。</p>

<p>因为对快照的修改对读操作不可见，所以只有写锁没有读锁，加上复制的昂贵成本，典型的适合读多写少的场景。如果更新频率较高，或者数组较大时，还是<code>Collections.synchronizedList(list)</code>，对所有操作用同一把锁来保证线程安全更好。</p>

<h2 id="toc_8">Map</h2>

<h3 id="toc_9">HashMap</h3>

<p>用<code>key</code>的哈希值%桶数组的大小可得到数组下标。</p>

<p>插入元素时，如果两条<code>key</code>落在同一个桶，<code>Entry</code>用一个<code>next</code>属性实现多个<code>Entry</code>以单向链表存放，后入桶的<code>Entry</code>将<code>next</code>指向桶当前的<code>Entry</code></p>

<p>当<code>Entry</code>数量达到桶数量的<code>75%</code>时，会成倍扩容桶数组，并重新分配所有原来的<code>Entry</code>，所以这两也最好有个预估值。</p>

<p>取模用位运算<code>(hash &amp; (arrayLength-1))</code>会比较快，所以数组的大小永远是2的<code>N</code>次方。默认第一次放入元素时的初始值是16。</p>

<p><strong>在JDK8里，新增默认为8的閥值，当一个桶里的<code>Entry</code>超过閥值，就不以单向链表而以红黑树来存放以加快<code>Key</code>的查找速度。</strong></p>

<h3 id="toc_10">LinkedHashMap</h3>

<p>扩展<code>HashMap</code>，增加了双向链表的实现，号称是最占内存的数据结构。</p>

<h3 id="toc_11">TreeMap</h3>

<p>以红黑树实现。</p>

<h3 id="toc_12">ConcurrentHashMap</h3>

<p>并发优化的<code>HashMap</code>，默认16把写锁（可以设置更多），有效地分散了阻塞的概率，而且没有读锁。</p>

<p>数据结构为<code>Segment[]</code>，<code>Segment</code>里面才是哈希桶数组，每个<code>Segment</code>一把锁。<code>Key</code>先算出它在哪个<code>Segment</code>里，再算出它在哪个哈希桶里。</p>

<h2 id="toc_13">Set</h2>

<p><code>Set</code>几乎都是内部用一个<code>Map</code>来实现的。</p>

<p>将<code>Map</code>里的<code>KeySet</code>当做一个<code>Set</code>，而<code>Value</code>是假值，全部使用同一个<code>Object</code>。<code>Set</code>的特征也继承了那些内部<code>Map</code>实现的特征。</p>

<ul>
<li><code>HashSet</code>：内部就是<code>HashMap</code></li>
<li><code>LinkedHashSet</code>：内部就是<code>LinkedHashMap</code></li>
<li><code>TreeSet</code>：内部就是<code>TreeMap</code>的<code>SortedSet</code></li>
<li><code>ConcurrentSkipListSet</code>：内部就是<code>ConcurrentSkipListMap</code>的并发优化<code>SortedSet</code></li>
</ul>

<h2 id="toc_14">Queue</h2>

<p><code>Queue</code>是在两端出入的<code>List</code>，所以也可以用数组或链表来实现。</p>

<h3 id="toc_15">LinkedList</h3>

<p>即是<code>List</code>，也是<code>Queue</code>。它是唯一一个允许放入<code>null</code>值的<code>Queue</code>。</p>

<h3 id="toc_16">ArrayDeque</h3>

<p>以循环数组实现的双向<code>Queue</code>。大小是2的倍数，默认是16。</p>

<p>It represens a queue where you can insert and remove elements from both ends of the queue. </p>

<h4 id="toc_17">Adding and Accessing Elements</h4>

<p>The order in which the elements added to the ArrayDeque are stored internally. ArrayDeque stores the elements in the order in which they are inserted.</p>

<p>You can peek at the element at the head of the queue without taking the element out of the queue.</p>

<h3 id="toc_18">PriorityQueue</h3>

<p>用二叉堆实现的优先级队列，不再是<code>FIFO</code>，而是按元素实现的<code>Comparable</code>接口或传入<code>Comparator</code>的比较结果来出队，数值越小，优先级越高，越先出队。</p>

<hr/>

<h3 id="toc_19">Reference</h3>

<p><a href="http://calvin1978.blogcn.com/articles/collection.html">http://calvin1978.blogcn.com/articles/collection.html</a></p>

<p><a href="http://tutorials.jenkov.com/java-collections/deque.html">http://tutorials.jenkov.com/java-collections/deque.html</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Java ArrayList工作原理及实现]]></title>
        <link href="http://nathanchen.github.io/14596082686083.html"/>
        <updated>2016-04-02T22:44:28+08:00</updated>
        <id>http://nathanchen.github.io/14596082686083.html</id>
        <content type="html"><![CDATA[
<h2 id="toc_0">概述</h2>

<p>以数组实现。节约空间，但数组有容量限制。超出限制时会增加<code>50%</code>容量，用<code>System.arraycopy()</code>复制到新的数组，因此最好能给出数组大小的预估值。默认第一次插入元素时，创建大小为10的数组。</p>

<h4 id="toc_1">基本优势</h4>

<p>按数组下标访问元素<code>get(i)</code> <code>set(i, e)</code>的性能很高。</p>

<p>直接在数组末尾加入元素<code>add(e)</code>的性能也高。</p>

<h4 id="toc_2">基本劣势</h4>

<p>如果按下表插入、删除元素<code>add(i, e)</code> <code>remove(i)</code> <code>remove(e)</code>，则要用System.arraycopy()来移动部分受影响的元素，性能就变差了。</p>

<pre><code class="language-java">ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();
list.add(&quot;语文: 99&quot;);
list.add(&quot;数学: 98&quot;);
list.add(&quot;英语: 100&quot;);
list.remove(0);
</code></pre>

<p><code>add</code>操作：直接将数组的内容置位</p>

<p><code>remove</code>操作：删除index为0的节点，并将后面的元素移到0处。</p>

<h2 id="toc_3">add函数</h2>

<p>add函数：将元素放到末尾</p>

<pre><code class="language-java">public boolean add(E e) {
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    elementData[size++] = e;
    return true;
}
</code></pre>

<p><code>ensureCapacityInternal</code>自动扩容机制的核心</p>

<pre><code class="language-java">private void ensureCapacityInternal(int minCapacity) {
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
    }
 
    ensureExplicitCapacity(minCapacity);
}
 
private void ensureExplicitCapacity(int minCapacity) {
    modCount++;
 
    // overflow-conscious code
    if (minCapacity - elementData.length &gt; 0)
        grow(minCapacity);
}
 
private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    // 扩展为原来的1.5倍
    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);
    // 如果扩为1.5倍还不满足需求，直接扩为需求值
    if (newCapacity - minCapacity &lt; 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
</code></pre>

<ul>
<li>当增加数据的时候，如果ArrayList的大小已经不满足需求时，那么就将数组变为原长度的1.5倍</li>
<li>之后的操作就是把老的数组拷到新的数组里面</li>
</ul>

<h2 id="toc_4">set和get函数</h2>

<ul>
<li>先做index范围检查，看是不是越界了</li>
<li>然后做赋值或访问操作</li>
</ul>

<h2 id="toc_5">remove函数</h2>

<pre><code class="language-java">public E remove(int index) {
    rangeCheck(index);
 
    modCount++;
    E oldValue = elementData(index);
 
    int numMoved = size - index - 1;
    if (numMoved &gt; 0)
        // 把后面的往前移
        System.arraycopy(elementData, index+1, elementData, index,
                         numMoved);
    // 把最后的置null
    elementData[--size] = null; // clear to let GC do its work
 
    return oldValue;
}
</code></pre>

<ul>
<li>删除要删的元素</li>
<li>将排在删除元素后面的往前移</li>
</ul>

<h3 id="toc_6">Reference</h3>

<p><a href="http://www.importnew.com/18865.html">http://www.importnew.com/18865.html</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[索引的相关知识]]></title>
        <link href="http://nathanchen.github.io/14594286280881.html"/>
        <updated>2016-03-31T20:50:28+08:00</updated>
        <id>http://nathanchen.github.io/14594286280881.html</id>
        <content type="html"><![CDATA[
<h2 id="toc_0">索引的类型</h2>

<h3 id="toc_1"><code>B树</code>(二叉搜索树)：</h3>

<ol>
<li>所有非叶子结点至多拥有两个儿子（<code>Left</code>和<code>Right</code>）；</li>
<li>所有结点存储一个关键字；</li>
<li>非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树；</li>
</ol>

<p><img src="media/14594286280881/201603311458.jpg" alt="201603311458"/></p>

<h3 id="toc_2"><code>B--tree</code>多路搜索树（并不是二叉的）</h3>

<h4 id="toc_3"><code>B--tree</code>特点:</h4>

<ol>
<li>定义任意非叶子结点最多只有<code>M</code>个儿子，且<code>M &gt; 2</code>；</li>
<li>根结点的儿子数为<code>[2, M]</code>；</li>
<li>除根结点以外的非叶子结点的儿子数为<code>[M/2, M]</code>；</li>
<li>每个结点存放至少<code>M/2-1</code>（取上整）和至多<code>M-1</code>个关键字；（至少2个关键字）</li>
<li>非叶子结点的关键字个数 = 指向儿子的指针个数 - 1；</li>
<li>非叶子结点的关键字：<code>K[1]</code>, <code>K[2]</code>, …, <code>K[M-1]</code>；且<code>K[i] &lt; K[i+1]</code>；</li>
<li>非叶子结点的指针：<code>P[1]</code>, <code>P[2]</code>, …, <code>P[M]</code>；其中<code>P[1]</code>指向关键字小于<code>K[1]</code>的子树，<code>P[M]</code>指向关键字大于<code>K[M-1]</code>的子树，其它<code>P[i]</code>指向关键字属于(<code>K[i-1]</code>, <code>K[i]</code>)的子树；</li>
<li> 所有叶子结点位于同一层；<br/></li>
</ol>

<blockquote>
<p>（M=3）<br/>
<img src="media/14594286280881/201603311503.jpg" alt="201603311503"/></p>
</blockquote>

<h3 id="toc_4"><code>B+-tree</code>(平衡二叉查找树)</h3>

<p><code>B-Tree</code>索引（大部分<code>mysql</code>存储引擎）<code>B-tree</code>的数据存储是有序的。加速数据的访问不用扫描整个表</p>

<h4 id="toc_5">数据库使用<code>B+-tree</code>结构（<code>B--tree</code>的变种）的原因</h4>

<p>数据库的索引大都以索引文件的形式存储在磁盘上，索引查找的过程就会产生磁盘<code>I/O</code>消耗，<strong>索引结构组织能减少查找过程中磁盘<code>I/O</code>的存取次数</strong>。磁盘会做到按需读取，<strong>每次预读的长度都会为页</strong>（一个节点的大小）<strong>的整数倍</strong>，这样每个节点就只需要一次<code>I/O</code>就能全部载入。新建的节点会申请页空间，一个节点物理上也存储在一个页里，计算机存储分配都是按页对齐的，这样就能一次<code>I/O</code>完全载入一个<code>node</code>。<code>B+-tree</code>的<code>m</code>值越大，树的高度越低，有利于一次完全载入</p>

<h4 id="toc_6">一颗<code>m</code>阶的<code>B+-tree</code>(二叉查找树)的特性如下（其中<code>ceil(x)</code>是一个取上限的函数）</h4>

<ol>
<li>树中每个结点至多有<code>m</code>个孩子</li>
<li>除根结点和叶子结点外，其它每个结点至少有<code>ceil(m/2)</code>个孩子</li>
<li>若根结点不是叶子结点，则至少有2个孩子（特殊情况：没有孩子的根结点，即根结点为叶子结点，整棵树只有一个根节点）</li>
<li>所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部结点或查询失败的结点，实际上这些结点不存在，指向这些结点的指针都为<code>null</code>)</li>
<li><p>每个非终端结点中包含有<code>n</code>个关键字信息：<code>(n，P0，K1，P1，K2，P2，......，Kn，Pn)</code>。其中：</p>

<pre><code>a) Ki (i=1...n)为关键字，且关键字按顺序排序K(i-1)&lt; Ki。
b) Pi为指向子树根的接点，且指针P(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。
c) 关键字的个数n必须满足： ceil(m / 2)-1 &lt;= n &lt;= m-1。
</code></pre></li>
</ol>

<h5 id="toc_7">下面以一棵5阶B+-tree实例进行讲解(如下图所示)：（重点看以下图）</h5>

<p><img src="media/14594286280881/201603311033.png" alt="201603311033"/></p>

<p>其满足上述条件：除根结点和叶子结点外，其它每个结点至少有<code>ceil(5/2)=3</code>个孩子（至少2个关键字）；当然最多5个孩子（最多4个关键字）。</p>

<p>下图中关键字为大写字母，顺序为字母升序。</p>

<p><strong>插入（insert）操作</strong></p>

<ul>
<li>首先在<code>B-tree</code>中是否存在，</li>
<li><p>如果不存在，即在叶子结点处结束，然后在叶子结点中插入该新的元素，</p>

<ul>
<li>注意：<strong>如果叶子结点空间足够</strong>，这里需要<strong>向右移动该叶子结点中大于新插入关键字的元素</strong>，</li>
<li><strong>如果空间满了以致没有足够的空间去添加新的元素</strong>，则将该<strong>结点进行<code>分裂</code></strong>，将<strong>一半数量的关键字元素分裂到新的其相邻右结点中</strong>，<strong>中间关键字元素上移到父结点中</strong>（当然，如果父结点空间满了，也同样需要<code>分裂</code>操作），而且当结点中关键元素向右移动了，相关的指针也需要向右移。</li>
<li>如果在根结点插入新元素，空间满了，则进行分裂操作，这样原来的根结点中的中间关键字元素向上移动到新的根结点中，因此导致树的高度增加一层。</li>
</ul></li>
</ul>

<h5 id="toc_8">插入以下字符字母到空的5阶<code>B-tree</code>中：</h5>

<pre><code>C N G A H E K Q M F W L T Z D P R X Y S
</code></pre>

<ul>
<li>结点空间足够，4个字母插入相同的结点中</li>
</ul>

<p><img src="media/14594286280881/20160331111501.jpg" alt="20160331111501"/></p>

<ul>
<li>当咱们试着插入<code>H</code>时，结点发现空间不够，以致<strong>将其分裂成2个结点</strong>，<strong>移动中间元素<code>G</code>上移到新的根结点中</strong>，在实现过程中，咱们把<strong><code>A</code>和<code>C</code>留在当前结点中</strong>，而<strong><code>H</code>和<code>N</code>放置新的其右邻居结点</strong>中</li>
</ul>

<p><img src="media/14594286280881/20160331111502.jpg" alt="20160331111502"/></p>

<ul>
<li>当咱们插入<code>E</code>, <code>K</code>, <code>Q</code>时，不需要任何分裂操作</li>
</ul>

<p><img src="media/14594286280881/20160331111503.jpg" alt="20160331111503"/></p>

<ul>
<li>插入<code>M</code>需要一次分裂，注意<code>M</code>恰好是中间关键字元素，以致向上移到父节点中</li>
</ul>

<p><img src="media/14594286280881/20160331111504.jpg" alt="20160331111504"/></p>

<ul>
<li>插入<code>F</code>, <code>W ,</code>L<code>, T</code>不需要任何分裂操作</li>
</ul>

<p><img src="media/14594286280881/20160331111505.jpg" alt="20160331111505"/></p>

<ul>
<li>插入<code>Z</code>时，最右的叶子结点空间满了，需要进行分裂操作，中间元素<code>T</code>上移到父节点中，注意通过上移中间元素，    树最终还是保持平衡，分裂结果的结点存在<code>2</code>个关键字元素。</li>
</ul>

<p><img src="media/14594286280881/20160331111506.jpg" alt="20160331111506"/></p>

<ul>
<li>插入<code>D</code>时，导致最左边的叶子结点被分裂，<code>D</code>恰好也是中间元素，上移到父节点中，然后字母<code>P</code>, <code>R</code>, <code>X</code>, <code>Y</code>陆续插入不需要任何分裂操作。</li>
</ul>

<p><img src="media/14594286280881/20160331111507.jpg" alt="20160331111507"/></p>

<ul>
<li>当插入<code>S</code>时，含有<code>N</code>, <code>P</code>, <code>Q</code>, <code>R</code>的结点需要分裂，把中间元素<code>Q</code>上移到父节点中，但是情况来了，<strong>父节点中空间已经满了</strong>，所以也要进行分裂，将父节点中的中间元素<code>M</code>上移到新形成的根结点中，<strong>注意以前在父节点中的第三个指针在修改后包括<code>D</code>和<code>G</code>节点中</strong>。这样具体插入操作的完成。</li>
</ul>

<p><img src="media/14594286280881/20160331111508.jpg" alt="20160331111508"/></p>

<p><strong>删除(delete)操作：</strong></p>

<ul>
<li>首先查找<code>B+-tree</code>中需删除的元素，如果该元素在<code>B+-tree</code>中存在，则将该元素在其结点中进行删除</li>
<li>如果删除该元素后，首先判断该元素是否有左右孩子结点，如果有，则上移孩子结点中的某相近元素到父节点中，然后是移动之后的情况；如果没有，直接删除后，移动之后的情况。</li>
</ul>

<p>删除元素，移动相应元素之后，如果某结点中元素数目小于<code>ceil(m/2)-1</code>，则需要看其某相邻兄弟结点是否丰满（结点中元素个数大于<code>ceil(m/2)-1</code>），<strong>如果丰满，则向父节点借一个元素来满足条件</strong>；<strong>如果其相邻兄弟都刚脱贫</strong>，即借了之后其结点数目小于<code>ceil(m/2)-1</code>，<strong>则该结点与其相邻的某一兄弟结点进行“合并”成一个结点</strong>，以此来满足条件</p>

<h5 id="toc_9">依次删除<code>H</code>, <code>T</code>, <code>R</code>, <code>E</code></h5>

<ul>
<li>首先删除元素<code>H</code>，当然首先查找<code>H</code>，<code>H</code>在一个叶子结点中，且该叶子结点元素数目3大于最小元素数目<code>ceil(m/2)-1=2</code>，则操作很简单，咱们只需要移动<code>K</code>至原来<code>H</code>的位置，移动<code>L</code>至<code>K</code>的位置（也就是结点中删除元素后面的元素向前移动）</li>
</ul>

<p><img src="media/14594286280881/20160331121601.jpg" alt="20160331121601"/></p>

<ul>
<li>删除<code>T</code>,因为<code>T</code>没有在叶子结点中，而是在中间结点中找到，咱们发现他的继承者<code>W</code>(字母升序的下个元素)，<strong>将<code>W</code>上移到<code>T</code>的位置</strong>，然后将原包含<code>W</code>的孩子结点中的<code>W</code>进行删除，这里恰好删除<code>W</code>后，该孩子结点中元素个数大于2，无需进行合并操作。</li>
</ul>

<p><img src="media/14594286280881/20160331121602.jpg" alt="20160331121602"/></p>

<ul>
<li>删除<code>R</code>，<code>R</code>在叶子结点中,但是该结点中元素数目为2，删除导致只有1个元素，已经小于最小元素数目<code>ceil(5/2)-1=2</code>,<strong>如果其某个相邻兄弟结点中比较丰满（元素个数大于<code>ceil(5/2)-1=2</code>），则可以向父结点借一个元素，然后将最丰满的相邻兄弟结点中上移最后或最前一个元素到父节点中</strong>，在这个实例中，右相邻兄弟结点中比较丰满（3个元素大于2），所以先向父节点借一个元素<code>W</code>下移到该叶子结点中，代替原来<code>S</code>的位置，<code>S</code>前移；然后<code>X</code>在相邻右兄弟结点中上移到父结点中，最后在相邻右兄弟结点中删除<code>X</code>，后面元素前移。</li>
</ul>

<p><img src="media/14594286280881/20160331121603.jpg" alt="20160331121603"/></p>

<ul>
<li><strong>删除<code>E</code>，删除后会导致很多问题</strong>，因为<code>E</code>所在的结点数目刚好达标，刚好满足最小元素个数<code>（ceil(5/2)-1=2）</code>,而相邻的兄弟结点也是同样的情况，删除一个元素都不能满足条件，所以<strong>需要该节点与某相邻兄弟结点进行合并操作</strong>；<strong>首先移动父结点中的元素</strong>（该元素在两个需要合并的两个结点元素之间）<strong>下移到其子结点中</strong>，<strong>然后将这两个结点进行合并成一个结点</strong>。所以在该实例中，<strong>咱们首先将父节点中的元素<code>D</code>下移到已经删除<code>E</code>而只有<code>F</code>的结点中，然后将含有<code>D</code>和<code>F</code>的结点和含有<code>A</code>, <code>C</code>的相邻兄弟结点进行合并成一个结点</strong>。</li>
</ul>

<p><img src="media/14594286280881/20160331121604.jpg" alt="20160331121604"/><br/>
<img src="media/14594286280881/20160331121605.jpg" alt="20160331121605"/></p>

<p>应文件系统所需而产生的一种<code>B+-tree</code>的变形树</p>

<h5 id="toc_10"><code>B+-tree</code>的特性：</h5>

<ol>
<li>所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的；</li>
<li>不可能在非叶子结点命中；</li>
<li>非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层；</li>
<li>更适合文件索引系统；</li>
</ol>

<h5 id="toc_11"><code>B+-树</code>比<code>B--tree</code>更适合实际应用中操作系统的文件索引和数据库索引的原因</h5>

<ol>
<li><strong><code>B+-tree</code>的磁盘读写代价更低</strong>：<code>B+-tree</code>的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对<code>B--tree</code>更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说<code>IO</code>读写次数也就降低了。</li>
<li><strong><code>B+-tree</code>的查询效率更加稳定</strong>：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</li>
</ol>

<h5 id="toc_12"><code>B+tree</code>的应用</h5>

<p><img src="media/14594286280881/201603311516.jpg" alt="201603311516"/></p>

<h3 id="toc_13"><code>B*-tree</code>（红黑树)</h3>

<p><code>B*-tree</code>是<code>B+-tree</code>的变体，<strong>在<code>B+-tree</code>的非根和非叶子结点再增加指向兄弟的指针</strong>；<code>B*-tree</code>定义了非叶子结点关键字个数至少为<code>(2/3)*M</code>，即块的最低使用率为<code>2/3</code>（代替<code>B+树</code>的<code>1/2</code>）</p>

<p><img src="media/14594286280881/201603311517.jpg" alt="201603311517"/></p>

<p><code>B+树</code>的分裂：<strong>当一个结点满时，分配一个新的结点，并将原结点中<code>1/2</code>的数据复制到新结点，最后在父结点中增加新结点的指针</strong>；<strong><code>B+树</code>的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针</strong>。</p>

<p><code>B*树</code>的分裂：<strong>当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中</strong>，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制<code>1/3</code>的数据到新结点，最后在父结点增加新结点的指针。</p>

<p>所以，<strong><code>B*树</code>分配新结点的概率比<code>B+树</code>要低，空间使用率更高</strong>；</p>

<p><strong>小结</strong></p>

<p><code>B树</code>：二叉树，每个结点只存储一个关键字，等于则命中，小于走左结点，大于走右结点；</p>

<p><code>B-树</code>：多路搜索树，每个结点存储<code>M/2</code>到<code>M</code>个关键字，非叶子结点存储指向关键字范围的子结点；所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中；</p>

<p><code>B+树</code>：在<code>B-树</code>基础上，为叶子结点增加链表指针，所有关键字都在叶子结点<br/>
中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中；</p>

<p><code>B*树</code>：在<code>B+树</code>基础上，为非叶子结点也增加链表指针，将结点的最低利用率从<code>1/2</code>提高到<code>2/3</code>；</p>

<p><strong>局限性</strong></p>

<ul>
<li>查找必须从索引列的最左边开始</li>
<li>不能跳过索引中的列进行查询</li>
<li>存储引擎不能优化访问任何在第一个范围条件右边的列</li>
</ul>

<p>访问就只能使用索引的头两列，因为<code>like</code>是范围条件</p>

<h3 id="toc_14">哈希索引（只有<code>memory</code>引擎支持显示的哈希索引）</h3>

<p>建立在哈希表的基础上，只对使用了索引中的每一列精确查找有用。对于每一行计算出内索引的哈希码，把哈希码保存在索引中，并且保存一个指向哈希表中每一行的指针<br/>
其检索效率非常高，索引的检索可以一次定位</p>

<h5 id="toc_15">哈希索引的弊端</h5>

<ul>
<li><code>Hash</code>索引仅仅能满足<code>=</code>, <code>IN</code>和<code>&lt;=&gt;</code>查询，<strong>不能使用范围查询</strong>。</li>
</ul>

<p>由于<code>Hash</code>索引比较的是进行<code>Hash</code>运算之后的<code>Hash</code>值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的<code>Hash</code>算法处理之后的<code>Hash</code>值的大小关系，并不能保证和<code>Hash</code>运算前完全一样。</p>

<ul>
<li>`<code>Hash</code>索引无法被用来避免数据的排序操作。</li>
</ul>

<p>由于<code>Hash</code>索引中存放的是经过<code>Hash</code>计算之后的<code>Hash</code>值，而且<code>Hash</code>值的大小关系并不一定和<code>Hash</code>运算前的键值完全一样，所以数据库<strong>无法利用索引的数据来避免任何排序运算</strong>。</p>

<ul>
<li><code>Hash</code>索引<strong>不能利用部分索引键查询</strong>。</li>
</ul>

<p>对于组合索引，<code>Hash</code>索引在计算<code>Hash</code>值的时候是组合索引键合并后再一起计算<code>Hash</code>值，而不是单独计算<code>Hash</code>值，所以通过组合索引的前面一个或几个索引键进行查询的时候，<code>Hash</code>索引也无法被利用。</p>

<ul>
<li><code>Hash</code>索引<strong>在任何时候都不能避免表扫描</strong>。</li>
</ul>

<p>前面已经知道，<code>Hash</code>索引是将索引键通过<code>Hash</code>运算之后，将<code>Hash</code>运算结果的<code>Hash</code>值和所对应的行指针信息存放于一个<code>Hash</code>表中，由于不同索引键存在相同<code>Hash</code>值，所以即使取满足某个<code>Hash</code>键值的数据的记录条数，也无法从<code>Hash</code>索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。</p>

<ul>
<li><code>Hash</code>索引<strong>遇到大量<code>Hash</code>值相等的情况后性能并不一定就会比<code>B-Tree</code>索引高</strong>。</li>
</ul>

<p>对于选择性比较低的索引键，如果创建<code>Hash</code>索引，那么将会存在大量记录指针信息存于同一个<code>Hash</code>值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下。</p>

<p>对使用索引的每一列的精确查找有用</p>

<h3 id="toc_16">空间索引（<code>MYISAM</code>必须使用<code>MYSQL</code>的<code>GIS</code>函数）</h3>

<p>空间索引介于空间操作算法和空间对象之间，它通过筛选作用，大量与特定空间操作无关的空间对象被排除，从而提高空间操作的速度和效率</p>

<p>常见空间索引类型有BSP树、K－D－B树、R树、R+树和CELL树</p>

<h3 id="toc_17">全文索引（<code>MYISAM</code>的一种特殊索引）</h3>

<pre><code>CREATE TABLE articles (id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY, title VARCHAR(200),body TEXT,FULLTEXT (title,body));
</code></pre>

<p>上面这是创建表的<code>mysql</code>语句，<strong>其中最后一句<code>FULLTEXT (title,body)</code></strong> <br/>
<code>SELECT</code>表字段<code>FROM</code>表名<code>WHERE MATCH</code>(全文搜索表字段)<code>AGAINST</code>(&#39;搜索字符串&#39;);</p>

<p><code>MATCH</code>相当于要找的列， 而<code>AGAINST</code>就是要找的内容。</p>

<h2 id="toc_18">高性能索引策略</h2>

<ul>
<li>隔离列（不是表达式的一部分，不能位于函数中）</li>
</ul>

<pre><code class="language-mysql">mysql&gt; select ... where TO_DAYS(CURRENT_DATE) - TO_DAYS(date_col)&lt;=10;
    
mysql&gt; select ... where data_cool &gt;= DATE_SUB(CURRENT_DATE,INTERVAL 10 DAY);
</code></pre>

<ul>
<li>前缀索引和索引选择性（不重复的索引值（基数）/表中所有行），唯一索引的选择率为1最佳，前缀的选择率接近<code>0.31</code></li>
</ul>

<pre><code class="language-mysql">SELECT COUNT(DISTINCT LEFT(city,3))/COUNT(*) AS SEL3,   COUNT(DISTINCT LEFT(city,4))/COUNT(*) AS SEL4, 
    COUNT(DISTINCT LEFT(city,5))/COUNT(*) AS SEL5…FROM TABLE_NAME; 
</code></pre>

<p>前缀索引不能用于<code>order by</code>或<code>group by</code></p>

<p>后缀索引，但是mysql不支持反向索引，可以保存反向字符，然后索引前缀</p>

<ul>
<li>聚集索引(<code>NONCLUSTERED</code>无论是聚集索引还是非聚集索引都是B树结构。)</li>
</ul>

<p>数据库表行中数据的物理顺序与键值的逻辑（索引）顺序相同。一个表只能有一个聚集索引，因为一个表的物理顺序只有一种情况，所以，对应的聚集索引只能有一个。如果某索引不是聚集索引，则表中的行物理顺序与索引顺序不匹配，与非聚集索引相同，聚集索引有着更快的检索速度。</p>

<p><code>innoDB</code>按照主键进行聚集，无主键使用唯一非空索引，无此索引会定义隐藏主键然后聚集，只聚集同一页的数据</p>

<p>聚类和非聚类对比图：</p>

<p><img src="media/14594286280881/201603311622.jpg" alt="201603311622"/></p>

<p>优点：</p>

<ol>
<li>相关数据保存在一起</li>
<li>数据访问快</li>
</ol>

<p>缺点:</p>

<ol>
<li>插入速度依赖于插入顺序</li>
<li>更新聚集索引代价昂贵</li>
<li>聚集索引表插入新行或行的主键被更新会占用更多的磁盘</li>
<li>聚集表可能比权标扫描慢</li>
<li>非聚类索引需要两次索引查找（找行主键-&gt;找主键保存的数据）</li>
</ol>

<p>适用情况：</p>

<ol>
<li>含有大量非重复值的列。</li>
<li>使用<code>BETWEEN</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>或<code>&lt;=</code>返回一个范围值的列</li>
<li>被连续访问的列</li>
<li>返回大型结果集的查询</li>
<li><p>经常被使用连接或<code>GROUP BY</code>子句的查询访问的列</p></li>
</ol>

<ul>
<li>覆盖索引：包含所有满足查询需要的数据的索引，<code>mysql</code>只能用<code>B-tree</code></li>
</ul>

<p>以<code>innodb</code>引擎</p>

<pre><code class="language-mysql">EXPLAIN SELECT id, name FROM table_name  WHERE name = ‘HOPPER’
</code></pre>

<p><code>Extra:Using where;Using index</code> 此处覆盖取得主键查询</p>

<ul>
<li><p>为排序使用索引扫描</p>

<p>产生排序的方式：文件排序，扫描有序索引</p></li>
</ul>

<pre><code>CREATE TABLE a(
… PRIMARY KEY(id),UNIQUE KEY date(date,nid,cid))
KEY idx_fk_nid(nid), KEY idx_fk_cid(cid)…);

SELECT id FROM table_name where date=&quot;2015-12-16&quot; ORDER BY nid,cid;
</code></pre>

<p>能工作<code>where date=&quot;2015-12-16&quot; ORDER BY nid,cid;</code>形成最左前缀</p>

<blockquote>
<p>注意事项：</p>

<p>索引<code>where</code>（非范围条件）和<code>order</code>形成最左端索引</p>

<p><code>order by</code>中的两列为最左前缀，使用相同的排序方向</p>
</blockquote>

<ul>
<li><p>前缀压缩索引（<code>PACK_KEYS</code>） 第一个值全排序，有相同前缀的，字节+后缀</p>

<p>缺点：<code>cpu</code>密集的负载慢几倍</p></li>
<li><p>避免多余和重复索引（类型相同，同样的顺序在同样的列上创建）</p>

<p>多余：索引（<code>a</code>, <code>b</code>）索引<code>a</code>多余，索引<code>b</code>不多余</p></li>
<li><p>索引和锁定 （从索引的开头开始，提取到满足第一个条件的行结束）</p></li>
</ul>

<h3 id="toc_19">索引的实例研究</h3>

<ul>
<li>支持多种过虑条件</li>
<li>避免多个范围条件只能第一个索引有效</li>
<li><p>优化排序 </p>

<p>只提取最终需要行的主键列，在把它联接回去一取得所有需要的列mysql语句：</p></li>
</ul>

<pre><code class="language-mysql">SELECT &lt;clos&gt; FROM table_name INNER JOIN (
    SELECT &lt;primary key cols&gt; FROM table_name where x.a=&quot;m&quot; ORDER BY rating LIMIT 100000,10) AS X USING(primary key cols)
</code></pre>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Java序列化]]></title>
        <link href="http://nathanchen.github.io/14594277278701.html"/>
        <updated>2016-03-31T20:35:27+08:00</updated>
        <id>http://nathanchen.github.io/14594277278701.html</id>
        <content type="html"><![CDATA[
<blockquote>
<p><strong>序列化</strong>：一种将对象以一连串的字节描述的过程<br/>
<strong>反序列化</strong>：一种将这些字节重建成一个对象的过程</p>
</blockquote>

<h3 id="toc_0">序列化的应用场景</h3>

<ul>
<li>当你想把的内存中的对象保存到一个文件中或者数据库中时候(数据持久化)；</li>
<li>当你想用套接字在网络上传送对象的时候；</li>
<li>当你想通过RMI传输对象的时候；
<code>Java RMI 支持存储于不同地址空间的程序级对象之间彼此进行通信，实现远程对象之间的无缝远程调用</code></li>
</ul>

<h3 id="toc_1">实现序列化</h3>

<p>将需要序列化的类实现<code>Serializable</code>接口就可以了，<code>Serializable</code>接口中没有任何方法，可以理解为一个标记，即表明这个类可以序列化.</p>

<h4 id="toc_2">序列化例子</h4>

<pre><code class="language-java">FileOutputStream fos = new FileOutputStream(&quot;serialize.obj&quot;);  
ObjectOutputStream oos = new ObjectOutputStream(fos);  
Serialize serialize = new Serialize();  
oos.writeObject(serialize);  
oos.flush();  
oos.close();
fos.close();  
</code></pre>

<h4 id="toc_3">反序列化例子</h4>

<pre><code class="language-java">FileInputStream fis = new FileInputStream(&quot;serialize.obj&quot;);  
ObjectInputStream ois = new ObjectInputStream(fis);  
serialize = (Serialize) ois.readObject();  
ois.close();  
fis.close();  
</code></pre>

<h3 id="toc_4">相关注意事项</h3>

<ul>
<li>序列化时，只对对象的状态进行保存，而不管对象的方法；</li>
<li><strong>当一个父类实现序列化，子类自动实现序列化</strong>，不需要显式实现<code>Serializable</code>接口；</li>
<li>当一个对象的实例变量引用其他对象，序列化该对象时也把引用对象进行序列化；</li>
<li>并非所有的对象都可以序列化，至于为什么不可以，有很多原因了,比如：

<ol>
<li>安全方面的原因，比如一个对象拥有<code>private</code>，<code>public</code>等<code>field</code>，对于一个要传输的对象，比如写到文件，或者进行<code>rmi</code>传输  等等，在序列化进行传输的过程中，这个对象的private等域是不受保护的。</li>
<li>资源分配方面的原因，比如<code>socket</code>，<code>thread</code>类，如果可以序列化，进行传输或者保存，也无法对他们进行重新的资源分配，而且也是没有必要这样实现。</li>
</ol></li>
</ul>

<h3 id="toc_5">序列化前和序列化后的对象的关系</h3>

<p>序列化时深复制，反序列化还原后的对象地址与原来的不同。</p>

<p><strong>不同的原因：</strong><br/>
通过序列化操作,我们可以实现对任何可Serializable对象的”深度复制（deep copy）&quot;——这意味着我们复制的是整个对象网，而不仅仅是基本对象及其引用。对于同一流的对象，他们的地址是相同，说明他们是同一个对象，但是与其他流的对象地址却不相同。也就说，只要将对象序列化到单一流中，就可以恢复出与我们写出时一样的对象网，而且只要在同一流中，对象都是同一个。</p>

<h3 id="toc_6">破坏单例模式</h3>

<p>单例是要求一个<code>JVM</code>中只有一个类对象的, 而现在通过反序列化,一个新的对象克隆了出来.</p>

<pre><code class="language-java">package com.serialize;

import java.io.Serializable;

public class SerSingleton implements Serializable
{
    private static final long serialVersionUID = 1L;
    
    String name;
    
    private SerSingleton()
    {
        System.out.println(&quot;Singleton is create&quot;);
        name=&quot;SerSingleton&quot;;
    }
    
    private static SerSingleton instance = new SerSingleton();
    
    public static SerSingleton getInstance()
    {
        return instance;
    }
    
    public static void createString()
    {
        System.out.println(&quot;createString in Singleton&quot;);
    }
}

@Test
public void test() throws IOException, ClassNotFoundException
{
    SerSingleton s1= null;
    SerSingleton s = SerSingleton.getInstance();
    
    FileOutputStream fos = new FileOutputStream(&quot;SerSingleton.obj&quot;);
    ObjectOutputStream oos = new ObjectOutputStream(fos);
    oos.writeObject(s);
    oos.flush();
    oos.close();
    
    FileInputStream fis = new FileInputStream(&quot;SerSingleton.obj&quot;);
    ObjectInputStream ois = new ObjectInputStream(fis);
    s1 = (SerSingleton)ois.readObject();
    System.out.println(s==s1);
}
    
----------
private Object readResolve()  
{  
    return instance;  
}  
</code></pre>

<blockquote>
<p>输出<code>false</code></p>
</blockquote>

<p>说明测试代码中的<code>s</code>和<code>s1</code>指向了不同的实例，在反序列化后，生成多个对象实例。</p>

<p>加上第二部分代码：这样当<code>JVM</code>从内存中反序列化地<q>组装</q>一个新对象时,就会自动调用这个<code>readResolve</code>方法来返回我们指定好的对象了, 单例规则也就得到了保证.</p>

<h3 id="toc_7">序列化ID</h3>

<p>序列化<code>ID</code>在<code>Eclipse</code>下提供了两种生成策略，一个是固定的<code>1L</code>，一个是随机生成一个不重复的<code>long</code>类型数据（实际上是使用<code>JDK</code>工具生成），在这里有一个建议，如果没有特殊需求，就是用默认的<code>1L</code>就可以，这样可以确保代码一致时反序列化成功。这也可能是造成序列化和反序列化失败的原因，因为不同的序列化id之间不能进行序列化和反序列化。</p>

<h3 id="toc_8">静态变量能否序列化</h3>

<p>序列化会忽略静态变量，即序列化不保存静态变量的状态。静态成员属于类级别的，所以不能序列化。即 序列化的是对象的状态不是类的状态。这里的不能序列化的意思，是序列化信息中不包含这个静态成员域。transient后的变量也不能序列化。</p>

<h3 id="toc_9">transient小结</h3>

<ol>
<li><p>一旦变量被<code>transient</code>修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。</p></li>
<li><p><code>transient</code>关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被<code>transient</code>关键字修饰的。变量如果是用户自定义类变量，则该类需要实现<code>Serializable</code>接口。</p></li>
<li><p>被<code>transient</code>关键字修饰的变量不再能被序列化，一个静态变量不管是否被<code>transient</code>修饰，均不能被序列化。</p></li>
</ol>

<h3 id="toc_10">注意：</h3>

<p><code>Java</code>对象序列化不仅保留一个对象的数据，而且递归保存对象引用的每个对象的数据 </p>

<p>对象的序列化可以通过实现两种接口来实现，若实现的是<code>Serializable</code>接口，则所有的序列化将会自动进行，若实现的是<code>Externalizable</code>接口，则没有任何东西可以自动序列化，需要在<code>writeExternal</code>方法中进行手工指定所要序列化的变量，这与是否被<code>transient</code>修饰无关</p>

<h3 id="toc_11">总结</h3>

<ol>
<li>当父类继承<code>Serializable</code>接口时，所有子类都可以被序列化。</li>
<li>子类实现了<code>Serializable</code>接口，父类没有，父类中的属性不能被序列化（不报错，数据不会丢失）但是在子类中的属性仍能正确序列化</li>
<li>如果序列化的属性是对象，则这个对象也必须实现<code>Serializable</code>接口，否则会报错。</li>
<li>在反序列化时，如果对象的属性有修改或删减，则修改的部分属性会丢失，但不会报错。</li>
<li>在反序列化时，如果<code>serialVersionUID</code>被序列化，则反序列化时会失败</li>
<li>当一个对象的实例变量引用其他对象，序列化改对象时，也把引用对象进行序列化</li>
<li><code>static</code>，<code>transient</code>后的变量不能被序列化</li>
</ol>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Java传值还是传引用]]></title>
        <link href="http://nathanchen.github.io/14594153252228.html"/>
        <updated>2016-03-31T17:08:45+08:00</updated>
        <id>http://nathanchen.github.io/14594153252228.html</id>
        <content type="html"><![CDATA[
<p><code>Java</code>都是按值传递的。</p>

<p>我们要这样去理解这个问题：</p>

<pre><code class="language-java">Dog myDog;
</code></pre>

<p><code>myDog</code>并不是一个<code>Dog</code>，而是一个指针指向了一个<code>Dog</code>对象。</p>

<pre><code class="language-java">Dog myDog = new Dog(&quot;Rover&quot;);
foo(myDog);
</code></pre>

<p>这个程序实际上是将<code>new Dog(&quot;Rover&quot;)</code>这个对象地址的值给了<code>foo</code>方法</p>

<p>假设<code>new Dog(&quot;Rover&quot;)</code>这个对象在内存地址的<code>42</code>，也就是说我们将<code>42</code>这个地址给了<code>foo</code>方法</p>

<pre><code class="language-java">public void foo(Dog someDog) 
{
    someDog.setName(&quot;Max&quot;);     // AAA
    someDog = new Dog(&quot;Fifi&quot;);  // BBB
    someDog.setName(&quot;Rowlf&quot;);   // CCC
}
</code></pre>

<ul>
<li><code>someDog</code>被设置为了<code>42</code></li>
<li>在<code>AAA</code>行

<ul>
<li>someDog这个对象（<code>42</code>）被要求改名为<code>Max</code></li>
</ul></li>
<li>在<code>BBB</code>行

<ul>
<li>生成一个新的<code>Dog</code>对象，比如说在地址<code>74</code></li>
<li>我们将<code>someDog</code>这个对象设置成<code>74</code></li>
</ul></li>
<li>在<code>CCC</code>行

<ul>
<li><code>someDog</code>这个对象（<code>74</code>）被要求改名为<code>Rowlf</code></li>
</ul></li>
<li>最后，我们返回结果</li>
</ul>

<p>因为我们传的只是<code>42</code>这个内存地址的值，所以返回后，<code>someDog</code>还是（<code>42</code>），只是他的名字变成了<code>Max</code></p>

<h3 id="toc_0">Reference</h3>

<p><a href="http://stackoverflow.com/questions/40480/is-java-pass-by-reference-or-pass-by-value">http://stackoverflow.com/questions/40480/is-java-pass-by-reference-or-pass-by-value</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[`Local Storage`缓存]]></title>
        <link href="http://nathanchen.github.io/14592202648535.html"/>
        <updated>2016-03-29T10:57:44+08:00</updated>
        <id>http://nathanchen.github.io/14592202648535.html</id>
        <content type="html"><![CDATA[
<p>因为<code>WAP触屏版</code>的面向对象都是使用智能手机浏览器访问的用户，而基本上所有智能手机的浏览器都支持<code>Local Storage</code>，这样就可以使用<code>Local Storage</code>缓存一些东西。</p>

<p>之前都是使用<code>Local Storage</code>缓存一些用户信息，当做<code>cookies</code>使用，甚至还有一段时间<code>Local Storage</code>里的内容不能通过浏览器‘清楚访问痕迹’的功能删除，就使用<code>Local Storage</code>作为存储用户唯一标识的地方。</p>

<p>现在为<code>WAP触屏版</code>的优化思路就是将<code>js</code>和<code>css</code>文件存到<code>Local Storage</code>中，用户之后访问需要<code>js</code>和<code>css</code>的时候都从<code>Local Storage</code>中取，而不从网络中拉了。</p>

<p>美团的<code>WAP触屏版</code>是一个做的比较极端的例子</p>

<p><img src="media/14592202648535/14592207018764.jpg" alt=""/></p>

<h3 id="toc_0">第一阶段</h3>

<p>其实对于规模不是很大的网站，上线的流程不会特别严格，特别规范，那么对<code>css</code>和<code>js</code>经常的修修补补是不可避免的。如果使用<code>Local Storage</code>缓存所有的<code>css</code>和<code>js</code>，那么就还要制定一套<code>Local Storage</code>缓存失效的规则。所以我们暂时先只对用到的第三方<code>js</code>和<code>css</code>（<code>jquery</code>，<code>Framework7</code>等）进行缓存</p>

<p>参考了《Web移动端使用localStorage缓存Js和css文件》<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup>，这套代码基本实现了使用<code>Local Storage</code>缓存<code>js</code>和<code>css</code>文件的基本需求，对于简单的网站页面效果也是明显的。</p>

<p>但是有两个问题：</p>

<p>1、不能跨域。程序是用<code>ajax</code>请求<code>css</code>和<code>js</code>的，由于<code>ajax</code>不能跨域，所以必须保证静态资源文件和网站要在同一个域名下，这个跟动静分离的思想有所违背。<strong>比较糙的解决方法就是将要缓存的文件映射一份在网站同域名下。</strong></p>

<p>2、文件不能顺序加载。程序在拿到<code>css</code>和<code>js</code>文件后，将这些文件的内容<code>head.appendChild(js/css)</code>到<code>html</code>中，这样会让这些文件同步加载到<code>html</code>中，而缓存的文件加载的顺序不能保证一定在非缓存文件之前，如果之后的<code>js</code>的文件依赖于缓存的<code>js</code>先加载，那么就会报错。</p>

<p>举个例子：</p>

<pre><code class="language-html">&lt;head&gt;
    &lt;script&gt;
        whir.res.loadJs(&quot;jquery&quot;, __BASE_SERVER__ + &quot;/js/jquery-1.8.3.min.js&quot;);
    &lt;/script&gt;
    &lt;script type=&quot;text/javascript&quot; src=&quot;${__static_server__}/js/needsJQUERY.js&quot;&gt;&lt;/script&gt;
&lt;/head&gt;
</code></pre>

<p>第二个文件需要<code>jquery</code>先加载，然后使用<code>jquery</code>的函数，但是<code>jquery</code>被缓存，且不能保证会在第二个文件处理前加载好。这样就会报错。</p>

<p>程序对顺序加载的解决方案是使用回调函数，保证数序：</p>

<pre><code class="language-html">whir.res.loadJs(&quot;jquery&quot;, __BASE_SERVER__ + &quot;/js/jquery-1.8.3.min.js&quot;), function(){
    whir.res.loadJs(&quot;needsJQUERY&quot;, &quot;/needsJQUERY.js&quot;);  
});
</code></pre>

<p>这种解决的方法对于结构简单的页面是有效的，但是我们的页面都是依赖一个公用的宏，在公用的宏中申明了所有地方放的<code>js</code>和<code>css</code>，每个页面自己又有一套本页面有效的<code>js</code>和<code>css</code>，对于这种<code>callback</code>随页面变化的情况，前面说的解决方法不太适用。</p>

<p><strong>比较糙的解决方法就是在加载最后一个缓存<code>js</code>文件的时候，<code>callback</code>方法中写<code>location.reload();</code>，页面强行刷新下</strong>。</p>

<h3 id="toc_1">第二阶段</h3>

<p>第二个问题相对来说更棘手，所以我们先要解决这个问题。</p>

<p>我们的思路是这样的：</p>

<ul>
<li>对于第一次来网站的用户，<code>Local Storage</code>为空，我们先使用正常的<code>js</code>和<code>css</code>引用的方法，然后再将<code>js</code>和<code>css</code>放入<code>Local Storage</code>中，但这一次不用<code>Local Storage</code>中缓存的文件</li>
<li>对于之前来过网站的用户，<code>Local Storage</code>是有缓存的<code>js</code>和<code>css</code>，所以直接使用这些缓存的文件</li>
</ul>

<p>判别用户之前有没有来过网站，我们就拿一个<code>cookie</code>来记录，如果用户有这个<code>cookie</code>值，则判断用户来过；如果没有这个值，则判断用户没有来过。</p>

<p>再者，如果用户的这个<code>cookie</code>值和我们<code>pageVersion</code>不一样，说明我们要缓存的<code>js</code>或者<code>css</code>版本号改变了，这时候，我们会先让<code>cookie</code>为空，将用户理解为一个全新的、第一次来的用户，然后继续整个流程。</p>

<p>这样好像就解决了用户第一次来，还要强制刷新页面的问题。<strong>直到我们用<code>safari</code>或者<code>uc</code>浏览器无痕浏览的功能访问网站的时候</strong>。</p>

<p><code>safari</code>的无痕浏览模式不支持<code>Local Storage</code>，并且会在<code>localstorage.setItem</code>的时候报错，自动停止程序，导致咱们缓存<code>js</code>和<code>css</code>时，用户访问的cookie写成功了，但是缓存没写进去。</p>

<p><code>uc</code>浏览器的无痕浏览模式也不支持<code>Local Storage</code>，并且在将<code>cookie</code>值更改以后，新旧两个<code>cookie</code>都会同时存在，这样我们的程序就变成了死循环，检测到用户访问过，以为有缓存，实际没有。</p>

<p>所以我们对程序又做了修正:</p>

<ul>
<li>将添加<code>cookie</code>操作加入到<code>loadJs</code>的回调函数中</li>
<li>在保证<code>localstorage.setItem</code>成功运行之后，我们才会把<code>cookie</code>值记录进去</li>
</ul>

<pre><code>&lt;script type=&quot;text/javascript&quot; src=&quot;${__static_server__}/js/localstorage.js&quot;&gt;&lt;/script&gt;
&lt;#if local_storage_version != &#39;&#39;&gt;
    &lt;script&gt;
        var lsv = &quot;&quot;;
        var name = &quot;lsv=&quot;;
        var ca = document.cookie.split(&quot;;&quot;);
        for (var i = 0; i &lt; ca.length; i++) {
            var c = ca[i];
            while (c.charAt(0) == &quot; &quot;) {
                c = c.substring(1);
            }
            if (c.indexOf(name) == 0) {
                lsv = c.substring(name.length, c.length);
            }
        }
        if (lsv != whir.res.pageVersion || (window.localStorage &amp;&amp; lsv != localStorage.getItem(&quot;version&quot;))) {
            var d = new Date();
            d.setTime(d.getTime() + (365 * 24 * 60 * 60 * 1000));
            var expires = &quot;expires=&quot; + d.toUTCString();
            document.cookie = &quot;lsv=;&quot; + expires;
            location.reload();
        }
    &lt;/script&gt;
&lt;#else&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;${__static_server__}/js/jquery-1.8.3.min.js&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;${__static_server__}/js/framework7/js/framework7.min.js&quot;&gt;&lt;/script&gt;
&lt;/#if&gt;
&lt;script&gt;
    whir.res.loadJs(&quot;jquery&quot;, __BASE_SERVER__ + &quot;/js/jquery-1.8.3.min.js&quot;);           whir.res.loadJs(&quot;framework7js&quot;, __BASE_SERVER__ + &quot;/js/framework7/js/framework7.min.js&quot;, function () {
            myApp = new Framework7();
            $$ = Dom7;
            $.cookie(&#39;lsv&#39;, whir.res.pageVersion, {path: &#39;/&#39;, expires: 365});
        });
&lt;/script&gt;
</code></pre>

<blockquote>
<p>localstorage.js</p>
</blockquote>

<pre><code class="language-javascript">var whir = window.whir || {};
var refreshYN = false;
whir.res = {
    pageVersion: &quot;121&quot;, //页面版本，由页面输出，用于刷新localStorage缓存
    //动态加载js文件并缓存
    loadJs: function (name, url, callback) {
        if (window.localStorage) {
            var xhr;
            var js = localStorage.getItem(name);
            if (js == null || js.length == 0 || this.pageVersion != localStorage.getItem(&quot;version&quot;)) {
                refreshYN = true;
                if (window.ActiveXObject) {
                    xhr = new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;);
                } else if (window.XMLHttpRequest) {
                    xhr = new XMLHttpRequest();
                }
                if (xhr != null) {
                    xhr.open(&quot;GET&quot;, url);
                    xhr.send(null);
                    xhr.onreadystatechange = function () {
                        if (xhr.readyState == 4 &amp;&amp; xhr.status == 200) {
                            js = xhr.responseText;
                            localStorage.setItem(name, js);
                            localStorage.setItem(&quot;version&quot;, whir.res.pageVersion);
                            // 确保浏览器支持localStorage.setItem
                            if (localStorage.getItem(&quot;version&quot;) == whir.res.pageVersion) {
                                if (callback != null) {
                                    callback(); //回调，执行下一个引用
                                }
                            }
                        }
                    };
                }
            } else {
                whir.res.writeJs(js);
                if (callback != null) {
                    callback(); //回调，执行下一个引用
                }
            }
        } else {
            whir.res.linkJs(url);
        }
    },
    loadCss: function (name, url) {
        if (window.localStorage) {
            var xhr;
            var css = localStorage.getItem(name);
            if (css == null || css.length == 0 || this.pageVersion != localStorage.getItem(&quot;version&quot;)) {
                if (window.ActiveXObject) {
                    xhr = new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;);
                } else if (window.XMLHttpRequest) {
                    xhr = new XMLHttpRequest();
                }
                if (xhr != null) {
                    xhr.open(&quot;GET&quot;, url);
                    xhr.withCredentials = true;
                    xhr.send(null);
                    xhr.onreadystatechange = function () {
                        if (xhr.readyState == 4 &amp;&amp; xhr.status == 200) {
                            css = xhr.responseText;
                            localStorage.setItem(name, css);
                            localStorage.setItem(&quot;version&quot;, whir.res.pageVersion);
                        }
                    };
                }
            } else {
                css = css.replace(/images\//g, &quot;style/images/&quot;); //css里的图片路径需单独处理
                whir.res.writeCss(css);
            }
        } else {
            whir.res.linkCss(url);
        }
    },
    //往页面写入js脚本
    writeJs: function (text) {
        var head = document.getElementsByTagName(&#39;HEAD&#39;).item(0);
        var link = document.createElement(&quot;script&quot;);
        link.type = &quot;text/javascript&quot;;
        link.innerHTML = text;
        head.appendChild(link);
    },
    //往页面写入css样式
    writeCss: function (text) {
        var head = document.getElementsByTagName(&#39;HEAD&#39;).item(0);
        var link = document.createElement(&quot;style&quot;);
        link.type = &quot;text/css&quot;;
        link.innerHTML = text;
        head.appendChild(link);
    },
    //往页面引入js脚本
    linkJs: function (url) {
        var head = document.getElementsByTagName(&#39;HEAD&#39;).item(0);
        var link = document.createElement(&quot;script&quot;);
        link.type = &quot;text/javascript&quot;;
        link.src = url;
        head.appendChild(link);
    },
    //往页面引入css样式
    linkCss: function (url) {
        var head = document.getElementsByTagName(&#39;HEAD&#39;).item(0);
        var link = document.createElement(&quot;link&quot;);
        link.type = &quot;text/css&quot;;
        link.rel = &quot;stylesheet&quot;;
        link.rev = &quot;stylesheet&quot;;
        link.media = &quot;screen&quot;;
        link.href = url;
        head.appendChild(link);
    }
};
</code></pre>

<h3 id="toc_2">第三阶段</h3>

<p>对于跨域的处理，我们采用了<code>CORS</code>的方式，主要就是在<code>Nginx</code>服务器上配置一下，比较简便。</p>

<div class="footnotes">
<hr/>
<ol>

<li id="fn1">
<p><a href="http://blog.csdn.net/a497785609/article/details/48321405">http://blog.csdn.net/a497785609/article/details/48321405</a>&nbsp;<a href="#fnref1" rev="footnote">&#8617;</a></p>
</li>

</ol>
</div>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[应用多级缓存模式支撑海量读服务]]></title>
        <link href="http://nathanchen.github.io/14590098445355.html"/>
        <updated>2016-03-27T00:30:44+08:00</updated>
        <id>http://nathanchen.github.io/14590098445355.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">如何缓存数据</h3>

<h4 id="toc_1">过期与不过期</h4>

<p>不过期缓存的场景一般思路如下：</p>

<p><img src="media/14590098445355/14590098715786.jpg" alt=""/></p>

<p>首先写数据库，如果成功则写缓存。这种机制存在一些问题：</p>

<ul>
<li>事务在提交时失败则写缓存是不会回滚的，造成DB和缓存数据不一致</li>
<li>多个人并发写缓存可能出现脏数据</li>
<li>同步写对性能有一定影响，异步写又存在丢数据的风险</li>
</ul>

<p>如果对缓存数据一致性要求不是那么高，数据量也不是很大，可以考虑定期全量同步缓存。</p>

<p><img src="media/14590098445355/14590100613107.jpg" alt=""/></p>

<ol>
<li>把写缓存改成写消息，通过消息通知数据变更</li>
<li>同步缓存系统会订阅消息，并根据消息进行更新缓存</li>
<li>数据一致性可以采用：消息体只包括ID，然后查库获取最新版本数据；通过时间戳和内容摘要机制（MD5）进行缓存更新</li>
<li>如上方法也不能保证消息不丢失，可以采用：应用在本地记录更新日志，当消息丢失了，回放更新日志</li>
</ol>

<p>过期缓存机制的常见步骤是：首先读取缓存，如果不命中，则查询数据，然后异步写入缓存并设置过期时间，下次读取将命中缓存。</p>

<h3 id="toc_2">Reference</h3>

<p><a href="http://jinnianshilongnian.iteye.com/blog/2283670">http://jinnianshilongnian.iteye.com/blog/2283670</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[浅谈Web缓存]]></title>
        <link href="http://nathanchen.github.io/14589988314853.html"/>
        <updated>2016-03-26T21:27:11+08:00</updated>
        <id>http://nathanchen.github.io/14589988314853.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">浏览器缓存</h3>

<h4 id="toc_1">Cache-Control</h4>

<p>1、<code>max-age</code>（单位为<code>s</code>）当浏览器向服务器发送请求后，在<code>max-age</code>这段时间里浏览器就不会再向服务器发送请求了。<code>max-age</code>会覆盖掉<code>Expires</code>。</p>

<pre><code>max-age=2592000
</code></pre>

<p>也就是说缓存有效期为2592000秒（也就是30天）。于是在30天内都会使用这个版本的资源，即使服务器上的资源发生了变化，浏览器也不会得到通知。</p>

<p>2、<code>s-maxage</code>（单位为<code>s</code>），只用于共享缓存（比如<code>CDN</code>）</p>

<pre><code>s-maxage=60
</code></pre>

<p>在这60秒中，即使更新了<code>CDN</code>的内容，浏览器也不会进行请求。如果存在<code>s-maxage</code>，则会覆盖掉<code>max-age</code>和<code>Expires header</code>。</p>

<p>3、<code>public</code>指定响应会被缓存，并且在多用户间共享。如果没有指定<code>public</code>还是<code>private</code>，则默认为<code>public</code></p>

<p>4、<code>private</code>响应只作为私有的缓存，不能在用户间共享。</p>

<p>5、<code>no-cache</code>指定不缓存响应，表明资源不进行缓存。设置了<code>no-cache</code>之后并不代表浏览器不缓存，而是在缓存前要向服务器确认资源是否被更改。因此有的时候只设置<code>no-cache</code>防止缓存还是不够保险，还可以加上<code>private</code>指令，将过期时间设为过去的时间。</p>

<p>6、<code>no-store</code>绝对禁止缓存</p>

<h4 id="toc_2">Expires</h4>

<p>缓存过期时间，用来指定资源到期的时间，是服务器端的具体的时间点。也就是说，<code>Expires = max-age + 请求时间</code>，需要和<code>Last-modified</code>结合使用。</p>

<h4 id="toc_3">Last-modified</h4>

<p>服务器端文件的最后修改时间，需要和<code>cache-control</code>共同使用，是检查服务器端资源是否更新的一种方式。当浏览器再次进行请求时，会向服务器传送<code>If-Modified-Since</code>报头，询问<code>Last-Modified</code>时间点之后资源是否被修改过。如果没有修改，则返回码为<code>304</code>，使用缓存；如果修改过，则再次去服务器请求资源，返回码和首次请求相同为<code>200</code>，资源为服务器最新资源。</p>

<h4 id="toc_4">ETag</h4>

<p>根据实体内容生成一段<code>hash</code>字符串，标识资源的状态，由服务端产生。浏览器会将这串字符串传回服务器，验证资源是否已经修改</p>

<p><img src="media/14589988314853/14589994585073.jpg" alt=""/></p>

<p>使用<code>ETag</code>可以解决<code>Last-modified</code>存在的一些问题：</p>

<ul>
<li>某些服务器不能精确得到资源的最后修改时间，这样就无法通过最后修改时间判断资源是否更新 </li>
<li>如果资源修改非常频繁，在秒以下的时间内进行修改，而<code>Last-modified</code>只能精确到秒 </li>
<li>一些资源的最后修改时间改变了，但是内容没改变，使用<code>ETag</code>就认为资源还是没有修改的。</li>
</ul>

<h3 id="toc_5">使用缓存流程</h3>

<p><img src="media/14589988314853/14589996373194.jpg" alt=""/></p>

<h3 id="toc_6">其他</h3>

<p><code>LocalStorage</code>是一种本地存储的公共资源，域名下很多应用共享这份资源会有风险；<code>LocalStorage</code>是以页面域名划分的，如果有多个等价域名之间的<code>LocalStorage</code>不互通，则会造成缓存多份浪费。</p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[深入分析`Java I/O`的工作机制]]></title>
        <link href="http://nathanchen.github.io/14588873943004.html"/>
        <updated>2016-03-25T14:29:54+08:00</updated>
        <id>http://nathanchen.github.io/14588873943004.html</id>
        <content type="html"><![CDATA[
<p>不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符，所以<code>I/O</code>操作的都是字节而不是字符。但是我们的程序中通常操作的数据都是字符形式的。</p>

<p>基于字节的<code>I/O</code>操作接口输入和输出分别是<code>InputStream</code>和<code>OutputStream</code></p>

<p>写字符的<code>I/O</code>操作接口涉及的是<code>write(char[] buf, int off, int len)</code></p>

<p>读字符的<code>I/O</code>操作是<code>read(char[] buf, int off, int len)</code></p>

<h4 id="toc_0">字节与字符的转化接口</h4>

<p>数据持久化或网络传输都是以字节进行的，所以必须要有<strong>字符到字节或者字节到字符</strong>的转化。</p>

<h4 id="toc_1">几种访问文件的方式</h4>

<p><strong>读取和写入文件<code>I/O</code>操作都调用操作系统提供的接口</strong>，因为磁盘设备是由操作系统管理的，应用程序要访问物理设备只能通过系统调用的方式来工作。</p>

<p>只要是系统调用就可能存在内核空间地址和用户空间地址切换的问题，这是操作系统为了保护系统本身的运行安全而将内核程序运行使用的内存空间和用户程序运行的内存空间隔离造成的。这样虽然保证了内核程序运行的安全性，但是也必然<strong>存在数据可能需要从内核空间向用户空间复制的问题</strong>。</p>

<p>如果遇到非常耗时的操作，如磁盘<code>I/O</code>，数据从磁盘复制到内核空间，然后又从内核空间复制到用户空间，将会非常缓慢。这时操作系统为了加速<code>I/O</code>访问，在<strong>内核空间使用缓存机制，也就是将从磁盘读取的文件按照一定的组织方式进行缓存</strong>。</p>

<h5 id="toc_2">标准访问文件方式</h5>

<p><strong>当应用程序调用<code>read()</code>接口</strong>时，操作系统检查内核的告诉缓存中有没有需要的数据。如果已经缓存了，那么就直接从缓存中返回；如果没有，从磁盘中读取，然后缓存在操作系统的缓存中。</p>

<p><strong>当应用程序调用<code>write()</code>接口</strong>时，将数据从用户地址空间复制到内核地址空间的缓存中。这时，对用户程序来说，写操作就已经完成了，至于什么时候再写到磁盘中是有操作系统决定的，除非显式地调用<code>sync</code>同步命令</p>

<h5 id="toc_3">直接<code>I/O</code>方式</h5>

<p><strong>应用程序直接访问磁盘数据，而不经过操作系统内核数据缓冲区</strong>，这样做的目的就是减少一次从内核缓冲区到用户程序缓存的数据复制。</p>

<p>这种访问文件的方式通常是在对数据的缓存管理由应用程序实现的数据库管理程序中。（如数据库管理系统中，系统明确地知道应该缓存哪些数据，应该失效哪些数据，还可以对一些热点数据做预加载，提前将热点数据加载到内存，可以加速数据的访问效率；而操作系统并不知道哪些是热点数据，只是简单地缓存最近一次从磁盘读取的数据）</p>

<p><strong>缺点：如果访问的数据不在应用程序缓存中，那么每次数据都会直接从磁盘加载。这种直接加载会非常缓慢</strong>。</p>

<h5 id="toc_4">同步访问文件方式</h5>

<p><strong>数据的读取和写入都是同步操作的</strong>，它与标准访问文件方式不同的是，<strong>只有当数据被成功写到磁盘时才返回给应用程序成功标志</strong>。</p>

<p>这种访问文件方式<strong>性能比较差</strong>，只有在一些对数据安全性要求比较高的场景中才会使用，而且通常这种操作方式的硬件都是定制的。</p>

<h5 id="toc_5">异步访问文件方式</h5>

<p><strong>当访问数据的线程发出请求之后，线程会接着去处理其他事情</strong>，而不是阻塞等待，当请求的数据返回后继续处理下面的操作。这种访问文件的方式可以明显地提高应用程序的效率，但是不会改变访问文件的效率。</p>

<h5 id="toc_6">内存映射方式</h5>

<p>内存映射方式是指操作系统将内存中的某一块区域与磁盘中的文件关联起来，当要访问内存中一段数据时，转换为访问文件的某一段数据。这种方式的目的同样是减少数据从内核空间缓存到用户空间缓存的数据复制操作，因为这两个空间的数据是共享的。</p>

<h4 id="toc_7">Java访问磁盘文件</h4>

<p>数据在磁盘中的唯一最小描述就是文件，也就是说上层应用程序只能通过文件来操作磁盘上的数据，文件也是操作系统和磁盘驱动器交互的最小单元。</p>

<p><code>Java</code>中通常的<code>File</code>并不代表一个真实存在的文件对象，当你指定一个路径描述符时，它就会返回一个代表这个路径的一个虚拟对象，这个可能是一个真实存在的文件或者是一个包含多个文件的目录。</p>

<p>如何从磁盘读取一段文本字符：</p>

<p>当传入一个文件路径时，将会根据这个路径创建一个<code>File</code>对象来标识这个文件，然后根据这个<code>File</code>对象创建真正读取文件的操作对象，这时将会真正创建一个关联真实存在的磁盘文件的文件描述符<code>FileDescriptor</code>，通过这个对象可以直接控制这个磁盘文件。</p>

<p>由于我们需要读取的是字符格式，所以需要<code>StreamDecoder</code>类将<code>byte</code>解码为<code>char</code>格式。</p>

<h4 id="toc_8">Java序列化</h4>

<p>Java序列化就是将一个对象转化成一串二进制表示的字节数组，通过保存或转移这些字节数据来达到持久化的目的。需要持久化，对象必须继承<code>java.io.Serializable</code>接口。</p>

<p>反序列化则是相反的过程，将这个字节数组再重新构造成对象。</p>

<h3 id="toc_9">网络<code>I/O</code>工作机制</h3>

<h4 id="toc_10">TCP状态转化</h4>

<p><img src="media/14588873943004/14588911569166.jpg" alt=""/></p>

<p>1、CLOSED：起始点，在超时或者连接关闭时进入此状态<br/>
2、LISTEN：Server端在等待连接时的状态，Server端为此要调用Scok</p>

<h4 id="toc_11">影响网络传输的因素</h4>

<p>将一份数据从一个地方正确地传输到另一个地方所需要的时间我们称为响应时间。影响这个响应时间的因素有很多。</p>

<ul>
<li>网络带宽</li>
<li>传输距离</li>
<li><code>TCP</code>拥塞控制</li>
</ul>

<p><code>TCP</code>传输是一个<code>停-等-停-等</code>协议，传输放和接受方的步调要一致，要达到这个步调一致就要通过拥塞控制来调节。TCP在传输时会设定一个窗口（<code>BDP，Brandwidth Delay Product</code>），这个窗口的大小是由带宽和<code>RTT</code>（<code>Round-Trip Time</code>，数据在两端的来回时间，也就是响应时间）决定的。计算的公式是<code>带宽（b/s）</code> * <code>RTT（s）</code>。通过这个值可以得出理论上最优的<code>TCP</code>缓冲区的大小。</p>

<h4 id="toc_12"><code>Java Socket</code>的工作机制</h4>

<p><code>Socket</code>描述计算机之间完成相互通信的一种抽象功能。</p>

<p>打个比方，可以把<code>Socket</code>比作两个城市之间的交通工具，有了它，就可以在城市之间来回穿梭了、交通工具有多种，每种交通工具也有相应的交通规则。<code>Socket</code>也一样，也有多种。大部分情况我们使用的是基于<code>TCP/IP</code>的流套接字，它是一种稳定的通信协议。</p>

<p><img src="media/14588873943004/14588952417202.jpg" alt=""/></p>

<p><code>主机A</code>的应用程序要能和<code>主机B</code>的应用程序<strong>通信，必须通过<code>Socket</code>建立连接</strong>，而<strong>建立<code>Socket</code>连接必须由底层<code>TCP/IP</code>协议来建立<code>TCP</code>连接</strong>。<strong>建立<code>TCP</code>连接需要底层<code>IP</code>协议来寻址网络中的主机</strong>。网络层使用的<code>IP</code>协议可以帮助我们根据<code>IP</code>地址来找到目标主机，但是一台主机上可能运行着多个应用程序，如何才能与指定的应用程序通信就要通过<code>TCP</code>或<code>UDP</code>的地址，也就是<strong>端口号</strong>来指定了。</p>

<h4 id="toc_13">建立通信链路</h4>

<p>当客户端要与服务端通信时，客户端<strong>首先要创建一个<code>Socket</code>实例</strong>，操作系统将为这个<code>Socket</code>实例<strong>分配一个没有被使用的本地端口号</strong>，并<strong>创建一个包含本地和远程地址和端口号的套接字数据结构</strong>，这个数据结构将一直保存在系统中直到这个连接关闭。</p>

<p>在创建<code>Socket</code>实例的构造函数正确返回之前，将要进行<code>TCP</code>的三次握手协议，<code>TCP</code>握手协议完成后，<code>Socket</code>实例对象将创建完成，否则将抛出<code>IOException</code>错误。</p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[深入Web请求过程]]></title>
        <link href="http://nathanchen.github.io/14588864645651.html"/>
        <updated>2016-03-25T14:14:24+08:00</updated>
        <id>http://nathanchen.github.io/14588864645651.html</id>
        <content type="html"><![CDATA[
<blockquote>
<p>B/S =&gt; Browser / Server<br/>
C/S =&gt; Client / Server</p>
</blockquote>

<h3 id="toc_0">如何发起一个请求</h3>

<p>浏览器在建立<code>Socket</code>连接之前，必须根据地址栏里输入的<code>URL</code>的域名<code>DNS</code>解析出<code>IP</code>地址，再根据这个<code>IP</code>地址和默认80端口与远程服务器建立<code>Socket</code>连接，然后浏览器根据这个<code>URL</code>组装成一个<code>get</code>类型的<code>HTTP</code>请求头，通过<code>outputStream.write()</code>发送到目标服务器，服务器等待<code>inputStream.read()</code>返回数据，最后断开这个连接。</p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Java 基础之`final`、`static`、`transient`]]></title>
        <link href="http://nathanchen.github.io/14588864364518.html"/>
        <updated>2016-03-25T14:13:56+08:00</updated>
        <id>http://nathanchen.github.io/14588864364518.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">一、关于<code>final</code></h3>

<p>根据程序上下文环境，<code>Java</code>关键字<code>fina</code>有<strong>这是无法改变的</strong>或者<strong>终态的</strong>含义，它可以修饰非抽象类、非抽象类成员方法和变量。你可能出于两种理解而需要阻止改变：设计或效率。</p>

<blockquote>
<p><code>final</code>类不能被继承，没有子类，<code>final</code>类中的方法默认是<code>final</code>的。</p>

<p><code>final</code>方法不能被子类的方法覆盖，但可以被继承。</p>

<p><code>final</code>成员变量表示常量，只能被赋值一次，赋值后值不再改变。</p>

<p><code>final</code>不能用于修饰构造方法。</p>
</blockquote>

<p>注意：父类的<code>private</code>成员方法是不能被子类方法覆盖的，因此<code>private</code>类型的方法默认是<code>final</code>类型的。</p>

<h4 id="toc_1">1、<code>final</code>类</h4>

<p><strong><code>final</code>类不能被继承</strong>，因此<code>final</code>类的成员方法没有机会被覆盖，默认都是<code>final</code>的。在设计类时候，<strong>如果这个类不需要有子类，类的实现细节不允许改变，并且确信这个类不会再被扩展，那么就设计为<code>final</code>类</strong>。</p>

<h4 id="toc_2">2、<code>final</code>方法</h4>

<p><strong>如果一个类不允许其子类覆盖某个方法，则可以把这个方法声明为<code>final</code>方法</strong>。</p>

<p>使用<code>final</code>方法的原因有二：</p>

<p>第一、把方法锁定，防止任何继承类修改它的意义和实现。</p>

<p>第二、高效。<strong>编译器在遇到调用<code>final</code>方法时候会转入内嵌机制</strong>，大大提高执行效率。</p>

<h4 id="toc_3">3、<code>final</code>变量（常量）</h4>

<p><strong>用<code>final</code>修饰的成员变量表示常量，值一旦给定就无法改变</strong>！</p>

<p><code>final</code>修饰的变量有三种：静态变量、实例变量和局部变量，分别表示三种类型的常量。</p>

<p>另外，<code>final</code>变量定义的时候，可以先声明，而不给初值，这中变量也称为final空白，<strong>无论什么情况，编译器都确保空白<code>final</code>在使用之前必须被初始化</strong>。但是，<code>final</code>空白在<code>final</code>关键字<code>final</code>的使用上提供了更大的灵活性，为此，一个类中的<code>final</code>数据成员就可以实现依对象而有所不同，却有保持其恒定不变的特征。</p>

<h4 id="toc_4">4、<code>final</code>参数</h4>

<p><strong>当函数参数为<code>final</code>类型时，你可以读取使用该参数，但是无法改变该参数的值</strong>（网上最流行的说法）。</p>

<p><strong>特例</strong></p>

<pre><code class="language-java">public class Test {
    public static void main(String[] args)  {
        MyClass myClass = new MyClass();
        StringBuffer buffer = new StringBuffer(&quot;hello&quot;);
        myClass.changeValue(buffer);
        System.out.println(buffer.toString());
    }
}
 
class MyClass {
 
    void changeValue(final StringBuffer buffer) {
        buffer.append(&quot;world&quot;);
    }
}

====&gt; helloworld
</code></pre>

<p>Once a final variable has been assigned, it always contains the same value. <strong><em>If a final variable holds a reference to an object, then the state of the object may be changed by operations on the object, but the variable will always refer to the same object.</em></strong></p>

<p>如果一个被<code>final</code>关键字修饰的变量<code>A</code>指向一个对象<code>B</code>的引用，那么这个变量<code>A</code>的状态可能会随着<code>B</code>的改变而改变，但<code>A</code>一直都指向<code>B</code>的</p>

<p>在上例中，变量<code>A</code>（<code>buffer</code>）指向一个对象<code>B</code>（<code>StringBuffer</code>）的引用，对象<code>B</code>（<code>StringBuffer</code>）的值改变了，但是他的内存地址没有改变。</p>

<pre><code class="language-java">final StringBuffer a = new StringBuffer(&quot;Hello&quot;);
a = new StringBuffer(&quot;World&quot;); //this wont compile
</code></pre>

<h3 id="toc_5">二、关于<code>static</code></h3>

<p><code>static</code>表示<strong>全局</strong>或者<strong>静态</strong>的意思，用来修饰成员变量和成员方法，也可以形成静态<code>static</code>代码块，但是<code>Java</code>语言中没有全局变量的概念。</p>

<h4 id="toc_6">1、<code>static</code>变量</h4>

<p>按照是否静态的对类成员变量进行分类可分两种：<strong>一种是被<code>static</code>修饰的变量，叫静态变量或类变量</strong>；另<strong>一种是没有被<code>static</code>修饰的变量，叫实例变量</strong>。两者的区别是：</p>

<p>对于<strong>静态变量在内存中只有一个拷贝</strong>（节省内存）， <strong>JVM 只为静态分配一次内存</strong>，在加载类的过程中完成静态变量的内存分配，<strong>可用类名直接访问</strong>（方便），当然也可以通过对象来访问（但是这是不推荐的）。</p>

<p><strong>对于实例变量，每创建一个实例，就会为实例变量分配一次内存，实例变量可以在内存中有多个拷贝，互不影响</strong>（灵活）。</p>

<p>用<code>public</code>修饰的<code>static</code>成员变量和成员方法本质是全局变量和全局方法，当声明其他类的对象时，不生成<code>static</code>变量的副本，而是类的所有实例共享同一个<code>static</code>变量。</p>

<p><code>static</code>变量前可以有<code>private</code>修饰，表示这个变量可以在类的静态代码块中，或者类的其他静态成员方法中使用，但是不能在其他类中通过类名来直接引用，这一点很重要。实际上你需要搞明白，<strong><code>private</code>是访问权限限定，<code>static</code>表示不要实例化就可以使用</strong>，这样就容易理解多了。<code>static</code>前面加上其它访问权限关键字的效果也以此类推。</p>

<h4 id="toc_7">2、<code>static</code>方法</h4>

<p>静态方法可以直接通过类名调用，任何的实例也都可以调用，因此<strong>静态方法中不能用<code>this</code>和<code>super</code>关键字，不能直接访问所属类的实例变量和实例方法(就是不带<code>static</code>的成员变量和成员成员方法)</strong>，只能访问所属类的静态成员变量和成员方法。因为实例成员与特定的对象关联！</p>

<p><strong>因为<code>static</code>方法独立于任何实例，因此<code>static</code>方法必须被实现，而不能是抽象的<code>abstract</code></strong>。</p>

<h4 id="toc_8">3、<code>static</code>代码块</h4>

<p><code>static</code>代码块也叫静态代码块，是在类中独立于类成员的<code>static</code>语句块，可以有多个，位置可以随便放，它不在任何的方法体内，<strong><code>JVM</code>加载类时会执行这些静态的代码块，如果<code>static</code>代码块有多个，<code>JVM</code>将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次</strong>。</p>

<h4 id="toc_9">4、<code>static</code>和<code>final</code>一块用表示什么</h4>

<p><strong><code>static</code>、<code>final</code>用来修饰成员变量和成员方法，可简单理解为“全局常量”</strong>！</p>

<p>对于变量，表示一旦给值就不可修改，并且通过类名可以访问。</p>

<p>对于方法，表示不可覆盖，并且可以通过类名直接访问。</p>

<p>特别要注意一个问题：</p>

<p>对于被<code>static</code>和<code>final</code>修饰过的实例常量，实例本身不能再改变了，但对于一些容器类型（比如，<code>ArrayList</code>、<code>HashMap</code>）的实例变量，不可以改变容器变量本身，但可以修改容器中存放的对象，这一点在编程中用到很多。</p>

<h4 id="toc_10">5、静态内部类</h4>

<p>这里简单介绍下，什么是静态内部类。</p>

<p><strong>简单的说内部类前加<code>static</code>就是静态内部类</strong>了，上代码：</p>

<pre><code class="language-java">public class Outer { 
    static int x =1;
    static class Nest {
        void print(){
            System.out.println(&quot;Nest &quot;+x);
        }
    }
    public static void main(String[] args){
        Outer.Nest nest = new Outer.Nest();
        nest.print();
    }
}
</code></pre>

<p>当内部类是<code>static</code>时，意味着：</p>

<ul>
<li><p>要创建静态内部类的对象，并不需要其外部类的对象；</p></li>
<li><p>不能够从静态内部类的对象中访问外部类的非静态成员；</p></li>
</ul>

<p>与普通的内部类的一个区别：在非静态内部类中不可以声明静态成员，只有将某个内部类修饰为静态类，然后才能够在这个类中定义静态的成员变量与成员方法。</p>

<h4 id="toc_11">6、静态导包</h4>

<p>所谓静态导入包：<code>import static com. ... . ClassName.*</code>这样写可以导入相关类里面的所有静态方法，或者也可以直接静态导入具体到静态方法名。</p>

<p>这样写的好处是，引用静态方法不用在前面加上类名.</p>

<p>需要注意两点：</p>

<ul>
<li><p>提防含糊不清的命名<code>static</code>成员。例如，如果你对<code>Integer</code>类和<code>Long</code>类执行了静态导入，引用<code>MAX_VALUE</code>将导致一个编译器错误，因为<code>Integer</code>和<code>Long</code>都有一个<code>MAX_VALUE</code>常量，并且<code>Java</code>不会知道你在引用哪个<code>MAX_VALUE</code>。</p></li>
<li><p>方法名的命名尽量明确，让看代码的人看到名称就知道这个方法是干嘛用的，不然静态导入会让代码变的难读。</p></li>
</ul>

<blockquote>
<p>附：</p>

<p><strong>对象的初始化顺序</strong>: </p>

<ul>
<li><strong>首先执行父类静态</strong>的内容，父类静态的内容执行完毕后，</li>
<li><strong>接着去执行子类的静态</strong>的内容，当子类的静态内容执行完毕之后，</li>
<li>再去看<strong>父类有没有非静态代码块</strong>，如果有就执行父类的非静态代码块，</li>
<li>父类的非静态代码块执行完毕，<strong>接着执行父类的构造方法</strong>；</li>
<li>父类的构造方法执行完毕之后，它接着去看<strong>子类有没有非静态代码块</strong>，如果有就执行子类的非静态代码块。</li>
<li>子类的非静态代码块执行完毕再去执行<strong>子类的构造方法</strong>。</li>
</ul>

<p><mark>总之一句话，静态代码块内容先执行，接着执行父类非静态代码块和构造方法，然后执行子类非静态代码块和构造方法</mark>。</p>

<p>**注意: <strong>子类的构造方法，</strong>不管这个构造方法带不带参数，默认的它都会先去寻找父类的不带参数的构造方法**。如果父类没有不带参数的构造方法，那么子类必须用<code>super</code>关键子来调用父类带参数的构造方法，否则编译不能通过。</p>
</blockquote>

<h3 id="toc_12">三、<code>transient</code></h3>

<p>java 的<code>transient</code>关键字为我们提供了便利，你只需要实现<code>Serilizable</code>接口，将不需要序列化的属性前添加关键字<code>transient</code>，序列化对象的时候，这个属性就不会序列化到指定的目的地中。</p>

<ul>
<li><p>一旦变量被<code>transient</code>修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。</p></li>
<li><p><code>transient</code>关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被<code>transient</code>关键字修饰的。变量如果是用户自定义类变量，则该类需要实现<code>Serializable</code>接口。</p></li>
<li><p>被<code>transient</code>关键字修饰的变量不再能被序列化，一个静态变量不管是否被<code>transient</code>修饰，均不能被序列化。</p></li>
</ul>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[高性能MySQL - 创建高性能的索引]]></title>
        <link href="http://nathanchen.github.io/14588857020339.html"/>
        <updated>2016-03-25T14:01:42+08:00</updated>
        <id>http://nathanchen.github.io/14588857020339.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">索引基础</h3>

<p>索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要，因为<strong>MySQL只能高效地使用索引的最左前缀列</strong>。创建一个包含两个列的索引，和创建两个只包含一列的索引是大不相同的。</p>

<h4 id="toc_1">索引的类型</h4>

<h5 id="toc_2">B-Tree索引</h5>

<p>B-Tree通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同。</p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[搜索引擎关键字智能提示的一种实现]]></title>
        <link href="http://nathanchen.github.io/14588733684599.html"/>
        <updated>2016-03-25T10:36:08+08:00</updated>
        <id>http://nathanchen.github.io/14588733684599.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">解决方案</h3>

<h5 id="toc_1">关键字收集</h5>

<p>当用户输入一个前缀时，碰到提示的候选词很多的时候，如何取舍，哪些展示在前面，哪些展示在后面？</p>

<p>用户在使用搜索引擎查找商家时，会输入大量的关键字，每一次输入就是对关键字的一次投票，那么关键字被输入的次数越多，它对应的查询就比较热门，所以需要查询的关键字记录下来，并且统计出每个关键字的频率，方便提示结果按照频率排序。</p>

<p>搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来。</p>

<h5 id="toc_2">拼音缩写提取</h5>

<p><code>chongqing</code>, <code>zhongqing</code> -&gt; <code>cq</code>, <code>zq</code></p>

<h3 id="toc_3">索引与前缀查询</h3>

<h4 id="toc_4">方案一：Trie树 + TopK算法</h4>

<p><strong>Trie树</strong>即字典树，又称单词查找树或键树，是一种树形结构，一种哈希树的变种。</p>

<p>它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。</p>

<p><img src="media/14588733684599/14588739187774.jpg" alt=""/></p>

<p>从上图可知，当用户输入前缀<code>i</code>的时候，搜索框可能会展示以<code>i</code>为前缀的<code>in</code>，<code>inn</code>，<code>int</code>等关键词，再当用户输入前缀<code>a</code>的时候，搜索框里面可能会提示以<code>a</code>为前缀的<code>ate</code>等关键词。如此，实现搜索引擎智能提示<code>suggestion</code>的第一个步骤便清晰了</p>

<p><strong>TopK算法</strong>用于解决统计热词的问题。解决TopK问题主要有两种策略：HashMap统计+排序（堆排序）。</p>

<p><code>HashMap</code>统计：先对这批海量数据预处理。具体方法是：维护一个<code>Key</code>为<code>Query</code>字串，<code>Value</code>为该<code>Query</code>出现次数的<code>HashMap</code>。</p>

<p><strong>该方案存在的问题</strong>是：</p>

<ul>
<li>需要维护拼音、缩写两棵<code>Trie</code>树。</li>
</ul>

<h4 id="toc_5">方案二：<code>Solr</code>自带<code>Suggest</code>智能提示</h4>

<p><strong>该方案存在的问题</strong>是：</p>

<ul>
<li>返回的结果是基于索引中字段的词频进行排序，不是用户搜索关键字的频率，因此不能将一些热门关键字排在前面。</li>
<li>拼音提示，多音字，缩写还是要另外加索引字段。</li>
</ul>

<h4 id="toc_6">方案三 <code>Solrcloud</code>建立单独的<code>collection</code>,利用<code>Solr</code>前缀查询实现</h4>

<p>专门为关键字建立一个索引<code>collection</code>，利用<code>Solr</code>前缀查询实现。<code>Solr</code>中的<code>copyField</code>能很好解决我们同时索引多个字段(汉字、<code>pinyin</code>, <code>abbre</code>)的需求，且<code>field</code>的<code>multiValued</code>属性设置为<code>true</code>时能解决同一个关键字的多音字组合问题。</p>

<h3 id="toc_7">Reference</h3>

<p><a href="http://tech.meituan.com/pinyin-suggest.html">http://tech.meituan.com/pinyin-suggest.html</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Java内存访问重排序的研究]]></title>
        <link href="http://nathanchen.github.io/14588711280200.html"/>
        <updated>2016-03-25T09:58:48+08:00</updated>
        <id>http://nathanchen.github.io/14588711280200.html</id>
        <content type="html"><![CDATA[
<pre><code>public class PossibleReordering {
    static int x = 0, y = 0;
    static int a = 0, b = 0;
    
    public static void main(String[] args) throws InterruptedException {
        Thread one = new Thread(new Runnable() {
            public void run() {
                a = 1;
                x = b;
            }
        });
    
        Thread other = new Thread(new Runnable() {
            public void run() {
                b = 1;
                y = a;
            }
        });
        one.start();other.start();
        one.join();other.join();
        System.out.println(“(” + x + “,” + y + “)”);
    }
}
</code></pre>

<p>这段代码的执行结果也可能是（0，0），因为，在实际运行时，代码指令可能并不是严格按照代码语句顺序执行的。</p>

<p>得到（0，0）结果的语句执行过程：</p>

<p><img src="media/14588711280200/14588715411444.jpg" alt=""/></p>

<p><code>a=1</code>和<code>x=b</code>这两个语句的赋值操作的顺序被颠倒了，或者说，发生了指令“重排序<code>(reording)</code>”</p>

<p>大多数现代微处理器都会采用将指令乱序执行的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避免获取下一条指令所需数据时造成的等待，通过乱序执行的技术，处理器可以大大提高执行效率。</p>

<h3 id="toc_0"><code>as-if-serial</code>语义</h3>

<p>所有的动作都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。</p>

<pre><code>int a = 1;
int b = 2;
int c = a + b;
</code></pre>

<p>将上面的代码编译成<code>Java</code>字节码或生成机器指令，可视为展开成了以下动作：</p>

<pre><code>1. 对a赋值1
2. 对b赋值2
3. 取a的值
4. 取b的值
5. 将取到两个值相加后存入c
</code></pre>

<p>在上面5个动作中，<code>动作1</code>可能会和<code>动作2、4</code>重排序，<code>动作2</code>可能会和<code>动作1、3</code>重排序，<code>动作3</code>可能会和<code>动作2、4</code>重排序，<code>动作4</code>可能会和<code>动作1、3</code>重排序。但<code>动作1</code>和<code>动作3、5</code>不能重排序。<code>动作2</code>和<code>动作4、5</code>不能重排序。因为它们之间存在数据依赖关系，一旦重排，<code>as-if-serial</code>语义便无法保证</p>

<h3 id="toc_1">内存访问重排序与内存可见性</h3>

<p>计算机系统中，为了尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存（cache）以提高性能。</p>

<p><img src="media/14588711280200/14588720292789.jpg" alt=""/></p>

<p>在这种模型下会存在一个现象，即缓存中的数据与主内存的数据并不是实时同步的，各CPU（或CPU核心）间缓存的数据并不是实时同步的。从程序的视角来看，就是同一个时间点，各个线程所看到的共享变量的值可能是不一致的。</p>

<h3 id="toc_2">内存访问重排序与Java内存模型</h3>

<p>根据<code>Java</code>内存模型中的规定，可以总结出以下几条<code>happens-before</code>规则。<code>happens-before</code>的前后两个操作不会被重排序且后者对前者的内存可见。</p>

<ul>
<li>程序次序法则：线程中的每个<code>动作A</code>都<code>happens-before</code>于该线程中的每一个<code>动作B</code>，其中，在程序中，所有的<code>动作B</code>都能出现在<code>动作A</code>之后。</li>
<li>监视器锁法则：对一个监视器锁的解锁<code>happens-before</code>于每一个后续对同一监视器锁的加锁。</li>
<li><code>volatile</code>变量法则：对<code>volatile</code>域的写入操作<code>happens-before</code>于每一个后续对同一个域的读写操作。</li>
<li>线程启动法则：在一个线程里，对<code>Thread.start()</code>的调用会<code>happens-before</code>于每个启动线程的动作。</li>
<li>线程终结法则：线程中的任何动作都<code>happens-before</code>于其他线程检测到这个线程已经终结、或者从<code>Thread.join()</code>调用中成功返回，或<code>Thread.isAlive()</code>返回<code>false</code>。</li>
<li>中断法则：一个线程调用另一个线程的<code>interrupt</code> <code>happens-before</code>于被中断的线程发现中断。</li>
<li>终结法则：一个对象的构造函数的结束<code>happens-before</code>于这个对象<code>finalizer</code>的开始。</li>
<li>传递性：如果<code>A</code> <code>happens-before</code>于<code>B</code>，且<code>B</code> <code>happens-before</code>于<code>C</code>，则<code>A</code> <code>happens-before</code>于<code>C</code></li>
</ul>

<h3 id="toc_3">Reference</h3>

<p><a href="http://tech.meituan.com/java-memory-reordering.html">http://tech.meituan.com/java-memory-reordering.html</a></p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[`MySQL`索引原理及慢查询优化]]></title>
        <link href="http://nathanchen.github.io/14588705157449.html"/>
        <updated>2016-03-25T09:48:35+08:00</updated>
        <id>http://nathanchen.github.io/14588705157449.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">MySQL索引原理</h3>

<h4 id="toc_1">索引目的</h4>

<p>在于提高查询效率，可以类比字典，如果要查<code>mysql</code>这个单词，我们肯定需要定位到<code>m</code>字母，然后从下往上找到<code>y</code>字母，再找到剩下的<code>sql</code>。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的。</p>

<h4 id="toc_2">索引原理</h4>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[`HashMap`底层原理]]></title>
        <link href="http://nathanchen.github.io/14588687241012.html"/>
        <updated>2016-03-25T09:18:44+08:00</updated>
        <id>http://nathanchen.github.io/14588687241012.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">引言</h3>

<blockquote>
<p><code>HashMap</code>基于哈希表的<code>Map</code>接口的实现。此实现提供所有可选的映射操作，并允许使用<code>null</code>值和<code>null</code>键。（除了不同步和允许使用<code>null</code>之外，<code>HashMap</code>类与<code>Hashtable</code>大致相同）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。</p>

<p>值得注意的是<code>HashMap</code>不是线程安全的，如果想要线程安全的<code>HashMap</code>，可以通过<code>Collections</code>类的静态方法<code>synchronizedMap</code>获得线程安全的<code>HashMap</code>。</p>

<pre><code>Map map = Collections.synchronizedMap(new HashMap());
</code></pre>
</blockquote>

<h3 id="toc_1">一、数据结构与冲突</h3>

<p><code>HashMap</code>的底层主要是基于数组和链表来实现的，它之所以有相当快的查询速度主要是因为它是通过计算散列码来决定存储的位置。<strong><code>HashMap</code>中主要是通过<code>key</code>的<code>hashCode</code>来计算<code>hash</code>值的</strong>，只要<code>hashCode</code>相同，计算出来的<code>hash</code>值就一样。<strong>如果存储的对象对多了，就有可能不同的对象所算出来的<code>hash</code>值是相同的，这就出现了所谓的<code>hash</code>冲突</strong>。解决<code>hash</code>冲突的方法有很多，<code>HashMap</code>底层是<strong>通过链表来解决<code>hash</code>冲突的</strong>。</p>

<p><img src="media/14588687241012/14588688631332.jpg" alt=""/></p>

<p>图中，左边部分代表哈希表，也称为哈希数组，数组的每个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。右边部分则显示数组内部结构，<code>HashMap</code>其实就是一个<code>Entry</code>数组，<code>Entry</code>对象中包含了键和值，其中<code>next</code>也是一个<code>Entry</code>对象，它就是用来处理<code>hash</code>冲突的，形成一个链表。</p>

<h3 id="toc_2">二、HashMap相关属性</h3>

<pre><code>transient Entry[] table;//存储元素的实体数组

transient int size;//存放元素的个数

int threshold; //临界值，当实际大小超过临界值时，会进行扩容，扩容大小为当前的2倍。threshold = 负载因子*容量

final float loadFactor; //负载因子

transient int modCount;//被修改的次数
</code></pre>

<p>其中比较重要的两个参数是容量(<code>Capacity</code>) 和 负载因子(<code>Load factor</code>)</p>

<blockquote>
<p><strong>Initial capacity</strong>: The capacity is the number of buckets in the hash table, The initial capacity is simply the capacity at the time the hash table is created.<br/>
<strong>Load factor</strong>: The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased.</p>
</blockquote>

<p>简单的说，<code>Capacity</code>就是<code>bucket</code>的大小，<code>loadFactor</code>就是<code>bucket</code>填满程度的最大比例。</p>

<p><code>loadFactor</code>越大，填满的元素越多，好处是，空间利用率高了，但冲突的机会加大了，链表长度会越来越长,查找效率降低。</p>

<p>反之，<code>loadFactor</code>越小，填满的元素越少，好处是冲突的机会减小了，但空间浪费多了，表中的数据将过于稀疏（很多空间还没用，就开始扩容了）</p>

<p>因此,必须在 “冲突的机会” 与 “空间利用率” 之间寻找一种平衡与折衷. 这种平衡与折衷本质上是数据结构中有名的 “时-空” 矛盾的平衡与折衷.</p>

<p>如果机器内存足够，并且想要提高查询速度的话可以将<code>loadFactor</code>设置小一点；相反如果机器内存紧张，并且对查询速度没有什么要求的话可以将<code>loadFactor</code>设置大一点。不过<strong>一般取默认值0.75</strong>就好。</p>

<h3 id="toc_3">三、使用频率最高的两个方法<code>put</code>和<code>get</code></h3>

<p><code>put</code>函数大致的思路为：</p>

<p>1、对<code>key</code>的<code>hashCode()</code>做<code>hash</code>，然后再计算<code>index</code>；</p>

<p>2、如果没碰撞直接放到<code>bucket</code>里；</p>

<p>3、如果碰撞了，以链表的形式存在<code>buckets</code>后；</p>

<p>4、如果碰撞导致链表过长(大于等于<code>TREEIFY_THRESHOLD</code>)，就把链表转换成红黑树；</p>

<p>5、如果节点已经存在就替换<code>old value</code>(保证<code>key</code>的唯一性)；</p>

<p>6、如果<code>bucket</code>满了(超过<code>loadFactor * current capacity</code>)，就要<code>resize</code>。</p>

<pre><code>public V put(K key, V value) 
{
    // 对key的hashCode()做hash
    return putVal(hash(key), key, value, false, true);
}
 
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) 
{
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;

    // tab为空则创建
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;

    // 计算index，并对null做处理
    if ((p = tab[i = (n - 1) &amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);

    else 
    {
        Node&lt;K,V&gt; e; K k;

        // 节点存在
        if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
            e = p;

        // 该链为树
        else if (p instanceof TreeNode)
            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);

        // 该链为链表
        else 
        {
            for (int binCount = 0; ; ++binCount) 
            {
                if ((e = p.next) == null) 
                {
                    p.next = newNode(hash, key, value, null);
                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    break;
                p = e;
            }
        }
        // 写入
        if (e != null) 
        { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 超过load factor*current capacity，resize
    if (++size &gt; threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
</code></pre>

<p><code>get</code>函数大致思路如下：</p>

<p>1、<code>bucket</code>里的第一个节点，直接命中；</p>

<p>2、如果有冲突，则通过<code>key.equals(k)</code>去查找对应的<code>entry</code>；</p>

<p>3、若为树，则在树中通过<code>key.equals(k)</code>查找，<code>O(logn)</code>；</p>

<p>4、若为链表，则在链表中通过<code>key.equals(k)</code>查找，<code>O(n)</code>。</p>

<pre><code>public V get(Object key) 
{
    Node&lt;K,V&gt; e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
 
final Node&lt;K,V&gt; getNode(int hash, Object key) 
{
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) 
    {
        // 直接命中
        if (first.hash == hash &amp;&amp; // always check first node
            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
            return first;
        // 未命中
        if ((e = first.next) != null) 
        {
            // 在树中get
            if (first instanceof TreeNode)
                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);
            // 在链表中get
            do 
            {
                if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
</code></pre>

<h3 id="toc_4">四、<code>resize</code>的实现</h3>

<p>当<code>put</code>时，如果发现目前的<code>bucket</code>占用程度已经超过了<code>loadFactor</code>所希望的比例，那么就会发生<code>resize</code>。在<code>resize</code>的过程，简单的说就是把<code>bucket</code>扩充为2倍，之后重新计算<code>index</code>，把节点再放到新的<code>bucket</code>中。<code>resize</code>的注释是这样描述的：</p>

<blockquote>
<p>Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table.</p>
</blockquote>

<p>大致意思就是说，<strong>当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置</strong>。</p>

<p>怎么理解呢？例如我们从16扩展为32时，具体的变化如下所示：</p>

<p><img src="media/14588687241012/14588692702341.jpg" alt=""/></p>

<p>因此元素在重新计算<code>hash</code>之后，因为<code>n</code>变为2倍，那么<code>n-1</code>的<code>mask</code>范围在高位多<code>1bit</code>(红色)，因此新的<code>index</code>就会发生这样的变化：</p>

<p><img src="media/14588687241012/14588692827747.jpg" alt=""/></p>

<p>因此，我们在扩充<code>HashMap</code>的时候，不需要重新计算<code>hash</code>，只需要看看原来的<code>hash</code>值新增的那个<code>bit</code>是1还是0就好了，是0的话索引没变，是1的话索引变成<code>原索引+oldCap</code>。可以看看下图为16扩充为32的<code>resize</code>示意图：</p>

<p><img src="media/14588687241012/14588693335759.jpg" alt=""/></p>

<p>这个设计非常巧妙，既省去了重新计算<code>hash</code>值的时间，而且同时，由于新增的<code>1bit</code>是0还是1可以认为是随机的，因此<code>resize</code>的过程，均匀的把之前的冲突的节点分散到新的<code>bucket</code>了。</p>

<h3 id="toc_5">总结</h3>

<p>通过<code>hash</code>的方法，通过<code>put</code>和<code>get</code>存储和获取对象。存储对象时，我们将<code>K/V</code>传给<code>put</code>方法时，它调用<code>hashCode</code>计算<code>hash</code>从而得到<code>bucket</code>位置，进一步存储，<code>HashMap</code>会根据当前<code>bucket</code>的占用情况自动调整容量(超过<code>loadFactor</code>则<code>resize</code>为原来的2倍)。获取对象时，我们将<code>K</code>传给<code>get</code>，它调用<code>hashCode</code>计算<code>hash</code>从而得到<code>bucket</code>位置，并进一步调用<code>equals()</code>方法确定键值对。如果发生碰撞的时候，<code>HashMap</code>通过链表将产生碰撞冲突的元素组织起来，在<code>Java 8</code>中，如果一个<code>bucket</code>中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。</p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[倒排索引及`tf-idf`算法简介]]></title>
        <link href="http://nathanchen.github.io/14587172862630.html"/>
        <updated>2016-03-23T15:14:46+08:00</updated>
        <id>http://nathanchen.github.io/14587172862630.html</id>
        <content type="html"><![CDATA[
<h1 id="toc_0">倒排索引简介</h1>

<p>倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(<code>inverted index</code>)。带有倒排索引的文件我们称为倒排索引文件，简称倒排文件(<code>inverted file</code>)。</p>

<p>倒排文件（倒排索引），索引对象是文档或者文档集合中的单词等，用来存储这些单词在一个文档或者一组文档中的存储位置，是对文档或者文档集合的一种最常用的索引机制。</p>

<p>搜索引擎的关键步骤就是建立倒排索引，倒排索引一般表示为一个关键词，然后是它的频度（出现的次数），位置（出现在哪一篇文章或网页中，及有关的日期，作者等信息），它相当于为互联网上几千亿页网页做了一个索引，<strong>好比一本书的目录、标签一般</strong>。读者想看哪一个主题相关的章节，直接根据目录即可找到相关的页面。不必再从书的第一页到最后一页，一页一页的查找。</p>

<h2 id="toc_1">Lucene倒排索引原理</h2>

<p>Lucene是一个开放源代码的高性能的Java全文检索引擎工具包，不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。目的是为软件开发人员提供一个简单易用的工具包，以方便在目标系统中实现全文检索的功能，或者以此为基础建立起完整的全文检索引擎。</p>

<p>Lucene使用的是倒排文件索引结构。该结构及相应的生成算法如下：  　　</p>

<p>设有两篇文章1和2：</p>

<p>文章1的内容为：</p>

<pre><code>    Tom lives in Guangzhou, I live in Guangzhou too.
</code></pre>

<p>文章2的内容为：</p>

<pre><code>    He once lived in Shanghai.
</code></pre>

<h3 id="toc_2">取得关键词</h3>

<p>由于Lucene是基于关键词索引和查询的，首先我们要取得这两篇文章的关键词，通常我们需要如下处理措施： 　　</p>

<ul>
<li><p>我们现在有的是文章内容，即一个字符串，我们先要找出字符串中的所有单词，即<strong>分词</strong>。英文单词由于用空格分隔，比较好处理。中文单词间是连在一起的需要特殊的分词处理 　 　</p></li>
<li><p><strong>去掉没有意义的大众词汇</strong>。文章中的<code>in</code>, <code>once</code>, <code>too</code>等词没有什么实际意义，中文中的<code>的</code>、<code>是</code>等字通常也无具体含义，这些不代表概念的词可以过滤掉 　　</p></li>
<li><p>用户通常希望查<code>He</code>时能把含<code>he</code>，<code>HE</code>的文章也找出来，所以所有单词需要<strong>统一大小写</strong>。 　　</p></li>
<li><p><strong>单词的统一化</strong>。用户通常希望查<code>live</code>时能把含<code>lives</code>，<code>lived</code>的文章也找出来，所以需要把<code>lives</code>，<code>lived</code>还原成<code>live</code> 　　</p></li>
<li><p>文章中的<strong>标点符号</strong>通常不表示某种概念，也可以过滤掉 　　</p></li>
</ul>

<p>在Lucene中以上措施由<code>Analyzer</code>类完成。 经过上面处理后，</p>

<p>文章1的所有关键词为：</p>

<pre><code>    [tom] [live] [guangzhou] [i] [live] [guangzhou]
</code></pre>

<p>文章2的所有关键词为：</p>

<pre><code>    [he] [live] [shanghai]
</code></pre>

<h3 id="toc_3">建立倒排索引</h3>

<p>有了关键词后，我们就可以建立倒排索引了。上面的对应关系是：<code>文章号</code>对<code>文章中所有关键词</code>。倒排索引把这个关系倒过来，变成: <code>关键词</code>对<code>拥有该关键词的所有文章号</code>。</p>

<p>文章1，2经过倒排后变成 　　</p>

<pre><code>关键词            文章号 　　
guangzhou        1
he               2 
i                1 
live             1,2
shanghai         2
tom              1 
</code></pre>

<p><strong>通常仅知道关键词在哪些文章中出现还不够，我们还需要知道关键词在文章中出现次数和出现的位置</strong>，通常有两种位置：</p>

<ul>
<li><p>字符位置，即记录该词是文章中第几个字符（优点是关键词亮显时定位快）</p></li>
<li><p>关键词位置，即记录该词是文章中第几个关键词（优点是节约索引空间、词组（phase）查询快），lucene中记录的就是这种位置　　</p></li>
</ul>

<p>加上<code>出现频率</code>和<code>出现位置</code>信息后，我们的索引结构变为： 　　</p>

<pre><code>关键词               文章号[出现频率]            出现位置 
guangzhou           1[2]                      3, 6 　
he                  2[1]                      1
i                   1[1]                      4
live                1[2]                      2, 5
                    2[1]                      2 
shanghai            2[1]                      3
tom                 1[1]                      1 
</code></pre>

<p>以<code>live</code>这行为例我们说明一下该结构：<code>live</code>在<code>文章1</code>中出现了2次，<code>文章2</code>中出现了一次，它的出现位置为<code>2,5,2</code>这表示什么呢？我们需要结合文章号和出现频率来分析，<code>文章1</code>中出现了2次，那么<code>2,5</code>就表示<code>live</code>在<code>文章1</code>中出现的两个位置，<code>文章2</code>中出现了一次，剩下的<code>2</code>就表示<code>live</code>是<code>文章2</code>中第2个关键字。 　　</p>

<p>以上就是Lucene索引结构中最核心的部分。我们注意到关键字是按字符顺序排列的（Lucene没有使用B树结构），因此Lucene可以用二元搜索算法快速定位关键词。</p>

<h3 id="toc_4">实现</h3>

<p>实现时，Lucene将上面三列分别作为词典文件<code>（Term Dictionary）</code>、频率文件<code>(frequencies)</code>、位置文件<code>(positions)</code>保存。其中词典文件不仅保存有每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。 　　</p>

<p>Lucene中使用了<code>field</code>的概念，用于表达信息所在位置（如标题中，文章中，url中），在建索引中，该<code>field</code>信息也记录在词典文件中，每个关键词都有一个<code>field</code>信息(因为每个关键字一定属于一个或多个<code>field</code>)。</p>

<h3 id="toc_5">压缩算法</h3>

<p>为了减小索引文件的大小，Lucene对索引还使用了压缩技术。</p>

<p>首先，<strong>对词典文件中的关键词进行了压缩</strong>，关键词压缩为&lt;前缀长度，后缀&gt;</p>

<pre><code>    例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为&lt;3，语&gt;。
</code></pre>

<p>其次大量用到的是<strong>对数字的压缩</strong>，<strong>数字只保存与上一个值的差值</strong>（这样可以减小数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389（不压缩要用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）。</p>

<h3 id="toc_6">应用原因</h3>

<p>下面我们可以通过对该索引的查询来解释一下为什么要建立索引。 　　</p>

<p>假设要查询单词<code>live</code>，Lucene先对词典二元查找、找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。词典通常非常小，因而，整个过程的时间是毫秒级的。 　　</p>

<p>而用普通的顺序匹配算法，不建索引，而是对所有文章的内容进行字符串匹配，这个过程将会相当缓慢，当文章数目很大时，时间往往是无法忍受的。</p>

<h2 id="toc_7">TF-IDF及其算法</h2>

<p><code>TF-IDF（term frequency – inverted document frequency）</code>是一种用于资讯检索与资讯探勘的常用加权技术。<code>TF-IDF</code>是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<strong>字词的重要性随着它在文件中出现的次数成正比增加</strong>，但同时会<strong>随着它在语料库中出现的频率成反比下降</strong>。TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜寻引擎还会使用基于连结分析的评级方法，以确定文件在搜寻结果中出现的顺序。</p>

<h3 id="toc_8">原理</h3>

<p>在一份给定的文件里，<strong>词频 (term frequency, TF)</strong>指的是某一个给定的词语在该文件中出现的次数。<strong>这个数字通常会被归一化</strong>（分子一般小于分母区别于IDF），<strong>以防止它偏向长的文件</strong>。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否。）</p>

<p><strong>逆向文件频率 (inverse document frequency, IDF)</strong>是一个词语普遍重要性的度量。某一特定词语的IDF，可以<strong>由总文件数目除以包含该词语之文件的数目，再将得到的商取对数</strong>得到。</p>

<p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。</p>

<p><strong>TFIDF的主要思想是</strong>：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TFIDF实际上是：<code>TF * IDF</code>，TF词频(Term Frequency)，IDF反文档频率(Inverse Document Frequency)。<strong>TF</strong>表示词条在文档d中出现的频率（另一说：TF词频(Term Frequency)指的是<strong>某一个给定的词语在该文件中出现的次数</strong>）。<strong>IDF的主要思想是：如果包含词条t的文档越少，也就是n越小，IDF越大</strong>，则说明词条t具有很好的类别区分能力。如果某一类文档C中包含词条t的文档数为m，而其它类包含t的文档总数为k，显然所有包含t的文档数n=m+k，当m大的时候，n也大，按照IDF公式得到的IDF的值会小，就说明该词条t类别区分能力不强。（另一说：IDF反文档频率(Inverse Document Frequency)是指果包含词条的文档越少，IDF越大，则说明词条具有很好的类别区分能力。）但是实际上，如果一个词条在一个类的文档中频繁出现，则说明该词条能够很好代表这个类的文本的特征，这样的词条应该给它们赋予较高的权重，并选来作为该类文本的特征词以区别与其它类文档。这就是IDF的不足之处.</p>

<p>在一份给定的文件里，<strong>词频（term frequency，TF）</strong>指的是某一个给定的词语在该文件中出现的频率。这个数字是对<strong>词数(term count)</strong>的归一化，以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词数，而不管该词语重要与否。）</p>

<p>对于在某一特定文件 d<sub>j</sub> 里的词语  t<sub>i</sub>  来说，它的重要性可表示为：</p>

<p><img src="media/14587172862630/14587192129158.jpg" alt=""/></p>

<blockquote>
<p>以上式子中 <img src="media/14587172862630/14587192460077.jpg" alt=""/><br/>
是该词在文件<img src="media/14587172862630/14587192606951.jpg" alt=""/><br/>
中的出现次数，而分母则是在文件<img src="media/14587172862630/14587192606951.jpg" alt=""/>中所有字词的出现次数之和。</p>
</blockquote>

<p><strong>逆向文件频率（inverse document frequency，IDF）</strong>是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到：</p>

<p><img src="media/14587172862630/14587193987421.jpg" alt=""/></p>

<p>其中</p>

<blockquote>
<ul>
<li><strong>|D|</strong>：语料库中的文件总数</li>
<li><img src="media/14587172862630/14587194172144.jpg" alt=""/>
：包含词语 <img src="media/14587172862630/14587194452522.jpg" alt=""/>
的文件数目（即 <img src="media/14587172862630/14587194565514.jpg" alt=""/>
的文件数目）如果该词语不在语料库中，就会导致被除数为零，因此一般情况下使用 <img src="media/14587172862630/14587194771634.jpg" alt=""/></li>
</ul>
</blockquote>

<p>然后</p>

<p><img src="media/14587172862630/14587195313386.jpg" alt=""/></p>

<blockquote>
<p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。</p>
</blockquote>

<h3 id="toc_9">示例</h3>

<h4 id="toc_10">示例一</h4>

<p>假如一篇文件的总词语数是100个，而词语<code>母牛</code>出现了3次，那么<code>母牛</code>一词在该文件中的词频<strong>tf就是3/100=0.03</strong>。一个计算文件频率 (DF) 的方法是测定有多少份文件出现过<code>母牛</code>一词，然后除以文件集里包含的文件总数。所以，如果<code>母牛</code>一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是 <strong>log(10,000,000 / 1,000)=4</strong>。最后的TF-IDF的分数为0.03 * 4=0.12。</p>

<h4 id="toc_11">示例二</h4>

<p><strong>根据关键字k1,k2,k3进行搜索结果的相关性就变成 TF1 x IDF1 + TF2 x IDF2 + TF3 x IDF3</strong>。比如document1的term总量为1000，k1,k2,k3在document1出现的次数是100，200，50。包含了 k1, k2, k3的docuement总量分别是 1000， 10000，5000。document set的总量为10000。 TF1 = 100/1000 = 0.1 TF2 = 200/1000 = 0.2 TF3 = 50/1000 = 0.05 IDF1 = log(10000/1000) = log(10) = 2.3 IDF2 = log(10000/100000) = log(1) = 0; IDF3 = log(10000/5000) = log(2) = 0.69 这样关键字k1,k2,k3与docuement1的相关性= <code>0.1*2.3 + 0.2*0 + 0.05*0.69 = 0.2645</code>其中k1比k3的比重在document1要大，k2的比重是0.</p>

<h4 id="toc_12">示例三</h4>

<p>在某个一共有一千词的网页中<code>原子能</code>、<code>的</code>和<code>应用</code>分别出现了2次、35次和5次，那么它们的词频就分别是 0.002、0.035 和 0.005。 我们将这三个数相加，其和 0.042 就是相应网页和查询“原子能的应用” 相关性的一个简单的度量。概括地讲，如果一个查询包含关键词 w1,w2,...,wN, 它们在一篇特定网页中的词频分别是: TF1, TF2, ..., TFN。 （TF: term frequency)。 那么，这个查询和该网页的相关性就是:TF1 + TF2 + ... + TFN。</p>

<p>读者可能已经发现了又一个漏洞。在上面的例子中，词<code>的</code>站了总词频的 80% 以上，而它对确定网页的主题几乎没有用。我们称这种词叫<strong><code>应删除词（Stopwords)</code></strong>，也就是说在度量相关性是不应考虑它们的频率。在汉语中，应删除词还有“是”、“和”、“中”、“地”、“得”等等几十个。忽略这些应删除词后，上述网页的相似度就变成了0.007，其中“原子能”贡献了 0.002，“应用”贡献了 0.005。细心的读者可能还会发现另一个小的漏洞。在汉语中，“应用”是个很通用的词，而“原子能”是个很专业的词，后者在相关性排名中比前者重要。因此我们需要给汉语中的每一个词给一个权重，这个权重的设定必须满足下面两个条件：</p>

<blockquote>
<ol>
<li><p>一个词预测主题能力越强，权重就越大，反之，权重就越小。我们在网页中看到“原子能”这个词，或多或少地能了解网页的主题。我们看到“应用”一次，对主题基本上还是一无所知。因此，“原子能“的权重就应该比应用大。</p></li>
<li><p>应删除词的权重应该是零。</p></li>
</ol>
</blockquote>

<p>我们很容易发现，如果一个关键词只在很少的网页中出现，我们通过它就容易锁定搜索目标，它的权重也就应该大。反之如果一个词在大量网页中出现，我们看到它仍然不很清楚要找什么内容，因此它应该小。概括地讲，假定一个关键词 ｗ 在 Ｄｗ 个网页中出现过，那么 Ｄｗ 越大，ｗ的权重越小，反之亦然。在信息检索中，使用最多的权重是“逆文本频率指数” （Inverse document frequency 缩写为ＩＤＦ），它的公式为ｌｏｇ（Ｄ／Ｄｗ）其中Ｄ是全部网页数。比如，我们假定中文网页数是Ｄ＝１０亿，应删除词“的”在所有的网页中都出现，即Ｄｗ＝１０亿，那么它的ＩＤＦ＝log(10亿/10亿）= log (1) = ０。<strong>假如专用词<code>原子能</code>在两百万个网页中出现，即Ｄｗ＝２００万，则它的权重ＩＤＦ＝log(500) =6.2。又假定通用词<code>应用</code>，出现在五亿个网页中，它的权重ＩＤＦ = log(2)则只有 0.7。也就只说，在网页中找到一个<code>原子能</code>的比配相当于找到九个<code>应用</code>的匹配。</strong>利用 IDF，上述相关性计算个公式就由词频的简单求和变成了加权求和，即 <code>TF1*IDF1 +　TF2*IDF2 ＋... + TFN*IDFN</code>。在上面的例子中，该网页和“原子能的应用”的相关性为 0.0161，其中“原子能”贡献了 0.0126，而“应用”只贡献了0.0035。这个比例和我们的直觉比较一致了。</p>

<h3 id="toc_13">附录：ElasticSearch相关查询</h3>

<h5 id="toc_14">文档内容</h5>

<pre><code>curl -XGET &#39;172.168.5.110:9200/logstash-wap-2016.03.22/wap/AVOcKIIFPPR76qlEVfH2?pretty&#39;
</code></pre>

<p>结果</p>

<p>{<br/>
  <q>_index</q> : <q>logstash-wap-2016.03.22</q>,<br/>
  <q>_type</q> : <q>wap</q>,<br/>
  <q>_id</q> : <q>AVOcKIIFPPR76qlEVfH2</q>,<br/>
  <q>_version</q> : 1,<br/>
  <q>found</q> : true,<br/>
  <q>_source</q> : {<br/>
    <q>message</q> : <q>2016-03-22 10:30:12 - [ INFO ] [appName: wap] 172.168.5.224 - [cn.hao24.mobile.aop.RequestAOP] Beginning method: cn.hao24.mobile.controller.goods.GoodsController.getGoodsExtendDescAPP\tRequest end. This request cost [26 ms] time. =&gt; [SID: MasmqDCe1iFiullGvJWHPe8VIfzIJjeZk] [CustId: ] [CustIp: ] [OsVersion: ] [PhoneModel: ] V1</q>,<br/>
    <q>@version</q> : <q>1</q>,<br/>
    <q>@timestamp</q> : <q>2016-03-22T02:30:13.287Z</q>,<br/>
    <q>host</q> : <q>template-CentOS6.5</q>,<br/>
    <q>path</q> : <q>/hao24/logs/admin-log.log</q>,<br/>
    <q>timestamp</q> : <q>2016-03-22 10:30:12</q>,<br/>
    <q>loglevel</q> : <q>INFO</q>,<br/>
    <q>appName</q> : <q>wap</q>,<br/>
    <q>serverip</q> : <q>172.168.5.224</q>,<br/>
    <q>class</q> : <q>cn.hao24.mobile.aop</q>,<br/>
    <q>method</q> : <q>RequestAOP</q>,<br/>
    <q>status</q> : <q>Beginning method: cn.hao24.mobile.controller.goods.GoodsController.getGoodsExtendDescAPP\tRequest end. This request cost [26 ms] time.</q>,<br/>
    <q>sid</q> : <q>MasmqDCe1iFiullGvJWHPe8VIfzIJjeZk</q><br/>
  }<br/>
}</p>

<h5 id="toc_15">查看Status字段分词</h5>

<pre><code>curl -XPOST &#39;172.168.5.110:9200/logstash-wap-2016.03.22/_analyze?pretty&#39; -d &#39;
{
    &quot;text&quot;: &quot;Beginning method: cn.hao24.mobile.controller.category.CategoryController.listAjax  Request end. This request cost [268 ms] time.&quot;
}&#39;
</code></pre>

<h5 id="toc_16">结果</h5>

<pre><code>{
  &quot;tokens&quot; : [ {
    &quot;token&quot; : &quot;beginning&quot;,
    &quot;start_offset&quot; : 0,
    &quot;end_offset&quot; : 9,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 0
  }, {
    &quot;token&quot; : &quot;method&quot;,
    &quot;start_offset&quot; : 10,
    &quot;end_offset&quot; : 16,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 1
  }, {
    &quot;token&quot; : &quot;cn.hao24&quot;,
    &quot;start_offset&quot; : 18,
    &quot;end_offset&quot; : 26,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 2
  }, {
    &quot;token&quot; : &quot;mobile.controller.category.categorycontroller.listajaxrequest&quot;,
    &quot;start_offset&quot; : 27,
    &quot;end_offset&quot; : 88,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 3
  }, {
    &quot;token&quot; : &quot;end&quot;,
    &quot;start_offset&quot; : 89,
    &quot;end_offset&quot; : 92,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 4
  }, {
    &quot;token&quot; : &quot;this&quot;,
    &quot;start_offset&quot; : 94,
    &quot;end_offset&quot; : 98,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 5
  }, {
    &quot;token&quot; : &quot;request&quot;,
    &quot;start_offset&quot; : 99,
    &quot;end_offset&quot; : 106,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 6
  }, {
    &quot;token&quot; : &quot;cost&quot;,
    &quot;start_offset&quot; : 107,
    &quot;end_offset&quot; : 111,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 7
  }, {
    &quot;token&quot; : &quot;268&quot;,
    &quot;start_offset&quot; : 113,
    &quot;end_offset&quot; : 116,
    &quot;type&quot; : &quot;&lt;NUM&gt;&quot;,
    &quot;position&quot; : 8
  }, {
    &quot;token&quot; : &quot;ms&quot;,
    &quot;start_offset&quot; : 117,
    &quot;end_offset&quot; : 119,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 9
  }, {
    &quot;token&quot; : &quot;time&quot;,
    &quot;start_offset&quot; : 121,
    &quot;end_offset&quot; : 125,
    &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
    &quot;position&quot; : 10
  } ]
}
</code></pre>

<h5 id="toc_17">TF-IDF分值</h5>

<pre><code>curl -XGET &#39;172.168.5.110:9200/logstash-wap-2016.03.22/wap/AVOcKIIFPPR76qlEVfH2/_explain?pretty&#39; -d &#39;{
      &quot;query&quot; : {
        &quot;term&quot; : { &quot;status&quot; : &quot;request&quot; }
      }
}&#39;
</code></pre>

<h5 id="toc_18">结果</h5>

<p>{<br/>
  <q>_index</q> : <q>logstash-wap-2016.03.22</q>,<br/>
  <q>_type</q> : <q>wap</q>,<br/>
  <q>_id</q> : <q>AVOcKIIFPPR76qlEVfH2</q>,<br/>
  <q>matched</q> : true,<br/>
  <q>explanation</q> : {<br/>
    <q>value</q> : 2.5711107,<br/>
    <q>description</q> : <q>sum of:</q>,<br/>
    <q>details</q> : [ {<br/>
      <q>value</q> : 2.5711107,<br/>
      <q>description</q> : <q>weight(status:request in 31) [PerFieldSimilarity], result of:</q>,<br/>
      <q>details</q> : [ {<br/>
        <q>value</q> : <mark><strong>2.5711107</strong></mark>,<br/>
        <q>description</q> : <q>fieldWeight in 31, product of:</q>,<br/>
        <q>details</q> : [ {<br/>
          <mark><q>value</q> : 1.4142135,</mark><br/>
          <q>description</q> : <q><mark><strong>tf</strong></mark>(freq=2.0), with freq of:</q>,<br/>
          <q>details</q> : [ {<br/>
            <q>value</q> : 2.0,<br/>
            <q>description</q> : <q>termFreq=2.0</q>,<br/>
            <q>details</q> : [ ]<br/>
          } ]<br/>
        }, {<br/>
          <mark><q>value</q> : 1.8180498,</mark><br/>
          <q>description</q> : <q><mark><strong>idf</strong></mark>(docFreq=439561, maxDocs=996081)</q>,<br/>
          <q>details</q> : [ ]<br/>
        }, {<br/>
          <q>value</q> : 1.0,<br/>
          <q>description</q> : <q>fieldNorm(doc=31)</q>,<br/>
          <q>details</q> : [ ]<br/>
        } ]<br/>
      } ]<br/>
    }, {<br/>
      <q>value</q> : 0.0,<br/>
      <q>description</q> : <q>match on required clause, product of:</q>,<br/>
      <q>details</q> : [ {<br/>
        <q>value</q> : 0.0,<br/>
        <q>description</q> : <q># clause</q>,<br/>
        <q>details</q> : [ ]<br/>
      }, {<br/>
        <q>value</q> : 0.55003995,<br/>
        <q>description</q> : <q>_type:wap, product of:</q>,<br/>
        <q>details</q> : [ {<br/>
          <q>value</q> : 1.0,<br/>
          <q>description</q> : <q>boost</q>,<br/>
          <q>details</q> : [ ]<br/>
        }, {<br/>
          <q>value</q> : 0.55003995,<br/>
          <q>description</q> : <q>queryNorm</q>,<br/>
          <q>details</q> : [ ]<br/>
        } ]<br/>
      } ]<br/>
    } ]<br/>
  }<br/>
}</p>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[高性能MySQL - Schema与数据类型优化]]></title>
        <link href="http://nathanchen.github.io/14585676478158.html"/>
        <updated>2016-03-21T21:40:47+08:00</updated>
        <id>http://nathanchen.github.io/14585676478158.html</id>
        <content type="html"><![CDATA[
<h3 id="toc_0">选择优化的数据类型</h3>

<h4 id="toc_1">字符串类型</h4>

<h5 id="toc_2">VARCHAR</h5>

<p><code>VARCHAR</code>类型用于存储可变长字符串。它比定长类型更节省空间，因为它仅使用必要的空间。</p>

<p><code>VARCHAR</code>需要使用1或2个额外字节记录字符串的长度：如果列的最大长度小于或等于255字节，则只使用1个字节表示；否则使用2个字节。</p>

<h5 id="toc_3">CHAR</h5>

<p><code>CHAR</code>类型是定长的：<code>MySQL</code>总是根据定义的字符串长度分配足够的空间。当存储<code>CHAR</code>值时，<code>MySQL</code>会删除所有的末尾空格。</p>

<p><code>CHAR</code>适合存储很短的字符串，或者所有值都接近同一个长度。；对于经常变更的数据，<code>CHAR</code>也比<code>VARCHAR</code>更好，因为定长的<code>CHAR</code>类型不容易产生碎片。对于非常短的列，<code>CHAR</code>比<code>VARCHAR</code>在存储空间上也更有效率。</p>

<h4 id="toc_4">日期和时间类型</h4>

<p>除了特殊情况，通常应该尽量使用<code>TIMESTAMP</code>，因为它比<code>DATETIME</code>空间效率更高。</p>

<h4 id="toc_5">特殊类型数据</h4>

<p>人们经常使用<code>VARCHAR(15)</code>列来存储<code>IP</code>地址。然而，它们实际上是32位无符号整数，不是字符串。用小数点将地址分成四段的表示方法只是为了让人们阅读容易。所以应该用无符号整数存储<code>IP</code>地址。</p>

<h3 id="toc_6">范式和反范式</h3>

<h4 id="toc_7">范式的优点和缺点</h4>

<p><strong>范式化通常能够带来的好处</strong>：</p>

<ul>
<li>范式化的更新操作通常比反范式化要快</li>
<li>当数据较好地范式化时，就只有很少或者没有重复数据，所以只需要修改更少的数据</li>
<li>范式化的表通常更小，可以更好地放在内存里，所以执行操作会更快</li>
<li>很少有多余的数据意味着检索列表数据时更少需要<code>DISTINCT</code>或者<code>GROUP BY</code>语句。</li>
</ul>

<p><strong>范式化设计的<code>schema</code>的缺点是通常需要关联</strong>。稍微复杂一些的查询语句在符合范式的<code>schema</code>上都可能需要至少一次关联，也许更多。</p>

<h4 id="toc_8">反范式的优点和缺点</h4>

<p>反范式化的<code>schema</code>因为所有数据都在一张表中，可以很好地避免关联。</p>

<p>如果不需要关联表，则对大部分查询最差的情况——即使表没有使用索引——是全表扫描。当数据比内存大时，这可能比关联要快得多，因为这样避免了随机I/O。</p>

<blockquote>
<p>混用范式化和反范式化</p>
</blockquote>

<h3 id="toc_9">加快ALTER TABLE操作的速度</h3>

<p>不是所有的<code>ALTER TABLE</code>操作都会引起表重建。例如，有两种方法可以改变或者删除一个列的默认值（一种方法很快，另一种则很慢）。</p>

<p>假如要修改电影的默认租赁期限，从三天改到五天。下面是很慢的方式：</p>

<pre><code class="language-sql">ALTER TABLE sakila.film
MODIFY COLUMN rental_duration TINYINT(3) NOT NULL DEFAULT 5;
</code></pre>

<p><code>SHOW STATUS</code>显示这个语句做了1000次读和1000次插入操作。换句话说，它拷贝了整张表到一张新表，甚至列的类型、大小和可否为<code>NULL</code>属性都没改变。</p>

<p>另外一种方法是通过<code>ALTER COLUMN</code>操作来改变列的默认值：</p>

<pre><code class="language-sql">ALTER TABLE sakila.film
ALTER COLUMN rental_duration SET DEFAULT 5;
</code></pre>

<p>这个语句会直接修改<code>.frm</code>文件而不涉及表数据。所以，这个操作是非常快的。</p>

<h4 id="toc_10">只修改.frm文件</h4>

<p>下面这些操作是有可能不需要重建表的：</p>

<ul>
<li>移除（不是增加）一个列的<code>AUTO_INCREMENT</code>属性</li>
<li>增加、移除，或更改<code>ENUM</code>和<code>SET</code>常量。如果移除的是已经有行数据用到其值的常量，查询将会返回一个空字符串值</li>
</ul>

<p>基本的技术是为想要的表结构创建一个新的<code>.frm</code>文件，然后用它替换掉已经存在的那张表的<code>.frm</code>文件，像下面这样：</p>

<ul>
<li>创建一张有相同结构的空表，并进行所需要的修改</li>
<li>执行<code>FLUSH TABLES WITH READ LOCK</code>。这将会关闭所有正在使用的表，并且禁止任何表被打开。</li>
<li>交换<code>.frm</code>文件</li>
<li>执行<code>UNLOCK TABLES</code>来释放第二步的读锁</li>
</ul>

<h4 id="toc_11">快速创建<code>MyISAM</code>索引</h4>

<p>为了高效地载入数据到MyISAM表中，有一个常用的技巧是先禁用、载入数据，然后重新启用索引：</p>

<pre><code>ALTER TABLE test.load_data DISABLE KEYS;
-- load the data
ALTER TABLE test.load_data ENABLE KEYS;
</code></pre>

<p>这个技巧能够发挥作用，是因为构建索引的工作被延迟到数据完全载入以后，这个时候已经可以通过排序来构建索引了。这样做会快很多，并且使得索引树的碎片更少、更紧凑。</p>

]]></content>
    </entry>
    
</feed>
